---
title: Overview
bibliography: ../references.bib
---

::: {.callout-tip}
## Reading

**Data:** @degen_prior_2021 on how prior beliefs modulate projectivity inferences. We will use the data collected for that paper, which can be found [here](https://github.com/judith-tonhauser/projective-probability), in this module. 

**Theory:** @degen_factive_2022 and @kane_intensional_2022 on whether there is a discrete category of factive predicates. We will specifically be concerned with Degen and Tonhauser's discussion–broadly, but most specifically in Section 4–about the sources of gradience. 
:::

Like in the first module of the course, in this second module of the course, we are going to focus on minimally extending standard statistical models used in analyzing inference judgments in order to probe how semantic semantic representations and/or reasoning processes interact with world knowledge (or *prior beliefs*) in driving inference judgments. We're going to consider two subtly distinct questions: (i) whether there is evidence for discrete classes of lexical representations that determine inferences commonly associated with factive predicates or whether this knowledge is fundamentally continuous; and (ii) how, for aspects of lexical knowledge that are fundamentally continuous, that knowledge is integrated with world knowledge.

The first question is the main focus of the paper by @degen_factive_2022, who argue (p. 553) "...that there is little empirical support from [their six] experiments for the assumed categorical distinction between factive and nonfactive predicates." We'll first discuss some modeling evidence presented by @kane_intensional_2022 that countervails this argument. We won't implement Kane et al.'s model, though all of the data is available [here](http://megaattitude.io/), and their code is documented and publicly available [here](https://github.com/MegaAttitude/intensional-gaps). The gist is that, when we appropriately account for various sources of gradience in inference judgments, we observe a small number of clear cluster of predicates, all of which correspond cleanly to the predicate classes one might expect from the literature of clause-embedding predicates and a subset of which correspond to traditional subclassifications of factives.

Our main reason for looking the finding by @kane_intensional_2022 is to sharpen the second question, which we will address by modeling data collected by @degen_prior_2021 for a slightly different purpose. As in Module 1, the basic recipe will be (i) to define two or more (families of) models; (ii) to fit both models to the data from some acceptability judgment data–in this case, to the data collected by @degen_prior_2021; and (iii) to compare how well the two models fit the data, weighed against some measure of how parsimonious (or conversely, complex) each model is.