<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.321">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Representation Learning for Syntactic and Semantic Theory - Model definition</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../island-effects/model-fitting-and-comparison.html" rel="next">
<link href="../island-effects/index.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/quarto-contrib/line-highlight-1.0.0/line-highlight.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../island-effects/index.html">Module 1: Island Effects</a></li><li class="breadcrumb-item"><a href="../island-effects/model-definition.html">Model definition</a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Representation Learning for Syntactic and Semantic Theory</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">About</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../installation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Installation</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../motivations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Motivations</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../methodological-approach.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Methodological Approach</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../course-structure-and-content.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Course Structure and Content</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Foundational Concepts in Probability and Statistics</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../foundational-concepts-in-probability-and-statistics/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">What is a probability?</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../foundational-concepts-in-probability-and-statistics/random-variables-and-probability-distributions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Random variables and probability distributions</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../foundational-concepts-in-probability-and-statistics/statistical-inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Statistical Inference</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
 <span class="menu-text">Module 1: Island Effects</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../island-effects/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../island-effects/model-definition.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Model definition</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../island-effects/model-fitting-and-comparison.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Model Fitting and Comparison</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
 <span class="menu-text">Module 2: Projective Content</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../projective-content/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../projective-content/inferentially-defined-classes-of-predicates.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Inferentially defined classes of predicates</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../projective-content/model-definition.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Model definition</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../projective-content/model-fitting-and-comparison.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Model fitting and comparison</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../projective-content/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../selection/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Module 3: Selection</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../thematic-roles/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Module 4: Thematic Roles</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#sprouse-et-als-2016-experiments-1-and-3" id="toc-sprouse-et-als-2016-experiments-1-and-3" class="nav-link active" data-scroll-target="#sprouse-et-als-2016-experiments-1-and-3">Sprouse et al’s (2016) Experiments 1 and 3</a>
  <ul class="collapse">
  <li><a href="#data-collection-instrument" id="toc-data-collection-instrument" class="nav-link" data-scroll-target="#data-collection-instrument">Data collection instrument</a></li>
  <li><a href="#scale-normalization" id="toc-scale-normalization" class="nav-link" data-scroll-target="#scale-normalization">Scale normalization</a></li>
  <li><a href="#design" id="toc-design" class="nav-link" data-scroll-target="#design">Design</a></li>
  </ul></li>
  <li><a href="#formalizing-the-model-families" id="toc-formalizing-the-model-families" class="nav-link" data-scroll-target="#formalizing-the-model-families">Formalizing the model families</a>
  <ul class="collapse">
  <li><a href="#the-ordinal-logit-linking-model" id="toc-the-ordinal-logit-linking-model" class="nav-link" data-scroll-target="#the-ordinal-logit-linking-model">The Ordinal Logit Linking Model</a></li>
  <li><a href="#a-first-poor-approximation" id="toc-a-first-poor-approximation" class="nav-link" data-scroll-target="#a-first-poor-approximation">A First (Poor) Approximation</a></li>
  <li><a href="#a-second-slightly-less-poor-approximation" id="toc-a-second-slightly-less-poor-approximation" class="nav-link" data-scroll-target="#a-second-slightly-less-poor-approximation">A Second (Slightly Less Poor) Approximation</a></li>
  <li><a href="#adding-grammar-and-processing-effects" id="toc-adding-grammar-and-processing-effects" class="nav-link" data-scroll-target="#adding-grammar-and-processing-effects">Adding Grammar and Processing Effects</a></li>
  </ul></li>
  <li><a href="#summing-up" id="toc-summing-up" class="nav-link" data-scroll-target="#summing-up">Summing Up</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Model definition</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p><span class="citation" data-cites="sprouse_acceptability_2018">Sprouse (<a href="#ref-sprouse_acceptability_2018" role="doc-biblioref">2018, 213–15</a>)</span> discusses how one might test particular theories that assume categorical or gradient grammatical representations: compute the predicted acceptability from an implementation of such theories and then using those predictions as predictors in some model. He notes (p.&nbsp;212) that, in deriving these predictions, it is important to consider five distinct (families of) phenomena that are likely, in combination, to modulate acceptability:</p>
<p><a name="five-phenomena"></a></p>
<ol type="i">
<li>the effects of typical sentence processing over the portion of the sentence that can be processed typically, such as dependency complexity, ambiguity resolution complexity (e.g., surprisal), working memory, etc,</li>
<li>the effects of atypical sentence processing over any structure-building violations, such as processes that are designed to construct an interpretable structure out of word strings,</li>
<li>plausibility and real-world knowledge effects,</li>
<li>task effects, and</li>
<li>any number of other components of sentence processing and acceptability judgments that we may not have explored yet.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></li>
</ol>
<p>He goes on to suggest that “…we can minimize the impact of the effects of typical processing, plausibility and real-world knowledge, task effects, and possibly even unexplored factors by using experimentally-defined phenomena…and focusing on the effect size of the difference between them.”</p>
<p><span class="citation" data-cites="sprouse_experimental_2016">Sprouse et al. (<a href="#ref-sprouse_experimental_2016" role="doc-biblioref">2016, 308</a>)</span> implement this idea in their data collection using “…a factorial design to isolate island effects over and above other factors (such as processing complexity) that may influence acceptability judgments <span class="citation" data-cites="sprouse_program_2007 sprouse_validation_2011 sprouse_assessing_2012">(<a href="#ref-sprouse_program_2007" role="doc-biblioref">Sprouse 2007</a>, <a href="#ref-sprouse_validation_2011" role="doc-biblioref">2011</a>; <a href="#ref-sprouse_assessing_2012" role="doc-biblioref">Sprouse and Almeida 2012</a>)</span>”. But even if we can minimize the impact of these effects, <span class="citation" data-cites="sprouse_acceptability_2018">Sprouse (<a href="#ref-sprouse_acceptability_2018" role="doc-biblioref">2018, 214</a>)</span> points to two main obstacles to doing this comparison in practice: (a) “theories of typical sentence processing are an active area of research”; and (b) “there is little to no research on the atypical sentence processing that arises for ungrammatical sentences”.</p>
<p>These are serious obstacles for anyone interested in comparing <em>particular</em> theories that assume categorical or gradient grammatical representations; and we should of course strive to test as specific a theory as we can. But if we are interested instead in comparing how well any theory that assumes a particular kind of grammatical representation can explain acceptability judgments relevant to a particular phenomenon, we can take a different tack.</p>
<p>The basic idea will be to ask, for a particular family of theories–in the current case, whether categorical or gradient representations comprise grammars–how we can represent the effect on acceptability that any possible analysis under that theory could produce. We will then search among those analyses for those that fit the data best. We can then compare the families of theories by quantitatively measuring the fit of those theories’ best analyses to the data and–as a measure of parsimony–weighing that fit against how many such best analyses there are. The more constrained the family of theories, the fewer such best analyses it will have and thus the more parsimonious we will consider it.</p>
<p>To illustrate how we might implement a comparison between categorical and gradient grammars, we’ll use <a href="https://www.jonsprouse.com/data/NLLT2016/">the data</a> collected by <span class="citation" data-cites="sprouse_experimental_2016">Sprouse et al. (<a href="#ref-sprouse_experimental_2016" role="doc-biblioref">2016</a>)</span> in their Experiments 1 and 3, which investigated English island effects across a range of island types and dependency types.</p>
<section id="sprouse-et-als-2016-experiments-1-and-3" class="level2">
<h2 class="anchored" data-anchor-id="sprouse-et-als-2016-experiments-1-and-3">Sprouse et al’s (2016) Experiments 1 and 3</h2>
<p>First, let’s load the data.</p>
<div class="cell" data-tags="[]" data-execution_count="1">
<details>
<summary>Download the data</summary>
<div class="sourceCode cell-code" id="cb1" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>wget https:<span class="op">//</span>www.jonsprouse.com<span class="op">/</span>data<span class="op">/</span>NLLT2016<span class="op">/</span>SCGC.data.<span class="bu">zip</span> <span class="op">-</span>P data<span class="op">/</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>unzip data<span class="op">/</span>SCGC.data.<span class="bu">zip</span> <span class="op">-</span>d data<span class="op">/</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-tags="[]" data-execution_count="49">
<div class="sourceCode cell-code" id="cb2" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pandas <span class="im">import</span> DataFrame, read_csv</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> load_data(fname: <span class="bu">str</span>, remove_fillers: <span class="bu">bool</span> <span class="op">=</span> <span class="va">False</span>) <span class="op">-&gt;</span> DataFrame:</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Load Sprouse et al.'s (2016) data</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="co">    ----------</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="co">    fname</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="co">        The filename of the data</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="co">    remove_fillers</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="co">        Whether to remove the fillers</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns</span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a><span class="co">    -------</span></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a><span class="co">    data</span></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a><span class="co">        The data</span></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># read the raw data skipping comment rows at the beginning</span></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>    data <span class="op">=</span> read_csv(fname, skiprows<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># remove NaN judgments</span></span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>    data <span class="op">=</span> data.query(<span class="st">"~judgment.isnull()"</span>)</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># fill NaNs</span></span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> col <span class="kw">in</span> [<span class="st">"dependency"</span>, <span class="st">"structure"</span>, <span class="st">"distance"</span>, <span class="st">"island"</span>]:</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>        data.loc[:,col] <span class="op">=</span> data[col].fillna(<span class="st">"filler"</span>)</span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>    <span class="co"># remove fillers</span></span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> remove_fillers:</span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>        data <span class="op">=</span> data.query(<span class="st">"dependency != 'filler'"</span>)</span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> data</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-tags="[]" data-execution_count="60">
<details>
<summary>Load the Experiments 1 and 3 data</summary>
<div class="sourceCode cell-code" id="cb3" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pandas <span class="im">import</span> concat</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>data_dir <span class="op">=</span> <span class="st">"./data/SCGC.data/"</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>data_exp1 <span class="op">=</span> load_data(os.path.join(data_dir, <span class="st">"Experiment 1 results - English.csv"</span>))</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>data_exp3 <span class="op">=</span> load_data(os.path.join(data_dir, <span class="st">"Experiment 3 results - English D-linking.csv"</span>))</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>data_exp3[<span class="st">"dependency"</span>] <span class="op">=</span> data_exp3.dependency.<span class="bu">map</span>({</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">"WH"</span>: <span class="st">"DlinkedWH"</span>, <span class="st">"RC"</span>: <span class="st">"DlinkedRC"</span>, <span class="st">"filler"</span>: <span class="st">"filler"</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>data_exp1[<span class="st">"exp"</span>] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>data_exp3[<span class="st">"exp"</span>] <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> concat([data_exp1, data_exp3])</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>data</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="60">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">subject</th>
<th data-quarto-table-cell-role="th">survey</th>
<th data-quarto-table-cell-role="th">order</th>
<th data-quarto-table-cell-role="th">judgment</th>
<th data-quarto-table-cell-role="th">item</th>
<th data-quarto-table-cell-role="th">condition</th>
<th data-quarto-table-cell-role="th">zscores</th>
<th data-quarto-table-cell-role="th">dependency</th>
<th data-quarto-table-cell-role="th">island</th>
<th data-quarto-table-cell-role="th">structure</th>
<th data-quarto-table-cell-role="th">distance</th>
<th data-quarto-table-cell-role="th">exp</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>A15EZJS1DROADE</td>
<td>1.3</td>
<td>13</td>
<td>1.0</td>
<td>F.1.UG</td>
<td>F.1.UG</td>
<td>-2.677619</td>
<td>filler</td>
<td>filler</td>
<td>filler</td>
<td>filler</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>A1948V3S82RNX5</td>
<td>1.2</td>
<td>17</td>
<td>1.0</td>
<td>F.1.UG</td>
<td>F.1.UG</td>
<td>-1.188567</td>
<td>filler</td>
<td>filler</td>
<td>filler</td>
<td>filler</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>A19P3BIPW6UMQ9</td>
<td>1.2</td>
<td>17</td>
<td>2.0</td>
<td>F.1.UG</td>
<td>F.1.UG</td>
<td>-1.012792</td>
<td>filler</td>
<td>filler</td>
<td>filler</td>
<td>filler</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>A1BZDH1VJJK97V</td>
<td>1.1</td>
<td>26</td>
<td>2.0</td>
<td>F.1.UG</td>
<td>F.1.UG</td>
<td>-1.148201</td>
<td>filler</td>
<td>filler</td>
<td>filler</td>
<td>filler</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>A1CE3DR200PXSS</td>
<td>1.2</td>
<td>17</td>
<td>1.0</td>
<td>F.1.UG</td>
<td>F.1.UG</td>
<td>-1.285708</td>
<td>filler</td>
<td>filler</td>
<td>filler</td>
<td>filler</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">10651</td>
<td>AU0LVWJM11NLF</td>
<td>1.1</td>
<td>51</td>
<td>4.0</td>
<td>WH.whe.non.sh.01</td>
<td>WH.whe.non.sh</td>
<td>-0.234321</td>
<td>DlinkedWH</td>
<td>WH</td>
<td>non</td>
<td>short</td>
<td>3</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">10652</td>
<td>AWSCR2O3D6T87</td>
<td>1.4</td>
<td>29</td>
<td>7.0</td>
<td>WH.whe.non.sh.08</td>
<td>WH.whe.non.sh</td>
<td>0.777625</td>
<td>DlinkedWH</td>
<td>WH</td>
<td>non</td>
<td>short</td>
<td>3</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">10653</td>
<td>AWSCR2O3D6T87</td>
<td>1.4</td>
<td>32</td>
<td>7.0</td>
<td>WH.whe.non.sh.04</td>
<td>WH.whe.non.sh</td>
<td>0.777625</td>
<td>DlinkedWH</td>
<td>WH</td>
<td>non</td>
<td>short</td>
<td>3</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">10654</td>
<td>AZCV8JQ2NEFN8</td>
<td>1.4</td>
<td>29</td>
<td>7.0</td>
<td>WH.whe.non.sh.08</td>
<td>WH.whe.non.sh</td>
<td>0.699702</td>
<td>DlinkedWH</td>
<td>WH</td>
<td>non</td>
<td>short</td>
<td>3</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">10655</td>
<td>AZCV8JQ2NEFN8</td>
<td>1.4</td>
<td>32</td>
<td>7.0</td>
<td>WH.whe.non.sh.04</td>
<td>WH.whe.non.sh</td>
<td>0.699702</td>
<td>DlinkedWH</td>
<td>WH</td>
<td>non</td>
<td>short</td>
<td>3</td>
</tr>
</tbody>
</table>

<p>21195 rows × 12 columns</p>
</div>
</div>
</div>
<section id="data-collection-instrument" class="level3">
<h3 class="anchored" data-anchor-id="data-collection-instrument">Data collection instrument</h3>
<p>Judgments in Sprouse et al.’s data were collected using a 7-point Likert scale–i.e.&nbsp;ordinal scale.</p>
<div class="cell" data-tags="[]" data-execution_count="71">
<details>
<summary>Plotting code</summary>
<div class="sourceCode cell-code" id="cb4" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> numpy <span class="im">import</span> arange</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib.pyplot <span class="im">import</span> subplot</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> subplot()</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>ax.hist(data.judgment, bins<span class="op">=</span>arange(<span class="dv">1</span>, <span class="dv">9</span>), rwidth<span class="op">=</span><span class="fl">0.5</span>, align<span class="op">=</span><span class="st">"left"</span>)</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">"Likert scale acceptability judgments (Experiments 1 and 3)"</span>)</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">"Likert scale acceptability judgment"</span>)</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> ax.set_ylabel(<span class="st">"Count"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="model-definition_files/figure-html/cell-5-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="scale-normalization" class="level3">
<h3 class="anchored" data-anchor-id="scale-normalization">Scale normalization</h3>
<p>Sprouse et al.&nbsp;also provide by-subject <span class="math inline">\(z\)</span>-scores, which are the quantities they use as dependent variables in their analyses because they are believed to “[eliminate] certain kinds of scale biases between participants” <span class="citation" data-cites="sprouse_experimental_2016">(<a href="#ref-sprouse_experimental_2016" role="doc-biblioref">Sprouse et al. 2016, 325</a>)</span>. These scores are derived by mapping ordinal scale ratings <span class="math inline">\(y_n\)</span> to <span class="math inline">\(\frac{y_n - \text{mean}\left(\left\{y_n \mid s = \text{subj}(n)\right\}\right)}{\text{sd}\left(\left\{y_n \mid s = \text{subj}(n)\right\}\right)}\)</span>, where <span class="math inline">\(\text{subj}\)</span> maps a response index to a subject identifier. We can recompute these values and see that they have high correlation with those that Sprouse et al.&nbsp;compute–presumably differing only up to floating point error.</p>
<div class="cell" data-tags="[]" data-execution_count="62">
<div class="sourceCode cell-code" id="cb5" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> numpy <span class="im">import</span> <span class="bu">round</span>, corrcoef</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pandas <span class="im">import</span> Series</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> zscore(responses: Series) <span class="op">-&gt;</span> Series:</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""z-score responses</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="co">    ----------</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="co">    responses</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="co">        The responses to z-score</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a><span class="co">        </span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a><span class="co">    -------</span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a><span class="co">    zscores</span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a><span class="co">        The z-scored responses</span></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (responses <span class="op">-</span> responses.mean()) <span class="op">/</span> responses.std()</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>zscores_exp1 <span class="op">=</span> data.groupby(<span class="st">"subject"</span>).judgment.transform(zscore)</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a><span class="bu">round</span>(corrcoef(data.zscores, zscores_exp1)[<span class="dv">1</span>,<span class="dv">0</span>], <span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="62">
<pre data-code-line-numbers=""><code>0.998</code></pre>
</div>
</div>
<p>We will <em>not</em> be using these <span class="math inline">\(z\)</span>-scores for our implementation. Instead, we will the raw ordinal responses using an ordinal logit model–described below. This approach will be taken throughout the course on principled grounds: any preprocessing of a dependent variable necessarily introduces potentially important changes in the structure of that variable that can have downstream effects on statistical inference.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> Nonetheless, for the purposes of plotting, <span class="math inline">\(z\)</span>-scores can be useful, and we will use them below.</p>
</section>
<section id="design" class="level3">
<h3 class="anchored" data-anchor-id="design">Design</h3>
<p>As mentioned above, the dataset has a factorial design, manipulating four factors:</p>
<ol type="a">
<li><code>structure</code> (<code>non</code>-island, <code>island</code>): whether or not the sentence contains a purported island violation</li>
<li><code>distance</code> (<code>short</code>, <code>long</code>): whether the number of words between the filler (i.e.&nbsp;the WH word) and the gap (i.e.&nbsp;the position the word is associated with) is small or large</li>
<li><code>island</code> type (<code>ADJ</code>unct island, <code>NP</code> island, <code>SUB</code>ject island, <code>WH</code>ether island): if <code>structure</code> = <code>island</code> and <code>distance</code> = <code>long</code>, what the island violation type is</li>
<li><code>dependency</code> type (<code>WH</code> main clause question, <code>RC</code>: relative clause, <code>DlinkedWH</code> main clause D-linked question, <code>DlinkedRC</code>: D-linked relative clause): whether the sentence is a WH interrogative or contains a relative clause and what the filler is (D-linked or not)</li>
</ol>
<p><a href="#exm-WH-whe-non-sh-05"></a> <a href="#exm-WH-whe-non-lg-05"></a> <a href="#exm-WH-whe-isl-sh-05"></a> <a href="#exm-WH-whe-isl-lg-05"></a> The first two factors–whose manipulation for <code>island</code>=<code>WH</code> and <code>dependency</code>=<code>WH</code> can be seen in (1-4), corresponding to items <code>WH.whe.non.sh.05</code>, <code>WH.whe.isl.sh.05</code>, <code>WH.whe.non.lg.05</code>, <code>WH.whe.isl.lg.05</code>–are intended to provide a way of estimating how acceptability is modulated by processing load–e.g.&nbsp;induced by having to keep a filler in memory longer before it can be linked with its gap–while keeping the meaning as constant as possible.<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></p>
<ol class="example" type="1">
<li>Who thinks that Aaron bought the house? (<code>structure</code>=<code>non</code>, <code>distance</code>=<code>short</code>)</li>
<li>Who wonders whether Aaron bought the house? (<code>structure</code>=<code>island</code>, <code>distance</code>=<code>short</code>)</li>
<li>What does the agent think that Aaron bought? (<code>structure</code>=<code>non</code>, <code>distance</code>=<code>long</code>)</li>
<li>What does the agent wonder whether Aaron bought? (<code>structure</code>=<code>island</code>, <code>distance</code>=<code>long</code>)</li>
</ol>
<p><span class="citation" data-cites="sprouse_experimental_2016">Sprouse et al. (<a href="#ref-sprouse_experimental_2016" role="doc-biblioref">2016</a>)</span> want this manipulation so that they can pull apart the contribution of what <span class="citation" data-cites="sprouse_acceptability_2018">Sprouse (<a href="#ref-sprouse_acceptability_2018" role="doc-biblioref">2018, 210</a>)</span> refers to as “the ‘grammar’ component of the theory of acceptability”, which he takes to be “something like an error signal from the structure-building component of the sentence processor” from world knowledge/typicality as well as “the ‘sentence processing’ component of the theory of acceptability judgments”, which he takes to be “everything that isn’t structure-building: parsing strategies for various types of ambiguity resolution, the complexity that arises from ambiguity resolution <span class="citation" data-cites="hale_probabilistic_2001 levy_expectation-based_2008">(e.g., surprisal, <a href="#ref-hale_probabilistic_2001" role="doc-biblioref">Hale 2001</a>; <a href="#ref-levy_expectation-based_2008" role="doc-biblioref">Levy 2008</a>)</span>, the complexity that arises from dependency processing <span class="citation" data-cites="gibson_linguistic_1998">(<a href="#ref-gibson_linguistic_1998" role="doc-biblioref">Gibson 1998</a>)</span>, the complexity that arises from working memory operations more generally <span class="citation" data-cites="lewis_activation-based_2005 mcelree_memory_2003">(<a href="#ref-lewis_activation-based_2005" role="doc-biblioref">Lewis and Vasishth 2005</a>; <a href="#ref-mcelree_memory_2003" role="doc-biblioref">McElree, Foraker, and Dyer 2003</a>)</span>, and many others components.”</p>
<p>We can get a quick intuition for what these effects might look like by looking at the average <span class="math inline">\(z\)</span>-scores for the above items.</p>
<div class="cell" data-tags="[]" data-execution_count="64">
<div class="sourceCode cell-code" id="cb7" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>factors <span class="op">=</span> [</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">"island"</span>, <span class="st">"dependency"</span>,</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">"distance"</span>, <span class="st">"structure"</span> </span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>item05_ids <span class="op">=</span> [</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">"WH.whe.non.sh.05"</span>, <span class="st">"WH.whe.non.lg.05"</span>, </span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">"WH.whe.isl.sh.05"</span>, <span class="st">"WH.whe.isl.lg.05"</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>data_exp1_item05 <span class="op">=</span> data_exp1[data_exp1.item.isin(item05_ids)]</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>data_exp1_item05_means <span class="op">=</span> data_exp1_item05.groupby(factors[<span class="dv">2</span>:] <span class="op">+</span> [<span class="st">"item"</span>])[[<span class="st">"zscores"</span>]].mean()</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>data_exp1_item05_means.sort_values(<span class="st">"zscores"</span>, ascending<span class="op">=</span><span class="va">False</span>).reset_index()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="64">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">distance</th>
<th data-quarto-table-cell-role="th">structure</th>
<th data-quarto-table-cell-role="th">item</th>
<th data-quarto-table-cell-role="th">zscores</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>short</td>
<td>non</td>
<td>WH.whe.non.sh.05</td>
<td>0.956486</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>short</td>
<td>island</td>
<td>WH.whe.isl.sh.05</td>
<td>0.944204</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>long</td>
<td>non</td>
<td>WH.whe.non.lg.05</td>
<td>0.857106</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>long</td>
<td>island</td>
<td>WH.whe.isl.lg.05</td>
<td>-0.427193</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>We can see (i) that the <code>distance</code>=<code>short</code> items (1-2) are judged to be about as acceptable as each other on average; (ii) that both <code>distance</code>=<code>long</code> items (3-4) are judged worse than both <code>distance</code>=<code>short</code> items on average; and (iii) that the <code>distance</code>=<code>long</code>, <code>structure</code>=<code>island</code> item (4), which is the one that has a dependency crossing an island boundary, is substantially worse than all the others on average. It is this sort of difference of differences that <span class="citation" data-cites="sprouse_experimental_2016">Sprouse et al. (<a href="#ref-sprouse_experimental_2016" role="doc-biblioref">2016</a>)</span> take as evidence for the influence of a “grammar” component over and above a “sentence processing” component–in the senses put forth by <span class="citation" data-cites="sprouse_acceptability_2018">Sprouse (<a href="#ref-sprouse_acceptability_2018" role="doc-biblioref">2018</a>)</span>.</p>
<div class="cell" data-tags="[]" data-execution_count="65">
<div class="sourceCode cell-code" id="cb8" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>data_test <span class="op">=</span> data.query(<span class="st">"distance != 'filler'"</span>)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>data_test_itemmeans <span class="op">=</span> data_test.groupby(</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>    factors <span class="op">+</span> [<span class="st">"item"</span>]</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>)[[<span class="st">"zscores"</span>]].mean().reset_index()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-tags="[]" data-execution_count="66">
<details>
<summary>Plotting code</summary>
<div class="sourceCode cell-code" id="cb9" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> seaborn <span class="im">import</span> FacetGrid, boxplot</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> FacetGrid(</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>    data_test_itemmeans,</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>    col<span class="op">=</span><span class="st">"island"</span>, row<span class="op">=</span><span class="st">"dependency"</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>p.<span class="bu">map</span>(</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>    boxplot, </span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">"distance"</span>, <span class="st">"zscores"</span>, <span class="st">"structure"</span>, </span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>    order<span class="op">=</span>[<span class="st">"short"</span>, <span class="st">"long"</span>], </span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>    hue_order<span class="op">=</span>[<span class="st">"non"</span>, <span class="st">"island"</span>]</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>p.set_ylabels(<span class="vs">r"Mean $z$-score of item"</span>)</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> p.add_legend()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="model-definition_files/figure-html/cell-9-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>In asking whether these data provide evidence for a categorical grammar or a gradient grammar, we are effectively asking whether the pattern of difference of differences across combinations of dependency type and island type are better explained as the product of a representation of the combination <span class="math inline">\(d\)</span> and <span class="math inline">\(i\)</span>–i.e.&nbsp;the <em>interaction of</em> <span class="math inline">\(d\)</span> and <span class="math inline">\(i\)</span>–that assumes a categorical grammar or a gradient grammar.</p>
<div class="cell" data-tags="[]" data-execution_count="67">
<div class="sourceCode cell-code" id="cb10" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>data_test_itemmeans[<span class="st">"itemnum"</span>] <span class="op">=</span> data_test_itemmeans.item.<span class="bu">map</span>(</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">lambda</span> x: x.split(<span class="st">"."</span>)[<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>data_test_itemmeans_cast <span class="op">=</span> data_test_itemmeans.pivot_table(</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>    index<span class="op">=</span>[<span class="st">"island"</span>, <span class="st">"dependency"</span>, <span class="st">"itemnum"</span>], </span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>    columns<span class="op">=</span>[<span class="st">"distance"</span>, <span class="st">"structure"</span>], </span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>    values<span class="op">=</span><span class="st">"zscores"</span></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>short_diffs <span class="op">=</span> data_test_itemmeans_cast.short.non <span class="op">-\</span></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>              data_test_itemmeans_cast.short.island</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>long_diffs <span class="op">=</span> data_test_itemmeans_cast.<span class="bu">long</span>.non <span class="op">-\</span></span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>             data_test_itemmeans_cast.<span class="bu">long</span>.island</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>diffs_of_diffs <span class="op">=</span> (short_diffs <span class="op">-</span> long_diffs).reset_index()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-tags="[]" data-execution_count="68">
<details>
<summary>Plotting code</summary>
<div class="sourceCode cell-code" id="cb11" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> boxplot(</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>    diffs_of_diffs,</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>    x<span class="op">=</span><span class="st">"island"</span>, y<span class="op">=</span><span class="dv">0</span>, hue<span class="op">=</span><span class="st">"dependency"</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> p.set_ylabel(<span class="st">"Difference of differences by item"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="model-definition_files/figure-html/cell-11-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>In terms solely of fit, the answer here <em>must</em> be that the best-fitting gradient model will always fit the data as well or better than the analogous best-fitting categorical model. (We’ll see why shortly.) The question is whether, once we consider the improved parsimony of the categorical family, the best-fitting categorical model is comparable to the gradient model.</p>
</section>
</section>
<section id="formalizing-the-model-families" class="level2">
<h2 class="anchored" data-anchor-id="formalizing-the-model-families">Formalizing the model families</h2>
<p>Let’s consider what a categorical family is committed to in contrast to a gradient model. To do this, we need to back up and talk about how to model what <span class="citation" data-cites="sprouse_acceptability_2018">Sprouse (<a href="#ref-sprouse_acceptability_2018" role="doc-biblioref">2018, 197</a>)</span> refers to as “the continuum of acceptability”. We’ll assume that the acceptability <span class="math inline">\(\alpha_i\)</span> of some natural language string <span class="math inline">\(i\)</span> can be represented by a real value (viewed as an element of an <a href="https://en.wikipedia.org/wiki/Ordered_field">ordered field</a>). This assumption is relatively uncontroversial: even those researchers committed to some form of discreteness in the “grammar” component of the theory of acceptability assume the existence of processes that should be modeled as gradient–at least as a first pass.</p>
<p>The first thing we need to do is to figure out how to model the relationship between <span class="math inline">\(\alpha_i\)</span>–however it is determined–and the set of judgments for that item <span class="math inline">\(\{y_n \mid \text{item}(n) = i\}\)</span>, where <span class="math inline">\(\text{item}\)</span> maps a response index to an item identifier. We’ll refer to this component of our model as our <em>linking model</em>. How we define this model is important because <em>we do not directly observe</em> the true acceptability represented by <span class="math inline">\(\alpha_i\)</span>; we must estimate it from the responses.<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a></p>
<section id="the-ordinal-logit-linking-model" class="level3">
<h3 class="anchored" data-anchor-id="the-ordinal-logit-linking-model">The Ordinal Logit Linking Model</h3>
<p>To model ordinal responses <span class="math inline">\(y_n\)</span>, we will use an <a href="https://en.wikipedia.org/wiki/Ordered_logit">ordered logit model</a>, which will be parameterized by our real-valued <span class="math inline">\(\alpha_{\text{item}(n)}\)</span> and <span class="math inline">\(K \equiv r_\text{max} - r_\text{min}\)</span> <em>cutpoints</em> <span class="math inline">\(\mathbf{c}_{\text{subj}(n)}\)</span> specific to each subject, where <span class="math inline">\(r_\text{max}\)</span> is the highest rating–7 in the Sprouse et al.&nbsp;data–and <span class="math inline">\(r_\text{min}\)</span> is the lowest–1 in the Sprouse et al.&nbsp;data.<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a> Let’s assume that <span class="math inline">\(c_{sr_\text{min}} \sim \mathcal{N}(0, \sigma^2_\text{cutpoint})\)</span> and that:</p>
<p><span class="math display">\[C_{s(r+1)} - C_{sr} \sim \text{Gamma}(2, 1)\]</span></p>
<p>We want a distribution–like the <a href="https://en.wikipedia.org/wiki/Gamma_distribution">gamma distribution</a>–on distances between cutpoints that has only positive support so that we can enforce a strict ordering assumption: <span class="math inline">\(\forall r \in \{r_\text{min}, \ldots, r_\text{max}\}: c_{sr} &lt; c_{s(r+1)}\)</span>. Any distribution with positive support would work here.</p>
<div class="cell" data-tags="[]" data-execution_count="11">
<div class="sourceCode cell-code" id="cb12" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> gamma</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="co"># uses the k, theta (scale) parameterization</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>cutpoint_distance_dist <span class="op">=</span> gamma(<span class="fl">2.0</span>, scale<span class="op">=</span><span class="fl">1.</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-tags="[]" data-code-comment="Plotting code" data-execution_count="69">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb13" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> numpy <span class="im">import</span> mgrid</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib.pyplot <span class="im">import</span> subplot</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> subplot()</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>distance <span class="op">=</span> mgrid[<span class="dv">0</span>:<span class="dv">10</span>:<span class="fl">0.01</span>]</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>density <span class="op">=</span> cutpoint_distance_dist.pdf(distance)</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>ax.plot(distance, density)</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="vs">r"PDF of the cutpoint distance prior distribution"</span>)</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="vs">r"Distance"</span>)</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> ax.set_ylabel(<span class="st">"Density"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="model-definition_files/figure-html/cell-13-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>The reason why we want a strict ordering assumption is that we’re going to use these <span class="math inline">\(K=6\)</span> cutpoints to define <span class="math inline">\(K+1 = 7\)</span> bins <span class="math inline">\(\{(-\infty, c_{sr_\text{min}}), (c_{sr_\text{min}}, c_{sr_\text{min} + 1}), \ldots, (c_{sr_\text{max}-2}, c_{sr_\text{max}-1}), (c_{sr_\text{max}-1}, \infty)\}\)</span> of contiguous real values. Each bin will correspond to a possible rating <span class="math inline">\(\{r_\text{min}, \ldots, r_\text{max}\}\)</span>.</p>
<div class="cell" data-tags="[]" data-execution_count="13">
<div class="sourceCode cell-code" id="cb14" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> numpy <span class="im">import</span> sort</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> numpy.random <span class="im">import</span> seed</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>seed(<span class="dv">302984</span>)</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>n_resp_levels <span class="op">=</span> <span class="dv">7</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>jumps <span class="op">=</span> cutpoint_distance_dist.rvs(n_resp_levels<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>cutpoints <span class="op">=</span> jumps.cumsum()</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>cutpoints <span class="op">-=</span> cutpoints.<span class="bu">min</span>()</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>cutpoints</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<pre data-code-line-numbers=""><code>array([ 0.        ,  3.01509045,  5.3033194 ,  8.44799298, 13.82188812,
       14.96264086])</code></pre>
</div>
</div>
<div class="cell" data-tags="[]" data-code-comment="Plotting code" data-execution_count="14">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb16" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> numpy <span class="im">import</span> ndarray</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_cutpoints(ax, cutpoints: ndarray, ymin: <span class="bu">float</span> <span class="op">=</span> <span class="dv">0</span>, ymax: <span class="bu">float</span> <span class="op">=</span> <span class="dv">1</span>) <span class="op">-&gt;</span> <span class="va">None</span>:</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>    ax.axis(xmin<span class="op">=</span>cutpoints[<span class="dv">0</span>] <span class="op">-</span> <span class="dv">2</span>, xmax<span class="op">=</span>cutpoints[<span class="op">-</span><span class="dv">1</span>] <span class="op">+</span> <span class="dv">2</span>)</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>    ax.vlines(cutpoints, ymin, ymax, colors<span class="op">=</span><span class="st">"C1"</span>)</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>    height <span class="op">=</span> (ymax <span class="op">+</span> ymin) <span class="op">/</span> <span class="dv">2</span></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, c_i <span class="kw">in</span> <span class="bu">enumerate</span>(cutpoints):</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> i:</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>            _ <span class="op">=</span> ax.annotate(</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>                i <span class="op">+</span> <span class="dv">1</span>,</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>                xy<span class="op">=</span>((c_i <span class="op">+</span> cutpoints[i<span class="op">-</span><span class="dv">1</span>]) <span class="op">/</span> <span class="dv">2</span>, height), xycoords<span class="op">=</span><span class="st">'data'</span>,</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>                horizontalalignment<span class="op">=</span><span class="st">'center'</span>, verticalalignment<span class="op">=</span><span class="st">'top'</span>,</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>                fontsize<span class="op">=</span><span class="dv">20</span>,</span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> <span class="kw">not</span> i:</span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>            _ <span class="op">=</span> ax.annotate(</span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>                i <span class="op">+</span> <span class="dv">1</span>,</span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a>                xy<span class="op">=</span>((c_i <span class="op">-</span> <span class="dv">1</span>), height), xycoords<span class="op">=</span><span class="st">'data'</span>,</span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>                horizontalalignment<span class="op">=</span><span class="st">'center'</span>, verticalalignment<span class="op">=</span><span class="st">'top'</span>,</span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>                fontsize<span class="op">=</span><span class="dv">20</span></span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a>    _ <span class="op">=</span> ax.annotate(</span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a>        cutpoints.shape[<span class="dv">0</span>] <span class="op">+</span> <span class="dv">1</span>,</span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a>        xy<span class="op">=</span>((cutpoints[<span class="op">-</span><span class="dv">1</span>] <span class="op">+</span> <span class="dv">1</span>), height), xycoords<span class="op">=</span><span class="st">'data'</span>,</span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a>        horizontalalignment<span class="op">=</span><span class="st">'center'</span>, verticalalignment<span class="op">=</span><span class="st">'top'</span>,</span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a>        fontsize<span class="op">=</span><span class="dv">20</span></span>
<span id="cb16-30"><a href="#cb16-30" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb16-31"><a href="#cb16-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-32"><a href="#cb16-32" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> subplot()</span>
<span id="cb16-33"><a href="#cb16-33" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-34"><a href="#cb16-34" aria-hidden="true" tabindex="-1"></a>plot_cutpoints(ax, cutpoints)</span>
<span id="cb16-35"><a href="#cb16-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-36"><a href="#cb16-36" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">"Binning of acceptability space"</span>)</span>
<span id="cb16-37"><a href="#cb16-37" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> ax.set_xlabel(<span class="st">"Acceptability"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="model-definition_files/figure-html/cell-15-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>What makes this model an ordered <em>logistic</em> model is its assumptions about how randomness in the responses comes about: namely, that participants produce the ordinal value <span class="math inline">\(y_n\)</span> corresponding to the bin in which <span class="math inline">\(\alpha_{\text{item}(n)} + \epsilon_n\)</span> falls, where <span class="math inline">\(\epsilon_n \sim \text{Logistic}(0, 1)\)</span> is an error term distributed <a href="https://en.wikipedia.org/wiki/Logistic_distribution">logistic</a>. That is, the PDF of <span class="math inline">\(\epsilon_n\)</span> is:</p>
<p><span class="math display">\[f(x) = \frac {e^{-x}}{\left(1+e^{-x}\right)^{2}}\]</span></p>
<div class="cell" data-tags="[]" data-execution_count="15">
<div class="sourceCode cell-code" id="cb17" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> logistic</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-tags="[]" data-code-comment="Plotting code" data-execution_count="16">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb18" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> subplot()</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>logodds <span class="op">=</span> mgrid[<span class="op">-</span><span class="dv">5</span>:<span class="dv">5</span>:<span class="fl">0.01</span>]</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>density <span class="op">=</span> logistic(<span class="dv">0</span>, <span class="dv">1</span>).pdf(mgrid[<span class="op">-</span><span class="dv">5</span>:<span class="dv">5</span>:<span class="fl">0.01</span>])</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>ax.plot(logodds, density)</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="vs">r"PDF of the standard logistic distribution"</span>)</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="vs">r"Error"</span>)</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> ax.set_ylabel(<span class="st">"Density"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="model-definition_files/figure-html/cell-17-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>For instance, if we simulate multiple draws for a <span class="math inline">\(Y_n\)</span> whose <span class="math inline">\(\alpha_{\text{item}(n)}\)</span> is in the center of the bin for response 4 and whose cutpoints <span class="math inline">\(\mathbf{c}_{\text{subj}(n)}\)</span> are the ones we sampled above…</p>
<div class="cell" data-tags="[]" data-execution_count="17">
<div class="sourceCode cell-code" id="cb19" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>seed(<span class="dv">3029</span>)</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>mu_n <span class="op">=</span> (cutpoints[<span class="dv">3</span>] <span class="op">+</span> cutpoints[<span class="dv">2</span>]) <span class="op">/</span> <span class="dv">2</span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>samples <span class="op">=</span> mu_n <span class="op">+</span> logistic(<span class="dv">0</span>, <span class="dv">1</span>).rvs(<span class="dv">10_000</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-tags="[]" data-code-comment="Plotting code" data-execution_count="19">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb20" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> subplot()</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>plot_cutpoints(ax, cutpoints, <span class="dv">0</span>, <span class="fl">0.25</span>)</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> ax.hist(samples, density<span class="op">=</span><span class="va">True</span>, bins<span class="op">=</span><span class="dv">20</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="model-definition_files/figure-html/cell-19-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>…we obtain a frequency distribution that peaks at 4, since <span class="math inline">\(\alpha_{\text{item}(n)} + \epsilon_n\)</span> has most density within <span class="math inline">\((c_{{\text{subj}(n)}, 3}, c_{{\text{subj}(n)}, 4})\)</span>, but where there are a fair number of 3s and 5s, since those value have a fair amount of density.</p>
<div class="cell" data-tags="[]" data-execution_count="20">
<div class="sourceCode cell-code" id="cb21" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>responses <span class="op">=</span> (samples[:,<span class="va">None</span>] <span class="op">&gt;</span> cutpoints[<span class="va">None</span>,:]).<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">1</span>) <span class="op">+</span> <span class="dv">1</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-tags="[]" data-code-comment="Plotting code" data-execution_count="22">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb22" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> subplot()</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> ax.hist(responses, bins<span class="op">=</span>arange(<span class="dv">1</span>, <span class="dv">9</span>), rwidth<span class="op">=</span><span class="fl">0.5</span>, align<span class="op">=</span><span class="st">"left"</span>, density<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="vs">r"Relative frequency of response in simulation"</span>)</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="vs">r"Response"</span>)</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> ax.set_ylabel(<span class="st">"Relative Frequency"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="model-definition_files/figure-html/cell-21-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>We will express that <span class="math inline">\(Y_n\)</span> is distributed ordered logistic with:</p>
<p><span class="math display">\[
\begin{align*}
Y_n &amp;\sim \text{OrderedLogistic}\left(\alpha_{\text{item}(n)}, \mathbf{c}_{\text{subj}(n)}\right)\\
\end{align*}
\]</span></p>
<p>To make the notation a bit less complex moving forward, I’m going to write <span class="math inline">\(\alpha_i\)</span>–rather than <span class="math inline">\(\alpha_{\text{item}(n)}\)</span> and <span class="math inline">\(\mathbf{c}_s\)</span>–rather than <span class="math inline">\(\mathbf{c}_{\text{subj}(n)}\)</span>–leaving implicit the statements “where <span class="math inline">\(i \equiv \text{item}(n)\)</span>” and “where <span class="math inline">\(s \equiv \text{subj}(n)\)</span>”.</p>
<p>The way of thinking about <span class="math inline">\(Y_n\)</span> described above effectively defines the PMF in terms of an expectation of <span class="math inline">\(\epsilon_n\)</span>–which, remember, is a random variable. To make things a bit simpler, let’s assume we’re working with the <a href="https://en.wikipedia.org/wiki/Extended_real_number_line">extended reals</a>, so we can say that <span class="math inline">\(c_{s(r_\text{min}-1)} = -\infty\)</span> and that <span class="math inline">\(c_{sr_\text{max}} = +\infty\)</span> for all subjects <span class="math inline">\(s\)</span>. Then, for <span class="math inline">\(r \in \{r_\text{min}, \ldots, r_\text{max}\}\)</span>:</p>
<p><span class="math display">\[\begin{align*}
\mathbb{P}(Y_n=r\mid\alpha_i, \mathbf{c}_s) &amp;= \int_\mathbb{R} f(e)\mathbb{P}(Y_n=r\mid\alpha_i, \mathbf{c}_s,e) \,\mathrm{d}e\\
&amp;= \int_\mathbb{R} f(e)\mathbb{P}\left(\alpha_i+e \in (c_{s(r-1)}, c_{sr})\right)\,\mathrm{d}e\\
&amp;= \int_\mathbb{R} f(e)\mathbb{P}\left(e \in (c_{s(r-1)} - \alpha_i, c_{sr} - \alpha_i)\right)\\
&amp;= \mathbb{E}\left[\mathbb{P}\left(\epsilon_n \in (c_{s(r-1)} - \alpha_i, c_{sr} - \alpha_i)\right)\right]\\
\end{align*}\]</span></p>
<p>This expression looks a bit hairy, but it turns out that we can express the PMF of <span class="math inline">\(Y_n\)</span> analytically. To do this, we first need to note that, for a fixed <span class="math inline">\(e\)</span>:</p>
<p><span class="math display">\[\begin{align*}
\mathbb{P}\left(e \in (c_{s(r-1)} - \alpha_i, c_{sr} - \alpha_i)\right) &amp;= F(c_{sr} - \alpha_i) - F(c_{s(r-1)} - \alpha_i)\\
&amp;= \text{logit}^{-1}(c_{sr} - \alpha_i) - \text{logit}^{-1}(c_{s(r-1)} - \alpha_i)
\end{align*}\]</span></p>
<p>where <span class="math inline">\(F(x) = \text{logit}^{-1}(x) = \frac{1}{1 + \exp(-x)}\)</span> is the CDF of the standard logistic distribution.</p>
<p>This function is also often called the inverse logit, logistic, or expit function. It can be viewed as mapping a log-odds to a probability. You may be familiar with it in the context of <a href="https://en.wikipedia.org/wiki/Logistic_regression">logistic regression</a>, where we model the conditional expectation <span class="math inline">\(\text{logit}\;\mathbb{E}[Y \mid \mathbf{X}]\)</span> of a Bernoulli random variable <span class="math inline">\(Y\)</span>–e.g.&nbsp;a variable indicating whether a sentence is <em>acceptable</em> or <em>unacceptable</em>–given some predictors <span class="math inline">\(\mathbf{X}\)</span>–e.g.&nbsp;<code>dependency</code>, <code>island</code>, <code>structure</code>, and <code>distance</code> from Sprouse et al.’s dataset.</p>
<div class="cell" data-tags="[]" data-execution_count="23">
<div class="sourceCode cell-code" id="cb23" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.special <span class="im">import</span> expit</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-tags="[]" data-code-comment="Plotting code" data-execution_count="24">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb24" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> subplot()</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>logodds <span class="op">=</span> mgrid[<span class="op">-</span><span class="dv">5</span>:<span class="dv">5</span>:<span class="fl">0.01</span>]</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>probability <span class="op">=</span> expit(mgrid[<span class="op">-</span><span class="dv">5</span>:<span class="dv">5</span>:<span class="fl">0.01</span>])</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>ax.plot(logodds, probability)</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="vs">r"The logistic function $\frac</span><span class="sc">{1}</span><span class="vs">{1+\exp(-x)}$"</span>)</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="vs">r"Log-odds $\log\frac</span><span class="sc">{p}</span><span class="vs">{1-p}$"</span>)</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> ax.set_ylabel(<span class="st">"Probability"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="model-definition_files/figure-html/cell-23-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>Thus, <span class="math inline">\(\mathbb{E}\left[\mathbb{P}\left(\epsilon_n \in (c_{s(r-1)} - \alpha_i, c_{sr} - \alpha_i)\right)\right]\)</span> is actually the expected value of a constant <span class="math inline">\(\text{logit}^{-1}(c_{sr} - \alpha_i) - \text{logit}^{-1}(c_{s(r-1)} - \alpha_i)\)</span> (relative to <span class="math inline">\(\epsilon_n\)</span>), which means that, for <span class="math inline">\(r \in \{r_\text{min}, \ldots, r_\text{max}\}\)</span>:</p>
<p><span class="math display">\[\mathbb{P}(Y_n=r\mid\alpha_i, \mathbf{c}_s) = \text{logit}^{-1}(c_{sr} - \alpha_i) - \text{logit}^{-1}(c_{s(r-1)} - \alpha_i)\]</span></p>
<p>More explicitly, the PMF of <span class="math inline">\(Y_n\)</span> is:</p>
<p><span class="math display">\[\mathbb{P}(Y_n = r \mid \alpha_i, \mathbf{c}_s) = \begin{cases}
\text{logit}^{-1}(c_{sr} - \alpha_i) &amp; \text{if } r = r_\text{min}\\
\text{logit}^{-1}(c_{sr} - \alpha_i) - \text{logit}^{-1}(c_{s(r-1)} - \alpha_i) &amp; \text{if } r_\text{min} &lt; r &lt; r_\text{max}\\
1 - \text{logit}^{-1}(c_{s(r-1)} - \alpha_i) &amp; \text{if } r = r_\text{max}\\
0 &amp; \text{otherwise}\\
\end{cases}\]</span></p>
<p>We commonly compute this by first computing the CDF and then taking the cumulative difference.</p>
<p><span class="math display">\[\mathbb{P}(Y_n \leq r \mid \alpha_i, \mathbf{c}_s) = \begin{cases}
0 &amp; \text{if } r &lt; r_\text{min}\\
\text{logit}^{-1}(c_{sr} - \alpha_i) &amp; \text{if } r &lt; r_\text{max}\\
1 &amp; \text{if } r \geq r_\text{max}\\
\end{cases}\]</span></p>
<div class="cell" data-tags="[]" data-execution_count="25">
<div class="sourceCode cell-code" id="cb25" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> numpy <span class="im">import</span> concatenate, ones, zeros, arange</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> ordinal_pmf(mu: ndarray, cutpoints: ndarray):</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>    n, <span class="op">=</span> mu.shape</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>    cdf <span class="op">=</span> expit(cutpoints[<span class="va">None</span>,:] <span class="op">-</span> mu[:,<span class="va">None</span>])</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> concatenate([cdf, ones([n, <span class="dv">1</span>])], axis<span class="op">=</span><span class="dv">1</span>) <span class="op">-\</span></span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>           concatenate([zeros([n, <span class="dv">1</span>]), cdf], axis<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>If we compute the PMF for the value of <span class="math inline">\(\alpha_i\)</span> we simulated against above, we get something very close to the relative frequency distribution we observed before.</p>
<div class="cell" data-tags="[]" data-code-comment="Plotting code" data-execution_count="26">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb26" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> subplot()</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>ax.bar(arange(<span class="dv">1</span>, <span class="dv">8</span>), ordinal_pmf(mu_n<span class="op">*</span>ones(<span class="dv">1</span>), cutpoints)[<span class="dv">0</span>], <span class="fl">0.5</span>)</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="vs">r"Probability mass function of ordinal logistic"</span>)</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="vs">r"Response"</span>)</span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> ax.set_ylabel(<span class="st">"Probability"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="model-definition_files/figure-html/cell-25-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>If we sweep the value of <span class="math inline">\(\alpha_i\)</span> relative to the set of cutpoints we sampled above, then plot the resulting PMF, the ordinal constraints on the distribution become apparent. Also notice that for 6, which has a very small bin relative to the other responses, no setting of <span class="math inline">\(\alpha_i\)</span> gives it a very high probability.</p>
<div class="cell" data-tags="[]" data-code-comment="Plotting code" data-execution_count="35">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb27" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib.pyplot <span class="im">import</span> subplots</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>pmfs <span class="op">=</span> ordinal_pmf(arange(<span class="op">-</span><span class="dv">1</span>, <span class="dv">20</span>), cutpoints)</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> subplots(figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">8</span>))</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>img <span class="op">=</span> ax.imshow(pmfs)</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>ax.set_xticks(arange(<span class="dv">7</span>), arange(<span class="dv">1</span>,<span class="dv">8</span>))</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">"Rating"</span>)</span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">"Value"</span>)</span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>img.set_cmap(<span class="st">'binary'</span>)</span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> fig.colorbar(img, label<span class="op">=</span><span class="st">"Probability"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="model-definition_files/figure-html/cell-26-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>Thus, the ordinal logistic model allows us to capture preference or dispreference for a particular response level by manipulating the bin size associated with that level. This manipulation of the bin size is how we model subjects’ preferences for particular bins. For instance, the subject we simulated above has a fairly strong dispreference for using a 6 response, which is a consequence of how small the bin for 6 is and which can be seen in the fact that no row of the above plot is particularly dark for 6.</p>
<p>There are many ways to set up the distribution on subject-specific cutpoints. In the current context, we are going to assume a general set of cutpoints <span class="math inline">\(\bar{\mathbf{c}}\)</span> that subjects rigidly shift left or right via a subject-specific intercept term <span class="math inline">\(\rho^\text{subj}_s \sim \mathcal{N}\left(0, \sigma^2_\text{subj}\right)\)</span>. That is, <span class="math inline">\(\mathbf{c}_s \equiv \bar{\mathbf{c}} + \rho^\text{subj}_s\)</span>–holding all assumptions above fixed. This assumption is fairly standard and the default in libraries like <a href="https://rdrr.io/cran/ordinal/"><code>ordinal</code></a>. An alternative assumption, which we will make later in the course, is that that subjects’ cutpoints <span class="math inline">\(\mathbf{c}_s\)</span> can freely vary–allowing different subjects to have different preferences for different ordinal responses.</p>
</section>
<section id="a-first-poor-approximation" class="level3">
<h3 class="anchored" data-anchor-id="a-first-poor-approximation">A First (Poor) Approximation</h3>
<p>Given the above setup, the simplest model we might define is one in which every item is equally acceptable and all the variability in responses is modeled by the error term and variability in how subjects bin the continuum of acceptability. That is, there is a single <span class="math inline">\(\mu\)</span> such that <span class="math inline">\(\alpha_i \equiv \mu\)</span>. This model is effectively a <a href="https://en.wikipedia.org/wiki/Random_effects_model">random effects model</a>, where the subject-specific intercepts <span class="math inline">\(\rho^\text{subj}_s\)</span> are the random effects.</p>
<p>We’ll use STAN to implement this model. You can find a very brief introduction to STAN <a href="../foundational-concepts-in-probability-and-statistics/statistical-inference.html#implementing-samplers-in-stan">here</a> in the course notes on <a href="../foundational-concepts-in-probability-and-statistics/statistical inference">statistical inference</a>.</p>
<p>The <code>data</code> block needs to specify information about both the responses and the subjects.</p>
<div class="sourceCode" id="cb28" data-startfrom="1" data-code-line-numbers=""><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="kw">data</span> {</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; N_resp;                           <span class="co">// number of responses</span></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; N_subj;                           <span class="co">// number of subjects</span></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">2</span>&gt; N_resp_levels;                    <span class="co">// number of possible likert scale acceptability judgment responses</span></span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">1</span>,<span class="kw">upper</span>=N_subj&gt; subj[N_resp];        <span class="co">// subject who gave response n</span></span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">1</span>,<span class="kw">upper</span>=N_resp_levels&gt; resp[N_resp]; <span class="co">// likert scale acceptability judgment responses </span></span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>We will have three (sets of) parameters:</p>
<ol type="1">
<li>the fixed representation of acceptability for every item <code>acc_mean</code></li>
<li>the standard deviation of the subject random intercepts <code>subj_intercept_std</code> and the <code>subj_intercepts</code> themselves</li>
<li>the distances (“<code>jumps</code>”) between cutpoints</li>
</ol>
<div class="sourceCode" id="cb29" data-startfrom="9" data-code-line-numbers=""><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan" style="counter-reset: source-line 8;"><span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a><span class="kw">parameters</span> {</span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span> acc_mean;                                 <span class="co">// mean acceptability</span></span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; subj_intercept_std;              <span class="co">// subject random intercept standard deviation</span></span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>[N_subj] subj_intercept;                 <span class="co">// subject random intercepts</span></span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt;[N_resp_levels<span class="dv">-2</span>] jumps;        <span class="co">// the cutpoint distances</span></span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>To enforce the prior on the distances between cutpoints–henceforth referred to as <code>jumps</code>–it will be useful to define them in <code>transformed parameters</code>.</p>
<div class="sourceCode" id="cb30" data-startfrom="16" data-code-line-numbers=""><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan" style="counter-reset: source-line 15;"><span id="cb30-16"><a href="#cb30-16" aria-hidden="true" tabindex="-1"></a><span class="kw">transformed parameters</span> {</span>
<span id="cb30-17"><a href="#cb30-17" aria-hidden="true" tabindex="-1"></a>  <span class="co">// compute the cutpoints by taking a cumulative sum</span></span>
<span id="cb30-18"><a href="#cb30-18" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>[N_resp_levels<span class="dv">-1</span>] cutpoints;</span>
<span id="cb30-19"><a href="#cb30-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-20"><a href="#cb30-20" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (c <span class="cf">in</span> <span class="dv">1</span>:(N_resp_levels<span class="dv">-1</span>)) {</span>
<span id="cb30-21"><a href="#cb30-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (c == <span class="dv">1</span>) {</span>
<span id="cb30-22"><a href="#cb30-22" aria-hidden="true" tabindex="-1"></a>      cutpoints[c] = <span class="fl">0.0</span>;</span>
<span id="cb30-23"><a href="#cb30-23" aria-hidden="true" tabindex="-1"></a>    } <span class="cf">else</span> {</span>
<span id="cb30-24"><a href="#cb30-24" aria-hidden="true" tabindex="-1"></a>      cutpoints[c] = cutpoints[c<span class="dv">-1</span>] + jumps[c<span class="dv">-1</span>];</span>
<span id="cb30-25"><a href="#cb30-25" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb30-26"><a href="#cb30-26" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb30-27"><a href="#cb30-27" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The <code>model</code> block then encodes the distributional assumptions about the subject random intercepts and cutpoints mentioned above, as well as the assumption that <code>resp[n]</code> <span class="math inline">\(\sim \text{OrderedLogistic}(\)</span> <code>mu</code>, <code>cutpoints + subj_intercept[subj[n]]</code><span class="math inline">\()\)</span>.</p>
<div class="sourceCode" id="cb31" data-startfrom="29" data-code-line-numbers=""><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan" style="counter-reset: source-line 28;"><span id="cb31-29"><a href="#cb31-29" aria-hidden="true" tabindex="-1"></a><span class="kw">model</span> {</span>
<span id="cb31-30"><a href="#cb31-30" aria-hidden="true" tabindex="-1"></a>  <span class="co">// sample the subject intercepts</span></span>
<span id="cb31-31"><a href="#cb31-31" aria-hidden="true" tabindex="-1"></a>  subj_intercept ~ normal(<span class="dv">0</span>, subj_intercept_std);</span>
<span id="cb31-32"><a href="#cb31-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-33"><a href="#cb31-33" aria-hidden="true" tabindex="-1"></a>  <span class="co">// sample the cutpoints distances</span></span>
<span id="cb31-34"><a href="#cb31-34" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">1</span>:(N_resp_levels<span class="dv">-2</span>))</span>
<span id="cb31-35"><a href="#cb31-35" aria-hidden="true" tabindex="-1"></a>    jumps[j] ~ gamma(<span class="dv">2</span>,<span class="dv">1</span>);</span>
<span id="cb31-36"><a href="#cb31-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-37"><a href="#cb31-37" aria-hidden="true" tabindex="-1"></a>  <span class="co">// sample the responses</span></span>
<span id="cb31-38"><a href="#cb31-38" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (n <span class="cf">in</span> <span class="dv">1</span>:N_resp)</span>
<span id="cb31-39"><a href="#cb31-39" aria-hidden="true" tabindex="-1"></a>    resp[n] ~ ordered_logistic(</span>
<span id="cb31-40"><a href="#cb31-40" aria-hidden="true" tabindex="-1"></a>      acc_mean, cutpoints + subj_intercept[subj[n]]</span>
<span id="cb31-41"><a href="#cb31-41" aria-hidden="true" tabindex="-1"></a>    );</span>
<span id="cb31-42"><a href="#cb31-42" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Finally, the <code>generated quantities</code> block computes the log-likelihood of each datapoint (<code>log_lik</code>), which is necessary for model comparison later.</p>
<div class="sourceCode" id="cb32" data-startfrom="43" data-code-line-numbers=""><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan" style="counter-reset: source-line 42;"><span id="cb32-43"><a href="#cb32-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-44"><a href="#cb32-44" aria-hidden="true" tabindex="-1"></a><span class="kw">generated quantities</span> {</span>
<span id="cb32-45"><a href="#cb32-45" aria-hidden="true" tabindex="-1"></a>  <span class="co">// compute the log-likelihood</span></span>
<span id="cb32-46"><a href="#cb32-46" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span> log_lik[N_resp];</span>
<span id="cb32-47"><a href="#cb32-47" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb32-48"><a href="#cb32-48" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (n <span class="cf">in</span> <span class="dv">1</span>:N_resp)</span>
<span id="cb32-49"><a href="#cb32-49" aria-hidden="true" tabindex="-1"></a>    log_lik[n] = ordered_logistic_lpmf(</span>
<span id="cb32-50"><a href="#cb32-50" aria-hidden="true" tabindex="-1"></a>      resp[n] | acc_mean, cutpoints + subj_intercept[subj[n]]</span>
<span id="cb32-51"><a href="#cb32-51" aria-hidden="true" tabindex="-1"></a>    );</span>
<span id="cb32-52"><a href="#cb32-52" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="a-second-slightly-less-poor-approximation" class="level3">
<h3 class="anchored" data-anchor-id="a-second-slightly-less-poor-approximation">A Second (Slightly Less Poor) Approximation</h3>
<p>A better version of this model adds item-specific random intercepts <span class="math inline">\(\rho^\text{item}_i \sim \mathcal{N}\left(0, \sigma^2_\text{item}\right)\)</span> that allow us to better predict the distribution of responses for a particular item. The main change is to define the distribution on responses as:</p>
<p><span class="math display">\[Y_n \sim \text{OrderedLogistic}\left(\alpha_{\text{item}(n)} + \rho^\text{item}_{\text{item}(n)}, \mathbf{c} + \rho^\text{subj}_{\text{subj}(n)}\right)\]</span></p>
<p>To implement this model, we need to add item identity information to the <code>data</code> block.</p>
<div class="sourceCode" id="cb33" data-source-line-numbers="3,6" data-startfrom="1" data-code-line-numbers="3,6"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="kw">data</span> {</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; N_resp;                           <span class="co">// number of responses</span></span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; N_item;                           <span class="co">// number of items</span></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; N_subj;                           <span class="co">// number of subjects</span></span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">2</span>&gt; N_resp_levels;                    <span class="co">// number of possible likert scale acceptability judgment responses</span></span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">1</span>,<span class="kw">upper</span>=N_item&gt; item[N_resp];        <span class="co">// item corresponding to response n</span></span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">1</span>,<span class="kw">upper</span>=N_subj&gt; subj[N_resp];        <span class="co">// subject who gave response n</span></span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">1</span>,<span class="kw">upper</span>=N_resp_levels&gt; resp[N_resp]; <span class="co">// likert scale acceptability judgment responses</span></span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>In the <code>parameters</code> block, we need to add the item random intercepts (<code>item_intercept</code> = <span class="math inline">\(\boldsymbol\rho\)</span>) as well as a parameter for their prior (<code>item_intercept_std</code> = <span class="math inline">\(\sigma_\text{item}\)</span>).</p>
<div class="sourceCode" id="cb34" data-source-line-numbers="3-4" data-startfrom="11" data-code-line-numbers="3-4"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan" style="counter-reset: source-line 10;"><span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a><span class="kw">parameters</span> {</span>
<span id="cb34-12"><a href="#cb34-12" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span> acc_mean;                                 <span class="co">// the mean acceptability</span></span>
<span id="cb34-13"><a href="#cb34-13" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; item_intercept_std;              <span class="co">// the item random intercept standard deviation</span></span>
<span id="cb34-14"><a href="#cb34-14" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>[N_item] item_intercept;                 <span class="co">// the item random intercepts</span></span>
<span id="cb34-15"><a href="#cb34-15" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; subj_intercept_std;              <span class="co">// subject random intercept standard deviation</span></span>
<span id="cb34-16"><a href="#cb34-16" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>[N_subj] subj_intercept;                 <span class="co">// subject random intercepts</span></span>
<span id="cb34-17"><a href="#cb34-17" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt;[N_resp_levels<span class="dv">-2</span>] jumps;        <span class="co">// the cutpoint distances</span></span>
<span id="cb34-18"><a href="#cb34-18" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb34-19"><a href="#cb34-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-20"><a href="#cb34-20" aria-hidden="true" tabindex="-1"></a><span class="kw">transformed parameters</span> {</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>In the <code>transformed parameters</code> block, we will define <span class="math inline">\(\alpha_i = \mu + \rho_i\)</span>.</p>
<div class="sourceCode" id="cb35" data-source-line-numbers="11-15" data-startfrom="22" data-code-line-numbers="11-15"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan" style="counter-reset: source-line 21;"><span id="cb35-22"><a href="#cb35-22" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>[N_resp_levels<span class="dv">-1</span>] cutpoints;</span>
<span id="cb35-23"><a href="#cb35-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-24"><a href="#cb35-24" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (c <span class="cf">in</span> <span class="dv">1</span>:(N_resp_levels<span class="dv">-1</span>)) {</span>
<span id="cb35-25"><a href="#cb35-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (c == <span class="dv">1</span>) {</span>
<span id="cb35-26"><a href="#cb35-26" aria-hidden="true" tabindex="-1"></a>      cutpoints[c] = <span class="fl">0.0</span>;</span>
<span id="cb35-27"><a href="#cb35-27" aria-hidden="true" tabindex="-1"></a>    } <span class="cf">else</span> {</span>
<span id="cb35-28"><a href="#cb35-28" aria-hidden="true" tabindex="-1"></a>      cutpoints[c] = cutpoints[c<span class="dv">-1</span>] + jumps[c<span class="dv">-1</span>];</span>
<span id="cb35-29"><a href="#cb35-29" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb35-30"><a href="#cb35-30" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb35-31"><a href="#cb35-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-32"><a href="#cb35-32" aria-hidden="true" tabindex="-1"></a>  <span class="co">// compute the item-specific acceptability</span></span>
<span id="cb35-33"><a href="#cb35-33" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span> acc[N_item];</span>
<span id="cb35-34"><a href="#cb35-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-35"><a href="#cb35-35" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span>:N_item)</span>
<span id="cb35-36"><a href="#cb35-36" aria-hidden="true" tabindex="-1"></a>    acc[i] = acc_mean + item_intercept[i];</span>
<span id="cb35-37"><a href="#cb35-37" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>And finally, in the model block, we state that <code>item_intercept</code> <span class="math inline">\(\sim \mathcal{N}(0,\)</span> <code>item_intercept_std</code> <span class="math inline">\(^2)\)</span> and we update the response distribution to reflect the addition of item-specific random intercepts.</p>
<div class="sourceCode" id="cb36" data-source-line-numbers="2-3,11-16" data-startfrom="39" data-code-line-numbers="2-3,11-16"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan" style="counter-reset: source-line 38;"><span id="cb36-39"><a href="#cb36-39" aria-hidden="true" tabindex="-1"></a><span class="kw">model</span> {  </span>
<span id="cb36-40"><a href="#cb36-40" aria-hidden="true" tabindex="-1"></a>  <span class="co">// sample the item intercepts</span></span>
<span id="cb36-41"><a href="#cb36-41" aria-hidden="true" tabindex="-1"></a>  item_intercept ~ normal(<span class="dv">0</span>, item_intercept_std);</span>
<span id="cb36-42"><a href="#cb36-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-43"><a href="#cb36-43" aria-hidden="true" tabindex="-1"></a>  <span class="co">// sample the subject intercepts</span></span>
<span id="cb36-44"><a href="#cb36-44" aria-hidden="true" tabindex="-1"></a>  subj_intercept ~ normal(<span class="dv">0</span>, subj_intercept_std);</span>
<span id="cb36-45"><a href="#cb36-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-46"><a href="#cb36-46" aria-hidden="true" tabindex="-1"></a>  <span class="co">// sample the cutpoints distances</span></span>
<span id="cb36-47"><a href="#cb36-47" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">1</span>:(N_resp_levels<span class="dv">-2</span>))</span>
<span id="cb36-48"><a href="#cb36-48" aria-hidden="true" tabindex="-1"></a>    jumps[j] ~ gamma(<span class="dv">2</span>,<span class="dv">1</span>);</span>
<span id="cb36-49"><a href="#cb36-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-50"><a href="#cb36-50" aria-hidden="true" tabindex="-1"></a>  <span class="co">// sample the responses</span></span>
<span id="cb36-51"><a href="#cb36-51" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (n <span class="cf">in</span> <span class="dv">1</span>:N_resp)</span>
<span id="cb36-52"><a href="#cb36-52" aria-hidden="true" tabindex="-1"></a>    resp[n] ~ ordered_logistic(</span>
<span id="cb36-53"><a href="#cb36-53" aria-hidden="true" tabindex="-1"></a>      acc[item[n]], cutpoints + subj_intercept[subj[n]]</span>
<span id="cb36-54"><a href="#cb36-54" aria-hidden="true" tabindex="-1"></a>    );</span>
<span id="cb36-55"><a href="#cb36-55" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>As we will see, this model will fit the data much better. But it’s still not a very good model. The reason is that, since the random intercepts are item-specific, the model cannot predict responses to items it hasn’t seen before particularly well. If we have an estimate for a particular participant’s cutpoints, the best we can do is to compute the probability of a particular response by marginalizing over the item-specific random intercepts.</p>
<p><span class="math display">\[\begin{align*}
\mathbb{P}(Y_n = r \mid \mu, \mathbf{c}, \rho^\text{subj}_{\text{subj}(n)}; \sigma_\text{item}) &amp;= \int_\mathbb{R} \mathbb{P}(Y_n = r \mid \mu, \rho)p(\rho; \sigma_\text{item})\,\mathrm{d}\rho\\
&amp;= \int_\mathbb{R} \text{OrderedLogistic}\left(r \mid \mu + \rho, \mathbf{c}_{\text{subj}(n)}\right)\mathcal{N}\left(\rho; 0, \sigma_\text{item}^2\right)\,\mathrm{d}\rho\\
\end{align*}\]</span></p>
</section>
<section id="adding-grammar-and-processing-effects" class="level3">
<h3 class="anchored" data-anchor-id="adding-grammar-and-processing-effects">Adding Grammar and Processing Effects</h3>
<p>To improve the predictive power of our models, we need to add information about properties of the items to our models–e.g.&nbsp;<code>dependency</code>, <code>island</code>, <code>structure</code>, and <code>distance</code>. How we add this information will correspond to the family of models we are fitting. All of these models will be <em>mixed effects models</em> or extensions thereof, so what I want to do now is to define a general mixed effects model. All our models from here on out in this module will use this model or some slight modification of it. To keep with our theme of focusing on the acceptability <span class="math inline">\(\alpha_i\)</span> of a particular item <span class="math inline">\(i\)</span>, I’m going to describe the mixed effects models we use in a slightly non-standard way that will hopefully make clear why we are using them.</p>
<p>We are going to define <span class="math inline">\(\alpha_i\)</span> in terms of some <em>fixed effects</em> <span class="math inline">\(\mathbf{x}^\text{fixed}_i\)</span>–in our case, some subset and/or combination of <code>dependency</code>, <code>island</code>, <code>structure</code>, and <code>distance</code>–as well as item random effects <span class="math inline">\(\mathbf{x}^\text{item}_i\)</span>. We will assume that the fixed effects <span class="math inline">\(\mathbf{x}^\text{fixed}_i\)</span> and <span class="math inline">\(\mathbf{x}^\text{item}_i\)</span> use a <a href="https://stats.oarc.ucla.edu/spss/faq/coding-systems-for-categorical-variables-in-regression-analysis-2/#DUMMYCODING">dummy coding</a> of the variables of interest and that the first element of both is always <span class="math inline">\(1\)</span>. The latter assumption allows us to easily represent an intercept term.</p>
<p>We will say that <span class="math inline">\(\alpha_i\)</span> is a linear function of <span class="math inline">\(\mathbf{x}^\text{fixed}_i\)</span> and <span class="math inline">\(\mathbf{x}^\text{by-item}_i\)</span>:</p>
<p><span class="math display">\[\alpha_i = \mathbf{x}^\text{fixed}_i \cdot \boldsymbol\beta + \mathbf{x}^\text{item}_i \cdot \boldsymbol\rho^\text{item}_i\]</span></p>
<p>where <span class="math inline">\(\boldsymbol\beta \in \mathbb{R}^{K_\text{fixed}}\)</span> is the <em>fixed effect coefficients</em> and <span class="math inline">\(\boldsymbol\rho^\text{item}_i \in \mathbb{R}^{K_\text{item}}\)</span> are the <em>by-item random effect coefficients</em>. The former (<span class="math inline">\(\boldsymbol\beta\)</span>) track the effect on acceptability that a particular aspect of the linguistic expression has in general, while the latter (<span class="math inline">\(\boldsymbol\rho^\text{item}_i\)</span>) track the way in which a particular item modulates these effects. In our case, we will keep the by-item random effect coefficients very simple: they will effectively just be equivalent to the random intercept above–i.e.&nbsp;<span class="math inline">\(\mathbf{x}^\text{item}_i = [1]\)</span> and thus <span class="math inline">\(\rho_{i1}\)</span> is an intercept.</p>
<p>In addition to acceptability <span class="math inline">\(\alpha_{\text{item}(n)}\)</span>, we will assume that the distribution of response <span class="math inline">\(Y_n\)</span> is sensitive to ways that particular participants’ perception of acceptability is modulated by particular properties <span class="math inline">\(\mathbf{x}^\text{subj}_{\text{item}(n)}\)</span> of the item they are rating. As for the fixed effects, <span class="math inline">\(\mathbf{x}^\text{subj}_{\text{item}(n)}\)</span> will be some subset and/or combination of <code>dependency</code>, <code>island</code>, <code>structure</code>, and <code>distance</code>.</p>
<p>We model this modulation in terms of <em>by-subject random effect coefficients</em> <span class="math inline">\(\boldsymbol\rho^\text{item}_s \in \mathbb{R}^{K_\text{subj}}\)</span>, defining the distribution of response <span class="math inline">\(Y_n\)</span> as:</p>
<p><span class="math display">\[Y_n \sim \text{OrderedLogistic}\left(\alpha_{\text{item}(n)} + \mathbf{x}^\text{subj}_{\text{item}(n)} \cdot \boldsymbol\rho^\text{subj}_{\text{subj}(n)}, \mathbf{c}\right)\]</span></p>
<p>This form looks slightly different than what we used for the first two models, but we could just as well have written it:</p>
<p><span class="math display">\[Y_n \sim \text{OrderedLogistic}\left(\alpha_{\text{item}(n)}, \mathbf{c} + \mathbf{x}^\text{subj}_{\text{item}(n)} \cdot \boldsymbol\rho^\text{subj}_{\text{subj}(n)}\right)\]</span></p>
<p>The main difference is that the signs invert: a shift up of the cutpoints is equivalent to a shift down in the acceptability.</p>
<p>To implement a mixed effects model in STAN, we need to add a few things to the <code>data</code> block, specifying how many fixed effect, by-item, and by-subject effects there are and what they are.</p>
<div class="sourceCode" id="cb37" data-source-line-numbers="6-11" data-startfrom="1" data-code-line-numbers="6-11"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="kw">data</span> {</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; N_resp;                           <span class="co">// number of responses</span></span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; N_item;                           <span class="co">// number of items</span></span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; N_subj;                           <span class="co">// number of subjects</span></span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">2</span>&gt; N_resp_levels;                    <span class="co">// number of possible likert scale acceptability judgment responses</span></span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">1</span>&gt; N_fixed;                          <span class="co">// number of fixed predictors</span></span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">1</span>&gt; N_by_subj;                        <span class="co">// number of random by-subject predictors</span></span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">1</span>&gt; N_by_item;                        <span class="co">// number of random by-item predictors</span></span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a>  <span class="dt">matrix</span>[N_resp,N_fixed] fixed_predictors;       <span class="co">// predictors (length and dependency type) including intercept</span></span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a>  <span class="dt">matrix</span>[N_resp,N_by_item] by_item_predictors;   <span class="co">// by-item predictors (length and dependency type) including intercept</span></span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a>  <span class="dt">matrix</span>[N_resp,N_by_subj] by_subj_predictors;   <span class="co">// by-subject predictors (length and dependency type) including intercept</span></span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">1</span>,<span class="kw">upper</span>=N_item&gt; item[N_resp];        <span class="co">// item corresponding to response n</span></span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">1</span>,<span class="kw">upper</span>=N_subj&gt; subj[N_resp];        <span class="co">// subject who gave response n</span></span>
<span id="cb37-14"><a href="#cb37-14" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">1</span>,<span class="kw">upper</span>=N_resp_levels&gt; resp[N_resp]; <span class="co">// likert scale acceptability judgment responses</span></span>
<span id="cb37-15"><a href="#cb37-15" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>We additionally need to add to the <code>parameters</code> block a representation of the fixed effect and augment the by-item and by-subject effects from scalars to vectors, with a corresponding change to covariance matrices.</p>
<div class="sourceCode" id="cb38" data-source-line-numbers="2-6" data-startfrom="17" data-code-line-numbers="2-6"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan" style="counter-reset: source-line 16;"><span id="cb38-17"><a href="#cb38-17" aria-hidden="true" tabindex="-1"></a><span class="kw">parameters</span> {</span>
<span id="cb38-18"><a href="#cb38-18" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>[N_fixed] fixed_coefs;                   <span class="co">// fixed coefficients (including intercept)</span></span>
<span id="cb38-19"><a href="#cb38-19" aria-hidden="true" tabindex="-1"></a>  <span class="dt">cov_matrix</span>[N_by_item] item_cov;                <span class="co">// item random effects covariance  </span></span>
<span id="cb38-20"><a href="#cb38-20" aria-hidden="true" tabindex="-1"></a>  <span class="dt">cov_matrix</span>[N_by_subj] subj_cov;                <span class="co">// subject random effects covariance            </span></span>
<span id="cb38-21"><a href="#cb38-21" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>[N_by_item] by_item_coefs[N_item];       <span class="co">// by-item coefficients (including intercept)</span></span>
<span id="cb38-22"><a href="#cb38-22" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>[N_by_subj] by_subj_coefs[N_subj];       <span class="co">// by-subject coefficients (including intercept)</span></span>
<span id="cb38-23"><a href="#cb38-23" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt;[N_resp_levels<span class="dv">-2</span>] jumps;        <span class="co">// cutpoint distances for each subject</span></span>
<span id="cb38-24"><a href="#cb38-24" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Rather than defining the acceptability by item in the <code>transformed parameters</code> block, it makes more sense to define it for each response, since both item and subject modulate it.</p>
<div class="sourceCode" id="cb39" data-source-line-numbers="12-20" data-startfrom="26" data-code-line-numbers="12-20"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan" style="counter-reset: source-line 25;"><span id="cb39-26"><a href="#cb39-26" aria-hidden="true" tabindex="-1"></a><span class="kw">transformed parameters</span> {</span>
<span id="cb39-27"><a href="#cb39-27" aria-hidden="true" tabindex="-1"></a>  <span class="co">// compute the cutpoints by taking a cumulative sum</span></span>
<span id="cb39-28"><a href="#cb39-28" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>[N_resp_levels<span class="dv">-1</span>] cutpoints;</span>
<span id="cb39-29"><a href="#cb39-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-30"><a href="#cb39-30" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (c <span class="cf">in</span> <span class="dv">1</span>:(N_resp_levels<span class="dv">-1</span>)) {</span>
<span id="cb39-31"><a href="#cb39-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (c == <span class="dv">1</span>) {</span>
<span id="cb39-32"><a href="#cb39-32" aria-hidden="true" tabindex="-1"></a>      cutpoints[c] = <span class="fl">0.0</span>;</span>
<span id="cb39-33"><a href="#cb39-33" aria-hidden="true" tabindex="-1"></a>    } <span class="cf">else</span> {</span>
<span id="cb39-34"><a href="#cb39-34" aria-hidden="true" tabindex="-1"></a>      cutpoints[c] = cutpoints[c<span class="dv">-1</span>] + jumps[c<span class="dv">-1</span>];</span>
<span id="cb39-35"><a href="#cb39-35" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb39-36"><a href="#cb39-36" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb39-37"><a href="#cb39-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-38"><a href="#cb39-38" aria-hidden="true" tabindex="-1"></a>  <span class="co">// compute the acceptability</span></span>
<span id="cb39-39"><a href="#cb39-39" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span> acc[N_resp];</span>
<span id="cb39-40"><a href="#cb39-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-41"><a href="#cb39-41" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (n <span class="cf">in</span> <span class="dv">1</span>:N_resp) {</span>
<span id="cb39-42"><a href="#cb39-42" aria-hidden="true" tabindex="-1"></a>    acc[n] = fixed_predictors[n] * fixed_coefs + </span>
<span id="cb39-43"><a href="#cb39-43" aria-hidden="true" tabindex="-1"></a>             by_item_predictors[n] * by_item_coefs[item[n]] + </span>
<span id="cb39-44"><a href="#cb39-44" aria-hidden="true" tabindex="-1"></a>             by_subj_predictors[n] * by_subj_coefs[subj[n]];</span>
<span id="cb39-45"><a href="#cb39-45" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb39-46"><a href="#cb39-46" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Finally, the main change in the <code>model</code> block is for handling the augmentation of the by-item and by-subject effects from scalars to vectors.</p>
<div class="sourceCode" id="cb40" data-source-line-numbers="2-7,13-18" data-startfrom="48" data-code-line-numbers="2-7,13-18"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan" style="counter-reset: source-line 47;"><span id="cb40-48"><a href="#cb40-48" aria-hidden="true" tabindex="-1"></a><span class="kw">model</span> { </span>
<span id="cb40-49"><a href="#cb40-49" aria-hidden="true" tabindex="-1"></a>  <span class="co">// initialize by-item random effects mean to 0</span></span>
<span id="cb40-50"><a href="#cb40-50" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>[N_by_item] item_mean = rep_vector(<span class="fl">0.0</span>, N_by_item);</span>
<span id="cb40-51"><a href="#cb40-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-52"><a href="#cb40-52" aria-hidden="true" tabindex="-1"></a>  <span class="co">// sample the item coefficients</span></span>
<span id="cb40-53"><a href="#cb40-53" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span>:N_item)</span>
<span id="cb40-54"><a href="#cb40-54" aria-hidden="true" tabindex="-1"></a>    by_item_coefs[i] ~ multi_normal(item_mean, item_cov);</span>
<span id="cb40-55"><a href="#cb40-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-56"><a href="#cb40-56" aria-hidden="true" tabindex="-1"></a>  <span class="co">// sample the cutpoints distances</span></span>
<span id="cb40-57"><a href="#cb40-57" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">1</span>:(N_resp_levels<span class="dv">-2</span>))</span>
<span id="cb40-58"><a href="#cb40-58" aria-hidden="true" tabindex="-1"></a>    jumps[j] ~ gamma(<span class="dv">2</span>,<span class="dv">1</span>);</span>
<span id="cb40-59"><a href="#cb40-59" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb40-60"><a href="#cb40-60" aria-hidden="true" tabindex="-1"></a>  <span class="co">// initialize by-subject random effects mean to 0</span></span>
<span id="cb40-61"><a href="#cb40-61" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>[N_by_subj] subj_mean = rep_vector(<span class="fl">0.0</span>, N_by_subj);</span>
<span id="cb40-62"><a href="#cb40-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-63"><a href="#cb40-63" aria-hidden="true" tabindex="-1"></a>  <span class="co">// sample the subject coefficients</span></span>
<span id="cb40-64"><a href="#cb40-64" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (s <span class="cf">in</span> <span class="dv">1</span>:N_subj)</span>
<span id="cb40-65"><a href="#cb40-65" aria-hidden="true" tabindex="-1"></a>    by_subj_coefs[s] ~ multi_normal(subj_mean, subj_cov);</span>
<span id="cb40-66"><a href="#cb40-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-67"><a href="#cb40-67" aria-hidden="true" tabindex="-1"></a>  <span class="co">// sample the responses</span></span>
<span id="cb40-68"><a href="#cb40-68" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (n <span class="cf">in</span> <span class="dv">1</span>:N_resp) {</span>
<span id="cb40-69"><a href="#cb40-69" aria-hidden="true" tabindex="-1"></a>    resp[n] ~ ordered_logistic(acc[n], cutpoints);</span>
<span id="cb40-70"><a href="#cb40-70" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb40-71"><a href="#cb40-71" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<section id="no-grammatical-effects" class="level4">
<h4 class="anchored" data-anchor-id="no-grammatical-effects">No Grammatical Effects</h4>
<p>The first model we will interested in within this general framework is one that accounts for the effects of <code>structure</code> (<code>non</code>-island v. <code>island</code>) and <code>distance</code> (<code>short</code> v. <code>long</code>) for each combination of <code>island</code> type (<code>ADJ</code>unct island, <code>NP</code> island, <code>SUB</code>ject island, <code>WH</code>ether island) and <code>dependency</code> type (<code>WH</code> v. <code>RC</code> v. <code>DlinkedWH</code> v. <code>DlinkedRC</code>) but does not capture the crucial interaction between <code>structure</code> and <code>distance</code> for any of them. Using the R formula interface, this model would be <code>judgment ~ (distance + structure) * island * dependency</code>.</p>
</section>
<section id="adding-a-grammatical-representation" class="level4">
<h4 class="anchored" data-anchor-id="adding-a-grammatical-representation">Adding a Grammatical Representation</h4>
<p>The second two models we will consider are also vanilla mixed effects models. The first assumes that all island violations have the same effect on acceptability: <code>judgment ~ (distance + structure) * island * dependency + distance:structure</code>. This model is consistent with the assumption that all islands are ungrammatical to the same extent and that that ungrammaticality yields the same decrement along the acceptability continuum–equal to whatever the coefficient <span class="math inline">\(\beta_{\text{distance} \times \text{structure}}\)</span> corresponding to the interaction term is. This assumption is technically consistent with either a categorical or gradient grammar, though in the latter case, the gradience would do no work–i.e.&nbsp;it is effectively a perverse sort of discrete grammar. I will refer to this as the minimal interaction model.</p>
<p>The second of these models assumes that all island violations have potentially distinct effects on acceptability: <code>judgment ~ distance * structure * island * dependency</code>. That is, there is a potentially distinct effect for every combination of island type and dependency type and there is no necessary relation among those effects. This assumption is consistent only with a gradient grammar, since any pair of effects could be arbitrarily similar but distinct. I will refer to this as the maximal interaction model.</p>
</section>
<section id="making-the-space-of-grammatical-representations-more-granular" class="level4">
<h4 class="anchored" data-anchor-id="making-the-space-of-grammatical-representations-more-granular">Making the space of grammatical representations more granular</h4>
<p>The minimal and maximal interaction models are extremes along a conceptual continuum that ignore two possibilities: (i) some combinations of island type and dependency type may not result in either categorical or gradient ungrammaticality; and (ii) the effects of island violations may <em>cluster</em>. A potential example of possibility (i) is that some of the differences of differences we observed above (duplicated below) are very near 0 on average. A potential example of (ii) is that the medians for many of these differences of differences are very near each other.</p>
<div class="cell" data-tags="[]" data-execution_count="70">
<details>
<summary>Plotting code</summary>
<div class="sourceCode cell-code" id="cb41" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> boxplot(</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>    diffs_of_diffs,</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>    x<span class="op">=</span><span class="st">"island"</span>, y<span class="op">=</span><span class="dv">0</span>, hue<span class="op">=</span><span class="st">"dependency"</span></span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> p.set_ylabel(<span class="st">"Difference of differences by item"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="model-definition_files/figure-html/cell-27-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>To capture both ideas, we can add some additional structure into how we represent the interaction effects in our mixed effects models. The basic idea is to assume that each pairing of an island type <span class="math inline">\(i\)</span> and a dependency type <span class="math inline">\(d\)</span> might be associated with a discrete indicator <span class="math inline">\(g_{di} \in \{0, \ldots, G\}\)</span> of its <em>level of ungrammaticality</em> <span class="citation" data-cites="chomsky_aspects_1965 chomsky_barriers_1986">(<a href="#ref-chomsky_aspects_1965" role="doc-biblioref">Chomsky 1965</a>, <a href="#ref-chomsky_barriers_1986" role="doc-biblioref">1986</a>)</span>, where <span class="math inline">\(G\)</span> is the maximal number of grammatical violations associated with any structure. We then define the island effect associated with island type <span class="math inline">\(i\)</span> and a dependency type <span class="math inline">\(d\)</span> in terms of <span class="math inline">\(g_{di} \sim \text{Categorical}(\boldsymbol{\gamma})\)</span>.</p>
<p>Depending on (i) how large <span class="math inline">\(G\)</span> is and (ii) how we constrain the relationship between the effect and <span class="math inline">\(g_{di}\)</span>, we get models that live between the extremes of our minimal and maximal interaction models. We will consider two ways that <span class="math inline">\(g_{di}\)</span> might determine the effect: either (a) increments of ungrammaticality come with constant penalty on the acceptability continuum <span class="math inline">\(\delta\)</span> and therefore the total decrement for <span class="math inline">\(g_{di}\)</span> increments of ungrammaticality is <span class="math inline">\(\delta g_{di}\)</span>; or (b) increments of ungrammaticality come with potentially variable penalties on the acceptability continuum <span class="math inline">\(\boldsymbol\delta\)</span> and therefore the total decrement for <span class="math inline">\(g_{di}\)</span> increments of ungrammaticality is <span class="math inline">\(\sum_{g' = 1}^{g_{di}} \delta_{g'}\)</span>, for some sequence of penalty term <span class="math inline">\(\boldsymbol\delta\)</span>. I will refer to the first as the <em>constrained clustered mixed effects model</em> and the second as the <em>unconstrained clustered mixed effects model</em>.</p>
<p>If <span class="math inline">\(G = 1\)</span>, the two models are equivalent, and we have a model that minimally augments our minimal interaction model with the ability to say that some island violations do not cause a decrement in acceptability. But when <span class="math inline">\(G = 2\)</span>, the models begin to pull apart, becoming more drastic as <span class="math inline">\(G \rightarrow \infty\)</span>.</p>
<p>Either sort of model is technically consistent with a categorical or gradient grammar, insofar as the gradient grammar is willing to posit at least some amount of underlying discreteness. But as for the the minimal interaction model, associating at least the family of constrained clustered interaction models with a gradient grammar is potentially perverse: where would the equidistance in the acceptability decrements come from?</p>
<p>To implement the two clustered interaction models, we will add to the <code>data</code> block from the mixed effects model a specification of the number of grammaticality levels (<code>N_grammaticality_levels</code><span class="math inline">\(= G+1\)</span>) and the interactions we’re modeling.</p>
<div class="sourceCode" id="cb42" data-source-line-numbers="2-3,14" data-startfrom="1" data-code-line-numbers="2-3,14"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="kw">data</span> {</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">2</span>&gt; N_grammaticality_levels;                   <span class="co">// number of grammaticality levels</span></span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">2</span>&gt; N_interactions;                            <span class="co">// number of interactions to model as discrete</span></span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; N_resp;                                    <span class="co">// number of responses</span></span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; N_subj;                                    <span class="co">// number of subjects</span></span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; N_item;                                    <span class="co">// number of items</span></span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">2</span>&gt; N_resp_levels;                             <span class="co">// number of possible likert scale acceptability judgment responses</span></span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">1</span>&gt; N_fixed;                                   <span class="co">// number of fixed predictors</span></span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">1</span>&gt; N_by_subj;                                 <span class="co">// number of random by-subject predictors</span></span>
<span id="cb42-10"><a href="#cb42-10" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">1</span>&gt; N_by_item;                                 <span class="co">// number of random by-item predictors</span></span>
<span id="cb42-11"><a href="#cb42-11" aria-hidden="true" tabindex="-1"></a>  <span class="dt">matrix</span>[N_resp,N_fixed] fixed_predictors;                <span class="co">// predictors (length and dependency type) including intercept</span></span>
<span id="cb42-12"><a href="#cb42-12" aria-hidden="true" tabindex="-1"></a>  <span class="dt">matrix</span>[N_resp,N_by_subj] by_subj_predictors;            <span class="co">// by-subject predictors (length and dependency type) including intercept</span></span>
<span id="cb42-13"><a href="#cb42-13" aria-hidden="true" tabindex="-1"></a>  <span class="dt">matrix</span>[N_resp,N_by_item] by_item_predictors;            <span class="co">// by-item predictors (length and dependency type) including intercept</span></span>
<span id="cb42-14"><a href="#cb42-14" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">1</span>,<span class="kw">upper</span>=N_interactions&gt; interactions[N_resp]; <span class="co">// interactions to model as discrete </span></span>
<span id="cb42-15"><a href="#cb42-15" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">1</span>,<span class="kw">upper</span>=N_subj&gt; subj[N_resp];                 <span class="co">// subject who gave response n</span></span>
<span id="cb42-16"><a href="#cb42-16" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">1</span>,<span class="kw">upper</span>=N_item&gt; item[N_resp];                 <span class="co">// item corresponding to response n</span></span>
<span id="cb42-17"><a href="#cb42-17" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">1</span>,<span class="kw">upper</span>=N_resp_levels&gt; resp[N_resp];          <span class="co">// likert scale acceptability judgment responses</span></span>
<span id="cb42-18"><a href="#cb42-18" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>To the <code>parameters</code> block of the constrained clutered interaction model, we’ll add the <code>penalty</code> <span class="math inline">\(\delta\)</span> and a parameter <code>gamma</code> that representations the probability of each grammaticality level.</p>
<div class="sourceCode" id="cb43" data-source-line-numbers="2-3" data-startfrom="20" data-code-line-numbers="2-3"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan" style="counter-reset: source-line 19;"><span id="cb43-20"><a href="#cb43-20" aria-hidden="true" tabindex="-1"></a><span class="kw">parameters</span> {</span>
<span id="cb43-21"><a href="#cb43-21" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span>&lt;<span class="kw">upper</span>=<span class="dv">0</span>&gt; penalty;                                  <span class="co">// grammaticality violation penalty</span></span>
<span id="cb43-22"><a href="#cb43-22" aria-hidden="true" tabindex="-1"></a>  <span class="dt">simplex</span>[N_grammaticality_levels] gamma;                 <span class="co">// probabilities of grammaticality levels</span></span>
<span id="cb43-23"><a href="#cb43-23" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>[N_fixed] fixed_coefs;                            <span class="co">// fixed coefficients (including intercept)</span></span>
<span id="cb43-24"><a href="#cb43-24" aria-hidden="true" tabindex="-1"></a>  <span class="dt">cov_matrix</span>[N_by_subj] subj_cov;                         <span class="co">// subject random effects covariance</span></span>
<span id="cb43-25"><a href="#cb43-25" aria-hidden="true" tabindex="-1"></a>  <span class="dt">cov_matrix</span>[N_by_item] item_cov;                         <span class="co">// item random effects covariance              </span></span>
<span id="cb43-26"><a href="#cb43-26" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>[N_by_subj] by_subj_coefs[N_subj];                <span class="co">// by-subject coefficients (including intercept)</span></span>
<span id="cb43-27"><a href="#cb43-27" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>[N_by_item] by_item_coefs[N_item];                <span class="co">// by-item coefficients (including intercept)</span></span>
<span id="cb43-28"><a href="#cb43-28" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt;[N_resp_levels<span class="dv">-2</span>] jumps;                 <span class="co">// cutpoint distances for each subject</span></span>
<span id="cb43-29"><a href="#cb43-29" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Analogously, to the <code>parameters</code> block of the unconstrained clutered interaction model, we’ll add <code>N_grammaticality_levels</code><span class="math inline">\(-1 = G\)</span> <code>penalty</code>s <span class="math inline">\(\boldsymbol\delta\)</span> and an analogous <code>gamma</code> parameter.</p>
<div class="sourceCode" id="cb44" data-source-line-numbers="2-3" data-startfrom="20" data-code-line-numbers="2-3"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan" style="counter-reset: source-line 19;"><span id="cb44-20"><a href="#cb44-20" aria-hidden="true" tabindex="-1"></a><span class="kw">parameters</span> {</span>
<span id="cb44-21"><a href="#cb44-21" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>&lt;<span class="kw">upper</span>=<span class="dv">0</span>&gt;[N_grammaticality_levels<span class="dv">-1</span>] penalty;     <span class="co">// grammaticality violation penalty</span></span>
<span id="cb44-22"><a href="#cb44-22" aria-hidden="true" tabindex="-1"></a>  <span class="dt">simplex</span>[N_grammaticality_levels] gamma;                 <span class="co">// probabilities of grammaticality levels</span></span>
<span id="cb44-23"><a href="#cb44-23" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>[N_fixed] fixed_coefs;                            <span class="co">// fixed coefficients (including intercept)</span></span>
<span id="cb44-24"><a href="#cb44-24" aria-hidden="true" tabindex="-1"></a>  <span class="dt">cov_matrix</span>[N_by_subj] subj_cov;                         <span class="co">// subject random effects covariance</span></span>
<span id="cb44-25"><a href="#cb44-25" aria-hidden="true" tabindex="-1"></a>  <span class="dt">cov_matrix</span>[N_by_item] item_cov;                         <span class="co">// item random effects covariance              </span></span>
<span id="cb44-26"><a href="#cb44-26" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>[N_by_subj] by_subj_coefs[N_subj];                <span class="co">// by-subject coefficients (including intercept)</span></span>
<span id="cb44-27"><a href="#cb44-27" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>[N_by_item] by_item_coefs[N_item];                <span class="co">// by-item coefficients (including intercept)</span></span>
<span id="cb44-28"><a href="#cb44-28" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt;[N_resp_levels<span class="dv">-2</span>] jumps;                 <span class="co">// cutpoint distances for each subject</span></span>
<span id="cb44-29"><a href="#cb44-29" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>To compute the acceptability in the <code>transformed parameters</code> blocks, we do something similar to what we did for the mixed effects model. The main difference is that we need to track the acceptability under each assumed level of grammaticality.</p>
<p><em>Constrained clustered mixed effects model</em></p>
<div class="sourceCode" id="cb45" data-source-line-numbers="13-23" data-startfrom="31" data-code-line-numbers="13-23"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan" style="counter-reset: source-line 30;"><span id="cb45-31"><a href="#cb45-31" aria-hidden="true" tabindex="-1"></a><span class="kw">transformed parameters</span> {</span>
<span id="cb45-32"><a href="#cb45-32" aria-hidden="true" tabindex="-1"></a>  <span class="co">// compute the cutpoints by taking a cumulative sum</span></span>
<span id="cb45-33"><a href="#cb45-33" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>[N_resp_levels<span class="dv">-1</span>] cutpoints;</span>
<span id="cb45-34"><a href="#cb45-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-35"><a href="#cb45-35" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (c <span class="cf">in</span> <span class="dv">1</span>:(N_resp_levels<span class="dv">-1</span>)) {</span>
<span id="cb45-36"><a href="#cb45-36" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (c == <span class="dv">1</span>) {</span>
<span id="cb45-37"><a href="#cb45-37" aria-hidden="true" tabindex="-1"></a>      cutpoints[c] = <span class="fl">0.0</span>;</span>
<span id="cb45-38"><a href="#cb45-38" aria-hidden="true" tabindex="-1"></a>    } <span class="cf">else</span> {</span>
<span id="cb45-39"><a href="#cb45-39" aria-hidden="true" tabindex="-1"></a>      cutpoints[c] = cutpoints[c<span class="dv">-1</span>] + jumps[c<span class="dv">-1</span>];</span>
<span id="cb45-40"><a href="#cb45-40" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb45-41"><a href="#cb45-41" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb45-42"><a href="#cb45-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-43"><a href="#cb45-43" aria-hidden="true" tabindex="-1"></a>  <span class="co">// compute the acceptability</span></span>
<span id="cb45-44"><a href="#cb45-44" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span> acc[N_resp,N_grammaticality_levels];</span>
<span id="cb45-45"><a href="#cb45-45" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb45-46"><a href="#cb45-46" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (n <span class="cf">in</span> <span class="dv">1</span>:N_resp) {</span>
<span id="cb45-47"><a href="#cb45-47" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (g <span class="cf">in</span> <span class="dv">1</span>:N_grammaticality_levels) {</span>
<span id="cb45-48"><a href="#cb45-48" aria-hidden="true" tabindex="-1"></a>      acc[n,g] = fixed_predictors[n] * fixed_coefs + </span>
<span id="cb45-49"><a href="#cb45-49" aria-hidden="true" tabindex="-1"></a>                by_subj_predictors[n] * by_subj_coefs[subj[n]] + </span>
<span id="cb45-50"><a href="#cb45-50" aria-hidden="true" tabindex="-1"></a>                by_item_predictors[n] * by_item_coefs[item[n]] +</span>
<span id="cb45-51"><a href="#cb45-51" aria-hidden="true" tabindex="-1"></a>                (g<span class="dv">-1</span>) * penalty;</span>
<span id="cb45-52"><a href="#cb45-52" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb45-53"><a href="#cb45-53" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb45-54"><a href="#cb45-54" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><em>Unconstrained clustered mixed effects model</em></p>
<div class="sourceCode" id="cb46" data-source-line-numbers="13-34" data-startfrom="31" data-code-line-numbers="13-34"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan" style="counter-reset: source-line 30;"><span id="cb46-31"><a href="#cb46-31" aria-hidden="true" tabindex="-1"></a><span class="kw">transformed parameters</span> {</span>
<span id="cb46-32"><a href="#cb46-32" aria-hidden="true" tabindex="-1"></a>  <span class="co">// compute the cutpoints by taking a cumulative sum</span></span>
<span id="cb46-33"><a href="#cb46-33" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>[N_resp_levels<span class="dv">-1</span>] cutpoints;</span>
<span id="cb46-34"><a href="#cb46-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-35"><a href="#cb46-35" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (c <span class="cf">in</span> <span class="dv">1</span>:(N_resp_levels<span class="dv">-1</span>)) {</span>
<span id="cb46-36"><a href="#cb46-36" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (c == <span class="dv">1</span>) {</span>
<span id="cb46-37"><a href="#cb46-37" aria-hidden="true" tabindex="-1"></a>      cutpoints[c] = <span class="fl">0.0</span>;</span>
<span id="cb46-38"><a href="#cb46-38" aria-hidden="true" tabindex="-1"></a>    } <span class="cf">else</span> {</span>
<span id="cb46-39"><a href="#cb46-39" aria-hidden="true" tabindex="-1"></a>      cutpoints[c] = cutpoints[c<span class="dv">-1</span>] + jumps[c<span class="dv">-1</span>];</span>
<span id="cb46-40"><a href="#cb46-40" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb46-41"><a href="#cb46-41" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb46-42"><a href="#cb46-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-43"><a href="#cb46-43" aria-hidden="true" tabindex="-1"></a>  <span class="co">// compute the decrement</span></span>
<span id="cb46-44"><a href="#cb46-44" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>[N_grammaticality_levels] decrement;</span>
<span id="cb46-45"><a href="#cb46-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-46"><a href="#cb46-46" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (g <span class="cf">in</span> <span class="dv">1</span>:N_grammaticality_levels) {</span>
<span id="cb46-47"><a href="#cb46-47" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (g == <span class="dv">1</span>) {</span>
<span id="cb46-48"><a href="#cb46-48" aria-hidden="true" tabindex="-1"></a>      decrement[g] = <span class="fl">0.0</span>;</span>
<span id="cb46-49"><a href="#cb46-49" aria-hidden="true" tabindex="-1"></a>    } <span class="cf">else</span> {</span>
<span id="cb46-50"><a href="#cb46-50" aria-hidden="true" tabindex="-1"></a>      decrement[g] = decrement[g<span class="dv">-1</span>] + penalty[g<span class="dv">-1</span>];</span>
<span id="cb46-51"><a href="#cb46-51" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb46-52"><a href="#cb46-52" aria-hidden="true" tabindex="-1"></a>  }  </span>
<span id="cb46-53"><a href="#cb46-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-54"><a href="#cb46-54" aria-hidden="true" tabindex="-1"></a>  <span class="co">// compute the acceptability</span></span>
<span id="cb46-55"><a href="#cb46-55" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span> acc[N_resp,N_grammaticality_levels];</span>
<span id="cb46-56"><a href="#cb46-56" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb46-57"><a href="#cb46-57" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (n <span class="cf">in</span> <span class="dv">1</span>:N_resp) {</span>
<span id="cb46-58"><a href="#cb46-58" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (g <span class="cf">in</span> <span class="dv">1</span>:N_grammaticality_levels) {</span>
<span id="cb46-59"><a href="#cb46-59" aria-hidden="true" tabindex="-1"></a>      acc[n,g] = fixed_predictors[n] * fixed_coefs + </span>
<span id="cb46-60"><a href="#cb46-60" aria-hidden="true" tabindex="-1"></a>                by_subj_predictors[n] * by_subj_coefs[subj[n]] + </span>
<span id="cb46-61"><a href="#cb46-61" aria-hidden="true" tabindex="-1"></a>                by_item_predictors[n] * by_item_coefs[item[n]] +</span>
<span id="cb46-62"><a href="#cb46-62" aria-hidden="true" tabindex="-1"></a>                decrement[g];</span>
<span id="cb46-63"><a href="#cb46-63" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb46-64"><a href="#cb46-64" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb46-65"><a href="#cb46-65" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The reason need to do this is that, because we are assuming that each pairing of island type and dependency type has a particular grammaticality that’s shared across all items that instantiate that pair. This assumption implies that responses are only independent conditioned on the grammaticality associated with that structure.</p>
<p><span class="math display">\[\begin{align*}
p(\mathbf{y} \mid \boldsymbol\gamma, \delta, \mathbf{c}) &amp;= \prod_{d,i} \sum_{g'} \mathbb{P}(g_{di} = g'; \boldsymbol\gamma, \delta, \mathbf{c}) \prod_{n: \text{struct}(n) = \langle d, i \rangle} p(y_n \mid g_{di} = g'; \boldsymbol\gamma, d, \mathbf{c})
\end{align*}\]</span></p>
<p>This assumption is represented in the <code>model</code> block:</p>
<div class="sourceCode" id="cb47" data-source-line-numbers="24-51" data-startfrom="56" data-code-line-numbers="24-51"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan" style="counter-reset: source-line 55;"><span id="cb47-56"><a href="#cb47-56" aria-hidden="true" tabindex="-1"></a><span class="kw">model</span> {</span>
<span id="cb47-57"><a href="#cb47-57" aria-hidden="true" tabindex="-1"></a>  <span class="co">// sample penalty</span></span>
<span id="cb47-58"><a href="#cb47-58" aria-hidden="true" tabindex="-1"></a>  penalty ~ normal(<span class="dv">0</span>, <span class="dv">1</span>);</span>
<span id="cb47-59"><a href="#cb47-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-60"><a href="#cb47-60" aria-hidden="true" tabindex="-1"></a>  <span class="co">// initialize by-subject random effects mean to 0</span></span>
<span id="cb47-61"><a href="#cb47-61" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>[N_by_subj] subj_mean;</span>
<span id="cb47-62"><a href="#cb47-62" aria-hidden="true" tabindex="-1"></a>  subj_mean = rep_vector(<span class="fl">0.0</span>, N_by_subj);</span>
<span id="cb47-63"><a href="#cb47-63" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb47-64"><a href="#cb47-64" aria-hidden="true" tabindex="-1"></a>  <span class="co">// initialize by-item random effects mean to 0</span></span>
<span id="cb47-65"><a href="#cb47-65" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>[N_by_item] item_mean;</span>
<span id="cb47-66"><a href="#cb47-66" aria-hidden="true" tabindex="-1"></a>  item_mean = rep_vector(<span class="fl">0.0</span>, N_by_item);</span>
<span id="cb47-67"><a href="#cb47-67" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb47-68"><a href="#cb47-68" aria-hidden="true" tabindex="-1"></a>  <span class="co">// sample the cutpoints distances</span></span>
<span id="cb47-69"><a href="#cb47-69" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">1</span>:(N_resp_levels<span class="dv">-2</span>))</span>
<span id="cb47-70"><a href="#cb47-70" aria-hidden="true" tabindex="-1"></a>    jumps[j] ~ gamma(<span class="dv">2</span>,<span class="dv">1</span>);</span>
<span id="cb47-71"><a href="#cb47-71" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb47-72"><a href="#cb47-72" aria-hidden="true" tabindex="-1"></a>  <span class="co">// sample the subject intercepts</span></span>
<span id="cb47-73"><a href="#cb47-73" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (s <span class="cf">in</span> <span class="dv">1</span>:N_subj)</span>
<span id="cb47-74"><a href="#cb47-74" aria-hidden="true" tabindex="-1"></a>    by_subj_coefs[s] ~ multi_normal(subj_mean, subj_cov);</span>
<span id="cb47-75"><a href="#cb47-75" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb47-76"><a href="#cb47-76" aria-hidden="true" tabindex="-1"></a>  <span class="co">// sample the item intercepts</span></span>
<span id="cb47-77"><a href="#cb47-77" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span>:N_item)</span>
<span id="cb47-78"><a href="#cb47-78" aria-hidden="true" tabindex="-1"></a>    by_item_coefs[i] ~ multi_normal(item_mean, item_cov);</span>
<span id="cb47-79"><a href="#cb47-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-80"><a href="#cb47-80" aria-hidden="true" tabindex="-1"></a>  <span class="co">// declare log-likelihood of responses corresponding to a particular interaction</span></span>
<span id="cb47-81"><a href="#cb47-81" aria-hidden="true" tabindex="-1"></a>  <span class="co">// assuming a particular grammaticality level</span></span>
<span id="cb47-82"><a href="#cb47-82" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span> theta[N_interactions,N_grammaticality_levels];</span>
<span id="cb47-83"><a href="#cb47-83" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb47-84"><a href="#cb47-84" aria-hidden="true" tabindex="-1"></a>  <span class="co">// initialize log-likelihood of responses corresponding to a particular interaction</span></span>
<span id="cb47-85"><a href="#cb47-85" aria-hidden="true" tabindex="-1"></a>  <span class="co">// to the log-prior on the membership probabilities</span></span>
<span id="cb47-86"><a href="#cb47-86" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span>:N_interactions) {</span>
<span id="cb47-87"><a href="#cb47-87" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (g <span class="cf">in</span> <span class="dv">1</span>:N_grammaticality_levels) {</span>
<span id="cb47-88"><a href="#cb47-88" aria-hidden="true" tabindex="-1"></a>      theta[i,g] = log(gamma[g]);</span>
<span id="cb47-89"><a href="#cb47-89" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb47-90"><a href="#cb47-90" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb47-91"><a href="#cb47-91" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb47-92"><a href="#cb47-92" aria-hidden="true" tabindex="-1"></a>  <span class="co">// add the log-likelihood of each response corresponding to a particular interaction</span></span>
<span id="cb47-93"><a href="#cb47-93" aria-hidden="true" tabindex="-1"></a>  <span class="co">// assuming a particular grammaticality level </span></span>
<span id="cb47-94"><a href="#cb47-94" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (n <span class="cf">in</span> <span class="dv">1</span>:N_resp) {</span>
<span id="cb47-95"><a href="#cb47-95" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (g <span class="cf">in</span> <span class="dv">1</span>:N_grammaticality_levels) {</span>
<span id="cb47-96"><a href="#cb47-96" aria-hidden="true" tabindex="-1"></a>      theta[interactions[n],g] += ordered_logistic_lpmf(</span>
<span id="cb47-97"><a href="#cb47-97" aria-hidden="true" tabindex="-1"></a>        resp[n] | acc[n,g], cutpoints</span>
<span id="cb47-98"><a href="#cb47-98" aria-hidden="true" tabindex="-1"></a>      );</span>
<span id="cb47-99"><a href="#cb47-99" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb47-100"><a href="#cb47-100" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb47-101"><a href="#cb47-101" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb47-102"><a href="#cb47-102" aria-hidden="true" tabindex="-1"></a>  <span class="co">// compute log-likelihood of all responses corresponding to a particular interaction</span></span>
<span id="cb47-103"><a href="#cb47-103" aria-hidden="true" tabindex="-1"></a>  <span class="co">// by summing over the likelihood assuming a particular grammaticality level</span></span>
<span id="cb47-104"><a href="#cb47-104" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span>:N_interactions) {</span>
<span id="cb47-105"><a href="#cb47-105" aria-hidden="true" tabindex="-1"></a>    <span class="kw">target +=</span> log_sum_exp(theta[i]);</span>
<span id="cb47-106"><a href="#cb47-106" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb47-107"><a href="#cb47-107" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This assumption also affects how we compute metrics for model comparison, which I’ll come back to in the next section. I’ll just say now that, to handle this, we need to compute the <em>membership probabilities</em> for each pairing of island type and dependency type–i.e.&nbsp;the posterior probability of the grammaticality levels given the responses to items instantiating that pairing.</p>
<p><span class="math display">\[\mathbb{P}(g_{di} = g' \mid \{y_n: \text{struct}(n) = \langle d, i \rangle\}) \propto p(\{y_n: \text{struct}(n) = \langle d, i \rangle\} \mid g_{di} = g')\mathbb{P}(g_{di} = g')\]</span></p>
<p>We do this computation in the <code>generated quantities</code> block.</p>
<div class="sourceCode" id="cb48" data-source-line-numbers="2-22" data-startfrom="109" data-code-line-numbers="2-22"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan" style="counter-reset: source-line 108;"><span id="cb48-109"><a href="#cb48-109" aria-hidden="true" tabindex="-1"></a><span class="kw">generated quantities</span> {  </span>
<span id="cb48-110"><a href="#cb48-110" aria-hidden="true" tabindex="-1"></a>  <span class="co">// declare log-likelihood of all responses corresponding to a particular interaction</span></span>
<span id="cb48-111"><a href="#cb48-111" aria-hidden="true" tabindex="-1"></a>  <span class="co">// by summing over the likelihood assuming a particular grammaticality level</span></span>
<span id="cb48-112"><a href="#cb48-112" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span> log_lik_grouped[N_interactions];</span>
<span id="cb48-113"><a href="#cb48-113" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb48-114"><a href="#cb48-114" aria-hidden="true" tabindex="-1"></a>  <span class="co">// compute log-likelihood of all responses corresponding to a particular interaction</span></span>
<span id="cb48-115"><a href="#cb48-115" aria-hidden="true" tabindex="-1"></a>  <span class="co">// by summing over the likelihood assuming a particular grammaticality level</span></span>
<span id="cb48-116"><a href="#cb48-116" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span>:N_interactions) {</span>
<span id="cb48-117"><a href="#cb48-117" aria-hidden="true" tabindex="-1"></a>    log_lik_grouped[i] = log_sum_exp(theta[i]);</span>
<span id="cb48-118"><a href="#cb48-118" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb48-119"><a href="#cb48-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-120"><a href="#cb48-120" aria-hidden="true" tabindex="-1"></a>  <span class="co">// declare probability of particular grammaticality level for each interaction</span></span>
<span id="cb48-121"><a href="#cb48-121" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span> log_membership[N_interactions,N_grammaticality_levels];</span>
<span id="cb48-122"><a href="#cb48-122" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb48-123"><a href="#cb48-123" aria-hidden="true" tabindex="-1"></a>  <span class="co">// compute probability of particular grammaticality level for each interaction</span></span>
<span id="cb48-124"><a href="#cb48-124" aria-hidden="true" tabindex="-1"></a>  <span class="co">// by dividing the likelihood under that level by the sum over likelihoods</span></span>
<span id="cb48-125"><a href="#cb48-125" aria-hidden="true" tabindex="-1"></a>  <span class="co">// across levels</span></span>
<span id="cb48-126"><a href="#cb48-126" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span>:N_interactions) {</span>
<span id="cb48-127"><a href="#cb48-127" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (g <span class="cf">in</span> <span class="dv">1</span>:N_grammaticality_levels) {</span>
<span id="cb48-128"><a href="#cb48-128" aria-hidden="true" tabindex="-1"></a>      log_membership[i,g] = theta[i,g] - log_lik_grouped[i];</span>
<span id="cb48-129"><a href="#cb48-129" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb48-130"><a href="#cb48-130" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb48-131"><a href="#cb48-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-132"><a href="#cb48-132" aria-hidden="true" tabindex="-1"></a>  <span class="co">// declare the log-likelihood (really, log-pointwise predictive density) of </span></span>
<span id="cb48-133"><a href="#cb48-133" aria-hidden="true" tabindex="-1"></a>  <span class="co">// each data point</span></span>
<span id="cb48-134"><a href="#cb48-134" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span> log_lik[N_resp];</span>
<span id="cb48-135"><a href="#cb48-135" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb48-136"><a href="#cb48-136" aria-hidden="true" tabindex="-1"></a>  <span class="co">// compute the log-likelihood (really, log-pointwise predictive density) of </span></span>
<span id="cb48-137"><a href="#cb48-137" aria-hidden="true" tabindex="-1"></a>  <span class="co">// each data point by weighting the likelihood assuming a particular </span></span>
<span id="cb48-138"><a href="#cb48-138" aria-hidden="true" tabindex="-1"></a>  <span class="co">// grammaticality level by the membership probability of that level </span></span>
<span id="cb48-139"><a href="#cb48-139" aria-hidden="true" tabindex="-1"></a>  <span class="co">// for the interaction corresponding to the data point.</span></span>
<span id="cb48-140"><a href="#cb48-140" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (n <span class="cf">in</span> <span class="dv">1</span>:N_resp) {</span>
<span id="cb48-141"><a href="#cb48-141" aria-hidden="true" tabindex="-1"></a>    <span class="dt">real</span> log_lik_by_level[N_grammaticality_levels];</span>
<span id="cb48-142"><a href="#cb48-142" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (g <span class="cf">in</span> <span class="dv">1</span>:N_grammaticality_levels) {</span>
<span id="cb48-143"><a href="#cb48-143" aria-hidden="true" tabindex="-1"></a>      log_lik_by_level[g] = log_membership[interactions[n],g] + </span>
<span id="cb48-144"><a href="#cb48-144" aria-hidden="true" tabindex="-1"></a>                            ordered_logistic_lpmf(resp[n] | acc[n,g], cutpoints);</span>
<span id="cb48-145"><a href="#cb48-145" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb48-146"><a href="#cb48-146" aria-hidden="true" tabindex="-1"></a>    log_lik[n] = log_sum_exp(log_lik_by_level);</span>
<span id="cb48-147"><a href="#cb48-147" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb48-148"><a href="#cb48-148" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
</section>
<section id="summing-up" class="level2">
<h2 class="anchored" data-anchor-id="summing-up">Summing Up</h2>
<p>Remember that we’re interested in the question of how, for a particular family of theories, we can represent the effect on acceptability that any possible analysis under that theory could produce. We defined a range of theories with different levels of expressivity, and now what we need to do is to search among analyses that can be expressed in those theories for those that fit the data best. Once we have those analyses, we can then compare the families of theories by quantitatively measuring the fit of those theories’ best analyses to the data and–as a measure of parsimony–weighing that fit against how many such best analyses there are. We will do this in the next section.</p>



</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" role="list">
<div id="ref-chomsky_aspects_1965" class="csl-entry" role="listitem">
Chomsky, Noam. 1965. <em>Aspects of the <span>Theory</span> of <span>Syntax</span></em>. Cambridge, MA: MIT Press.
</div>
<div id="ref-chomsky_barriers_1986" class="csl-entry" role="listitem">
———. 1986. <em>Barriers</em>. Cambridge, MA: MIT Press.
</div>
<div id="ref-gibson_linguistic_1998" class="csl-entry" role="listitem">
Gibson, Edward. 1998. <span>“Linguistic Complexity: Locality of Syntactic Dependencies.”</span> <em>Cognition</em> 68 (1): 1–76. <a href="https://doi.org/10.1016/S0010-0277(98)00034-1">https://doi.org/10.1016/S0010-0277(98)00034-1</a>.
</div>
<div id="ref-hale_probabilistic_2001" class="csl-entry" role="listitem">
Hale, John. 2001. <span>“A <span>Probabilistic</span> <span>Earley</span> <span>Parser</span> <span>As</span> a <span>Psycholinguistic</span> <span>Model</span>.”</span> In <em>Proceedings of the <span>Second</span> <span>Meeting</span> of the <span>North</span> <span>American</span> <span>Chapter</span> of the <span>Association</span> for <span>Computational</span> <span>Linguistics</span> on <span>Language</span> <span>Technologies</span></em>. <span>NAACL</span> ’01. Stroudsburg, PA, USA: Association for Computational Linguistics.
</div>
<div id="ref-levy_expectation-based_2008" class="csl-entry" role="listitem">
Levy, Roger. 2008. <span>“Expectation-Based Syntactic Comprehension.”</span> <em>Cognition</em> 106 (3): 1126–77.
</div>
<div id="ref-lewis_activation-based_2005" class="csl-entry" role="listitem">
Lewis, Richard L., and Shravan Vasishth. 2005. <span>“An <span>Activation</span>-<span>Based</span> <span>Model</span> of <span>Sentence</span> <span>Processing</span> as <span>Skilled</span> <span>Memory</span> <span>Retrieval</span>.”</span> <em>Cognitive Science</em> 29 (3): 375–419. <a href="https://doi.org/10.1207/s15516709cog0000_25">https://doi.org/10.1207/s15516709cog0000_25</a>.
</div>
<div id="ref-mcelree_memory_2003" class="csl-entry" role="listitem">
McElree, Brian, Stephani Foraker, and Lisbeth Dyer. 2003. <span>“Memory Structures That Subserve Sentence Comprehension.”</span> <em>Journal of Memory and Language</em> 48 (1): 67–91. <a href="https://doi.org/10.1016/S0749-596X(02)00515-6">https://doi.org/10.1016/S0749-596X(02)00515-6</a>.
</div>
<div id="ref-sprouse_program_2007" class="csl-entry" role="listitem">
Sprouse, Jon. 2007. <span>“A <span>Program</span> for <span>Experimental</span> <span>Syntax</span>.”</span> PhD thesis, University of Maryland.
</div>
<div id="ref-sprouse_validation_2011" class="csl-entry" role="listitem">
———. 2011. <span>“A Validation of <span>Amazon</span> <span>Mechanical</span> <span>Turk</span> for the Collection of Acceptability Judgments in Linguistic Theory.”</span> <em>Behavorial Research</em> 43: 155–67.
</div>
<div id="ref-sprouse_acceptability_2018" class="csl-entry" role="listitem">
———. 2018. <span>“Acceptability Judgments and Grammaticality, Prospects and Challenges.”</span> In <em>The Impact of the Chomskyan Revolution in Linguistics</em>, edited by Norbert Hornstein, Howard Lasnik, Pritty Patel-Grosz, and Charles Yang, 195–224. Berlin, Boston: De Gruyter Mouton. <a href="https://doi.org/doi:10.1515/9781501506925-199">https://doi.org/doi:10.1515/9781501506925-199</a>.
</div>
<div id="ref-sprouse_assessing_2012" class="csl-entry" role="listitem">
Sprouse, Jon, and Diogo Almeida. 2012. <span>“Assessing the Reliability of Textbook Data in Syntax: <span>Adger</span>’s <span>Core</span> <span>Syntax</span>.”</span> <em>Journal of Linguistics</em> 48 (03): 609–52.
</div>
<div id="ref-sprouse_experimental_2016" class="csl-entry" role="listitem">
Sprouse, Jon, Ivano Caponigro, Ciro Greco, and Carlo Cecchetto. 2016. <span>“Experimental Syntax and the Variation of Island Effects in English and Italian.”</span> <em>Natural Language &amp; Linguistic Theory</em> 34: 307–44. <a href="https://doi.org/10.1007/s11049-015-9286-8">https://doi.org/10.1007/s11049-015-9286-8</a>.
</div>
<div id="ref-stevens_psychophysical_1957" class="csl-entry" role="listitem">
Stevens, S. S. 1957. <span>“On the Psychophysical Law.”</span> <em>Psychological Review</em> 64: 153–81. <a href="https://doi.org/10.1037/h0046162">https://doi.org/10.1037/h0046162</a>.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p><span class="citation" data-cites="sprouse_acceptability_2018">Sprouse (<a href="#ref-sprouse_acceptability_2018" role="doc-biblioref">2018, 213</a>)</span> notes one idea for such a component: “…participants might be implicitly comparing violation sentences to the minimally different grammatical sentences that have the same meanings…[and] that acceptability judgments are impacted by the similarity/dissimilarity between the violation sentence and the grammatical counterpart.”<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>In discussing the introduction of the magnitude estimation task by <span class="citation" data-cites="stevens_psychophysical_1957">(<a href="#ref-stevens_psychophysical_1957" role="doc-biblioref">Stevens 1957</a>)</span>, <span class="citation" data-cites="sprouse_acceptability_2018">Sprouse (<a href="#ref-sprouse_acceptability_2018" role="doc-biblioref">2018, 199</a>)</span> suggests that Likert scale tasks assume “…that participants treat the intervals between the response points as equal, but provides no mechanism to guarantee that.” This suggestion is not quite right: a model that links the acceptability continuum (to use the Sprouse’s terminology) to the Likert scale ratings may assume that response points correspond to intervals of the acceptability continuum that are of equal size; but it need not. For instance, an ordinal logit model–the kind of linking model we use below–can make the assumption that these intervals are of equal size, but most of the time, we use such a model because we <em>don’t</em> want to make that assumption.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>It’s important to note that when <code>distance</code>=<code>short</code> and <code>structure</code>=<code>island</code>, the dependency does not cross into an island. It’s merely the case that there is an island in the sentence.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>As <span class="citation" data-cites="sprouse_acceptability_2018">Sprouse (<a href="#ref-sprouse_acceptability_2018" role="doc-biblioref">2018, 196</a>)</span> notes, “[l]inking hypotheses are rarely amenable to direct investigation, so progress can only be measured by the success of the theory that results from the linking hypothesis plus the empirically collected data.”<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>It is often the case that analyses will assume a shared set of cutpoints for all subjects. This assumption fails to model potential variability in how subjects use the ordinal response scale.<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://giscus.app/client.js" data-repo="aaronstevenwhite/representation-learning-course" data-repo-id="R_kgDOJsrvfQ" data-category="General" data-category-id="DIC_kwDOJsrvfc4CXIDs" data-mapping="title" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="top" data-theme="light" data-lang="en" crossorigin="anonymous" async="">
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../island-effects/index.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Overview</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../island-effects/model-fitting-and-comparison.html" class="pagination-link">
        <span class="nav-page-text">Model Fitting and Comparison</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



<script src="../site_libs/quarto-contrib/line-highlight-1.0.0/line-highlight.js" defer="true"></script>
</body></html>