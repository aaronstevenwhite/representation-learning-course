<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.321">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Representation Learning for Syntactic and Semantic Theory - Selection</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../thematic-roles/index.html" rel="next">
<link href="../projective-content/model-fitting-and-comparison.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/quarto-contrib/line-highlight-1.0.0/line-highlight.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../selection/index.html">Module 3: Selection</a></li><li class="breadcrumb-item"><a href="../selection/index.html">Selection</a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Representation Learning for Syntactic and Semantic Theory</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">About</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../installation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Installation</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../motivations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Motivations</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../methodological-approach.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Methodological Approach</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../course-structure-and-content.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Course Structure and Content</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Foundational Concepts in Probability and Statistics</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../foundational-concepts-in-probability-and-statistics/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">What is a probability?</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../foundational-concepts-in-probability-and-statistics/random-variables-and-probability-distributions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Random variables and probability distributions</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../foundational-concepts-in-probability-and-statistics/statistical-inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Statistical Inference</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
 <span class="menu-text">Module 1: Island Effects</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../island-effects/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../island-effects/model-definition.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Model definition</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../island-effects/model-fitting-and-comparison.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Model Fitting and Comparison</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
 <span class="menu-text">Module 2: Projective Content</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../projective-content/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../projective-content/inferentially-defined-classes-of-predicates.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Inferentially defined classes of predicates</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../projective-content/model-definition.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Model definition</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../projective-content/model-fitting-and-comparison.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Model fitting and comparison</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../selection/index.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Selection</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../thematic-roles/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Module 4: Thematic Roles</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Selection</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Reading
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Data:</strong> <span class="citation" data-cites="white_frequency_2020">White and Rawlins (<a href="#ref-white_frequency_2020" role="doc-biblioref">2020</a>)</span> on collecting a broad-coverage acceptability judgment dataset focused on complement clauses and <span class="citation" data-cites="white_computational_2016">White and Rawlins (<a href="#ref-white_computational_2016" role="doc-biblioref">2016</a>)</span> on using that dataset to develop a computational model of selection. We will use the data collected for those papers, which can be found <a href="http://megaattitude.io/projects/mega-acceptability/">here</a>, in this module.</p>
<p><strong>Theory:</strong> <span class="citation" data-cites="lohninger_typology_2020">Lohninger and Wurmbrand (<a href="#ref-lohninger_typology_2020" role="doc-biblioref">to appear</a>)</span> on the typology of complement clauses. We will specifically be concerned with their hypothesis that the distributional complement clauses is constrained by a monotonicity constraint relating ordered semantic types to ordered syntactic types.</p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>TELL ENT ENT PROP</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>B       B      B       B      I         I</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>someone told   someone that   something happened</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="126">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co">#!wget http://megaattitude.io/projects/mega-acceptability/mega-acceptability-v1.zip -P data/</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="co">#!unzip data/mega-acceptability-v1.zip -d data/</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>data_dir <span class="op">=</span> <span class="st">"./data/mega-acceptability-v1/"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-tags="[]" data-execution_count="127">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> load_data(fname: <span class="bu">str</span>, verbose: <span class="bu">bool</span> <span class="op">=</span> <span class="va">True</span>) <span class="op">-&gt;</span> pd.DataFrame:</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># read the raw data skipping comment rows at the beginning</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>    data <span class="op">=</span> pd.read_csv(fname, sep<span class="op">=</span><span class="st">"</span><span class="ch">\t</span><span class="st">"</span>)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> verbose:</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>        n_datapoints <span class="op">=</span> data.shape[<span class="dv">0</span>]</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"The full dataset has </span><span class="sc">{</span>n_datapoints<span class="sc">}</span><span class="ss"> datapoints."</span>)</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># remove non-native speakers</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>    data <span class="op">=</span> data.query(<span class="st">"nativeenglish"</span>)</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> verbose:</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>        n_datapoints_native <span class="op">=</span> data.shape[<span class="dv">0</span>]</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Removing </span><span class="sc">{</span>n_datapoints <span class="op">-</span> n_datapoints_native<span class="sc">}</span><span class="ss"> "</span></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>              <span class="st">"responses from nonnative speakers."</span>)</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># remove NaN judgments</span></span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>    data <span class="op">=</span> data.query(<span class="st">"~response.isnull()"</span>)</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> verbose:</span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>        n_datapoints_nonnull <span class="op">=</span> data.shape[<span class="dv">0</span>]</span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Removing </span><span class="sc">{</span>n_datapoints_native <span class="op">-</span> n_datapoints_nonnull<span class="sc">}</span><span class="ss"> NA responses."</span>)</span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> data</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-tags="[]" data-execution_count="128">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> load_data(os.path.join(data_dir, <span class="st">"mega-acceptability-v1.tsv"</span>))</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>data</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>The full dataset has 250000 datapoints.
Removing 600 responses from nonnative speakers.
Removing 10 NA responses.</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="128">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">participant</th>
<th data-quarto-table-cell-role="th">list</th>
<th data-quarto-table-cell-role="th">presentationorder</th>
<th data-quarto-table-cell-role="th">verb</th>
<th data-quarto-table-cell-role="th">frame</th>
<th data-quarto-table-cell-role="th">response</th>
<th data-quarto-table-cell-role="th">nativeenglish</th>
<th data-quarto-table-cell-role="th">sentence</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>4</td>
<td>862</td>
<td>1</td>
<td>turn_out</td>
<td>NP was Ved whichNP to VP</td>
<td>2.0</td>
<td>True</td>
<td>Someone was turned out which thing to do.</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>381</td>
<td>862</td>
<td>1</td>
<td>turn_out</td>
<td>NP was Ved whichNP to VP</td>
<td>1.0</td>
<td>True</td>
<td>Someone was turned out which thing to do.</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>395</td>
<td>862</td>
<td>1</td>
<td>turn_out</td>
<td>NP was Ved whichNP to VP</td>
<td>2.0</td>
<td>True</td>
<td>Someone was turned out which thing to do.</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>621</td>
<td>862</td>
<td>1</td>
<td>turn_out</td>
<td>NP was Ved whichNP to VP</td>
<td>1.0</td>
<td>True</td>
<td>Someone was turned out which thing to do.</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>527</td>
<td>862</td>
<td>1</td>
<td>turn_out</td>
<td>NP was Ved whichNP to VP</td>
<td>1.0</td>
<td>True</td>
<td>Someone was turned out which thing to do.</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">249995</td>
<td>113</td>
<td>928</td>
<td>50</td>
<td>madden</td>
<td>NP Ved about NP</td>
<td>4.0</td>
<td>True</td>
<td>Someone maddened about something.</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">249996</td>
<td>32</td>
<td>928</td>
<td>50</td>
<td>madden</td>
<td>NP Ved about NP</td>
<td>2.0</td>
<td>True</td>
<td>Someone maddened about something.</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">249997</td>
<td>544</td>
<td>928</td>
<td>50</td>
<td>madden</td>
<td>NP Ved about NP</td>
<td>1.0</td>
<td>True</td>
<td>Someone maddened about something.</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">249998</td>
<td>727</td>
<td>928</td>
<td>50</td>
<td>madden</td>
<td>NP Ved about NP</td>
<td>7.0</td>
<td>True</td>
<td>Someone maddened about something.</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">249999</td>
<td>294</td>
<td>928</td>
<td>50</td>
<td>madden</td>
<td>NP Ved about NP</td>
<td>1.0</td>
<td>True</td>
<td>Someone maddened about something.</td>
</tr>
</tbody>
</table>

<p>249390 rows × 8 columns</p>
</div>
</div>
</div>
<p><span class="citation" data-cites="white_computational_2016">White and Rawlins (<a href="#ref-white_computational_2016" role="doc-biblioref">2016</a>)</span> model the ordinal acceptability judgments <span class="math inline">\(r_i\)</span> associated with a sentence <span class="math inline">\(s_i\)</span> to be a function of the probability <span class="math inline">\(\alpha_{vf}\)</span> that the main clause verb <span class="math inline">\(v = \text{verb}(i)\)</span> in <span class="math inline">\(s_i\)</span> is acceptable in the syntactic frame <span class="math inline">\(f = \text{frame}(i)\)</span> instantiated in <span class="math inline">\(s_i\)</span>.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> They model this probability as a function of two other kinds of probability: (i) the probability <span class="math inline">\(\lambda_{vs}\)</span> that a particular verb <span class="math inline">\(v\)</span> can have a particular semantic type signature <span class="math inline">\(s\)</span>; and (ii) the probability <span class="math inline">\(\mu_{sf}\)</span> that a particular semantic type signature <span class="math inline">\(s\)</span> can be mapped onto a particular syntactic frame <span class="math inline">\(f\)</span>.</p>
<p>The basic idea is that we should predict a verb to be good–modulo other factors, such as its case assignment properties <span class="citation" data-cites="pesetsky_zero_1991">(<a href="#ref-pesetsky_zero_1991" role="doc-biblioref"><strong>pesetsky_zero_1991?</strong></a>)</span>–in a particular syntactic frame insofar as it can have at least one semantic type signature that maps onto that frame. That is, they define the probability <span class="math inline">\(\alpha_{vf}\)</span> that a main clause verb <span class="math inline">\(v\)</span> is acceptable in a syntactic frame <span class="math inline">\(f\)</span> to be <span class="math inline">\(p\left(\bigvee_s l_{vs} \land m_{sf}\right)\)</span>, where:</p>
<p><span class="math display">\[\begin{align*}
l_{vs} &amp;= \begin{cases}
\top &amp; \text{if } v \text{ can have semantic type signature } s\\
\bot &amp; \text{otherwise}
\end{cases}\\
m_{sf} &amp;= \begin{cases}
\top &amp; \text{if } s \text{ can map onto syntactic frame } f\\
\bot &amp; \text{otherwise}
\end{cases}
\end{align*}\]</span></p>
<p>Insofar as a verb’s having a particular type signature is independent of that type signature mapping onto a particular syntactic frame, this probability can be <em>factored</em> into an expression in terms of <span class="math inline">\(\lambda_{vs}\)</span> and <span class="math inline">\(\mu_{sf}\)</span>:</p>
<p><span class="math display">\[\begin{align*}
p\left(\bigvee_s l_{vs} \land m_{sf}\right) &amp;= p\left(\lnot\lnot\bigvee_s l_{vs} \land m_{sf}\right)\\
&amp;= 1 - p\left(\lnot\bigvee_s l_{vs} \land m_{sf}\right)\\
&amp;= 1 - p\left(\bigwedge_s \lnot\left[ l_{vs} \land m_{sf}\right]\right)\\
&amp;= 1 - \prod_s p\left(\lnot\left[ l_{vs} \land m_{sf}\right]\right)\\
&amp;= 1 - \prod_s 1 - p\left(l_{vs} \land m_{sf}\right)\\
&amp;= 1 - \prod_s 1 - p\left(l_{vs}\right)p\left(m_{sf}\right)\\
&amp;= 1 - \prod_s 1 - \lambda_{vs}\mu_{sf}\\
\end{align*}\]</span></p>
<p>Importantly, they assume: (a) that verbs can be compatible with multiple semantic type signatures; (b) that multiple semantic type signatures can map onto the same frame; and (c) that multiple frames can be mapped onto by the same semantic type signature. So <span class="math inline">\(\sum_s \lambda_{vs}\)</span> and <span class="math inline">\(\sum_s \mu_{sf}\)</span> can be anywhere between <span class="math inline">\(0\)</span> and the number of type signatures, and <span class="math inline">\(\sum_f \mu_{sf}\)</span> can be anywhere between <span class="math inline">\(0\)</span> and the number of syntactic frames. None of the three need to be <span class="math inline">\(1\)</span>.</p>
<p>Solving for <span class="math inline">\(\lambda_{vs}\)</span> and <span class="math inline">\(\mu_{sf}\)</span>, from which <span class="math inline">\(\alpha_{vf}\)</span> can be computed deterministically, is an instance of a <a href="https://en.wikipedia.org/wiki/Matrix_decomposition">matrix factorization</a> problem–of which <a href="https://en.wikipedia.org/wiki/Principal_component_analysis">principal component analysis</a> [PCA; <span class="citation" data-cites="pearson_lines_1901">Pearson (<a href="#ref-pearson_lines_1901" role="doc-biblioref">1901</a>)</span>], <a href="https://en.wikipedia.org/wiki/Factor_analysis">factor analysis</a>, and <a href="https://en.wikipedia.org/wiki/Non-negative_matrix_factorization">postive/non-negative matrix factorization</a> [NMF; <span class="citation" data-cites="paatero_positive_1994">Paatero and Tapper (<a href="#ref-paatero_positive_1994" role="doc-biblioref">1994</a>)</span>] are common forms.</p>
<div class="cell" data-tags="[]" data-execution_count="129">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> numpy <span class="im">import</span> ndarray</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pandas <span class="im">import</span> CategoricalDtype</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> hash_series(series: pd.Series, categories: Optional[<span class="bu">list</span>[<span class="bu">str</span>]] <span class="op">=</span> <span class="va">None</span>, indexation: <span class="bu">int</span><span class="op">=</span><span class="dv">1</span>) <span class="op">-&gt;</span> <span class="bu">tuple</span>[ndarray, ndarray]:</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Hash a series to numeric codes</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="co">    ----------</span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="co">    column</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a><span class="co">        The series to hash</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a><span class="co">    index</span></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a><span class="co">        The starting index (defaults to 1)</span></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># enforce 0- or 1-indexation</span></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> indexation <span class="kw">not</span> <span class="kw">in</span> [<span class="dv">0</span>, <span class="dv">1</span>]:</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">"Must choose either 0- or 1-indexation."</span>)</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># convert the series to a category</span></span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> categories <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>        category_series <span class="op">=</span> series.astype(<span class="st">"category"</span>)</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>        cat_type <span class="op">=</span> CategoricalDtype(categories<span class="op">=</span>categories)</span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>        category_series <span class="op">=</span> series.astype(cat_type)</span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># get the hash</span></span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a>    hash_map <span class="op">=</span> category_series.cat.categories.values</span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a>    <span class="co"># map to one-indexed codes</span></span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a>    hashed_series <span class="op">=</span> (category_series.cat.codes <span class="op">+</span> indexation).values</span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> hash_map, hashed_series</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-tags="[]" data-execution_count="130">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> cmdstanpy, arviz</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> cmdstanpy <span class="im">import</span> CmdStanModel</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> typing <span class="im">import</span> Optional</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> enum <span class="im">import</span> Enum</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dataclasses <span class="im">import</span> dataclass</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> arviz <span class="im">import</span> InferenceData</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> FitType(Enum):</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>    OPTIMIZE <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>    SAMPLE <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a><span class="at">@dataclass</span></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> SelectionData:</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>    N_verb: <span class="bu">int</span></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>    N_frame: <span class="bu">int</span></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>    N_component: <span class="bu">int</span></span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>    N_subj: <span class="bu">int</span></span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>    N_resp: <span class="bu">int</span></span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>    N_resp_levels: <span class="bu">int</span></span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>    verb: ndarray</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>    frame: ndarray</span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>    subj: ndarray</span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>    resp: ndarray</span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> UnconstrainedSelectionModel:</span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a>    stan_file <span class="op">=</span> <span class="st">"./models/fuzzy-logic-factorization.stan"</span></span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a>    data_class <span class="op">=</span> SelectionData</span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, n_component: <span class="bu">int</span>):</span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model <span class="op">=</span> CmdStanModel(stan_file<span class="op">=</span><span class="va">self</span>.stan_file)</span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n_component <span class="op">=</span> n_component</span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-33"><a href="#cb7-33" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> construct_model_data(<span class="va">self</span>, data: pd.DataFrame):</span>
<span id="cb7-34"><a href="#cb7-34" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.verb_hash_map, verb_hashed <span class="op">=</span> hash_series(data.verb)</span>
<span id="cb7-35"><a href="#cb7-35" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.frame_hash_map, frame_hashed <span class="op">=</span> hash_series(data.frame)</span>
<span id="cb7-36"><a href="#cb7-36" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.subj_hash_map, subj_hashed <span class="op">=</span> hash_series(data.participant)</span>
<span id="cb7-37"><a href="#cb7-37" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-38"><a href="#cb7-38" aria-hidden="true" tabindex="-1"></a>        model_data <span class="op">=</span> {</span>
<span id="cb7-39"><a href="#cb7-39" aria-hidden="true" tabindex="-1"></a>            <span class="st">"N_verb"</span>: <span class="va">self</span>.verb_hash_map.shape[<span class="dv">0</span>],</span>
<span id="cb7-40"><a href="#cb7-40" aria-hidden="true" tabindex="-1"></a>            <span class="st">"N_frame"</span>: <span class="va">self</span>.frame_hash_map.shape[<span class="dv">0</span>],</span>
<span id="cb7-41"><a href="#cb7-41" aria-hidden="true" tabindex="-1"></a>            <span class="st">"N_component"</span>: <span class="va">self</span>.n_component,</span>
<span id="cb7-42"><a href="#cb7-42" aria-hidden="true" tabindex="-1"></a>            <span class="st">"N_subj"</span>: <span class="va">self</span>.subj_hash_map.shape[<span class="dv">0</span>],</span>
<span id="cb7-43"><a href="#cb7-43" aria-hidden="true" tabindex="-1"></a>            <span class="st">"N_resp"</span>: data.shape[<span class="dv">0</span>],</span>
<span id="cb7-44"><a href="#cb7-44" aria-hidden="true" tabindex="-1"></a>            <span class="st">"N_resp_levels"</span>: <span class="dv">7</span>,</span>
<span id="cb7-45"><a href="#cb7-45" aria-hidden="true" tabindex="-1"></a>            <span class="st">"verb"</span>: verb_hashed,</span>
<span id="cb7-46"><a href="#cb7-46" aria-hidden="true" tabindex="-1"></a>            <span class="st">"frame"</span>: frame_hashed,</span>
<span id="cb7-47"><a href="#cb7-47" aria-hidden="true" tabindex="-1"></a>            <span class="st">"subj"</span>: subj_hashed,</span>
<span id="cb7-48"><a href="#cb7-48" aria-hidden="true" tabindex="-1"></a>            <span class="st">"resp"</span>: data.response.astype(<span class="bu">int</span>).values</span>
<span id="cb7-49"><a href="#cb7-49" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb7-50"><a href="#cb7-50" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-51"><a href="#cb7-51" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> model_data</span>
<span id="cb7-52"><a href="#cb7-52" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-53"><a href="#cb7-53" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _validate_data(<span class="va">self</span>):</span>
<span id="cb7-54"><a href="#cb7-54" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.data_class(<span class="op">**</span><span class="va">self</span>.model_data)</span>
<span id="cb7-55"><a href="#cb7-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-56"><a href="#cb7-56" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> fit(</span>
<span id="cb7-57"><a href="#cb7-57" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>, </span>
<span id="cb7-58"><a href="#cb7-58" aria-hidden="true" tabindex="-1"></a>        data: pd.DataFrame,</span>
<span id="cb7-59"><a href="#cb7-59" aria-hidden="true" tabindex="-1"></a>        fit_type: FitType <span class="op">=</span> FitType.OPTIMIZE,</span>
<span id="cb7-60"><a href="#cb7-60" aria-hidden="true" tabindex="-1"></a>        save_dir: Optional[<span class="bu">str</span>] <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb7-61"><a href="#cb7-61" aria-hidden="true" tabindex="-1"></a>        verbose: <span class="bu">bool</span> <span class="op">=</span> <span class="va">True</span>, </span>
<span id="cb7-62"><a href="#cb7-62" aria-hidden="true" tabindex="-1"></a>        show_progress: <span class="bu">bool</span> <span class="op">=</span> <span class="va">True</span></span>
<span id="cb7-63"><a href="#cb7-63" aria-hidden="true" tabindex="-1"></a>    ) <span class="op">-&gt;</span> InferenceData:</span>
<span id="cb7-64"><a href="#cb7-64" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model_data <span class="op">=</span> <span class="va">self</span>.construct_model_data(data)</span>
<span id="cb7-65"><a href="#cb7-65" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-66"><a href="#cb7-66" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._validate_data()</span>
<span id="cb7-67"><a href="#cb7-67" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-68"><a href="#cb7-68" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> verbose:</span>
<span id="cb7-69"><a href="#cb7-69" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"Fitting model..."</span>)</span>
<span id="cb7-70"><a href="#cb7-70" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-71"><a href="#cb7-71" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fit_type <span class="op">=</span> fit_type</span>
<span id="cb7-72"><a href="#cb7-72" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-73"><a href="#cb7-73" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> fit_type <span class="op">==</span> FitType.OPTIMIZE:</span>
<span id="cb7-74"><a href="#cb7-74" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.raw_model_fit <span class="op">=</span> <span class="va">self</span>.model.optimize(</span>
<span id="cb7-75"><a href="#cb7-75" aria-hidden="true" tabindex="-1"></a>                data<span class="op">=</span><span class="va">self</span>.model_data</span>
<span id="cb7-76"><a href="#cb7-76" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb7-77"><a href="#cb7-77" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb7-78"><a href="#cb7-78" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.raw_model_fit <span class="op">=</span> <span class="va">self</span>.model.sample(</span>
<span id="cb7-79"><a href="#cb7-79" aria-hidden="true" tabindex="-1"></a>                data<span class="op">=</span><span class="va">self</span>.model_data, </span>
<span id="cb7-80"><a href="#cb7-80" aria-hidden="true" tabindex="-1"></a>                show_progress<span class="op">=</span>show_progress</span>
<span id="cb7-81"><a href="#cb7-81" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb7-82"><a href="#cb7-82" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-83"><a href="#cb7-83" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> save_dir <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb7-84"><a href="#cb7-84" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> verbose:</span>
<span id="cb7-85"><a href="#cb7-85" aria-hidden="true" tabindex="-1"></a>                <span class="bu">print</span>(<span class="st">"Saving model..."</span>)</span>
<span id="cb7-86"><a href="#cb7-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-87"><a href="#cb7-87" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.save(save_dir)</span>
<span id="cb7-88"><a href="#cb7-88" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-89"><a href="#cb7-89" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> verbose:</span>
<span id="cb7-90"><a href="#cb7-90" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"Saving model..."</span>)</span>
<span id="cb7-91"><a href="#cb7-91" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-92"><a href="#cb7-92" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span></span>
<span id="cb7-93"><a href="#cb7-93" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-94"><a href="#cb7-94" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> pointwise_log_likelihoods(<span class="va">self</span>, data: Optional[pd.DataFrame] <span class="op">=</span> <span class="va">None</span>, <span class="op">**</span>kwargs) <span class="op">-&gt;</span> InferenceData:</span>
<span id="cb7-95"><a href="#cb7-95" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> data <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb7-96"><a href="#cb7-96" aria-hidden="true" tabindex="-1"></a>            model_data <span class="op">=</span> <span class="va">self</span>.model_data</span>
<span id="cb7-97"><a href="#cb7-97" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb7-98"><a href="#cb7-98" aria-hidden="true" tabindex="-1"></a>            model_data <span class="op">=</span> <span class="va">self</span>.construct_model_data(data, <span class="op">**</span>kwargs)</span>
<span id="cb7-99"><a href="#cb7-99" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb7-100"><a href="#cb7-100" aria-hidden="true" tabindex="-1"></a>        log_likelihoods <span class="op">=</span> <span class="va">self</span>.model.generate_quantities(</span>
<span id="cb7-101"><a href="#cb7-101" aria-hidden="true" tabindex="-1"></a>            data<span class="op">=</span>model_data, </span>
<span id="cb7-102"><a href="#cb7-102" aria-hidden="true" tabindex="-1"></a>            previous_fit<span class="op">=</span><span class="va">self</span>.raw_model_fit</span>
<span id="cb7-103"><a href="#cb7-103" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb7-104"><a href="#cb7-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-105"><a href="#cb7-105" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> arviz.from_cmdstanpy(log_likelihoods)</span>
<span id="cb7-106"><a href="#cb7-106" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-107"><a href="#cb7-107" aria-hidden="true" tabindex="-1"></a>    <span class="at">@property</span></span>
<span id="cb7-108"><a href="#cb7-108" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> model_fit(<span class="va">self</span>):</span>
<span id="cb7-109"><a href="#cb7-109" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> fit_type <span class="op">==</span> FitType.OPTIMIZE:</span>
<span id="cb7-110"><a href="#cb7-110" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="va">self</span>.raw_model_fit</span>
<span id="cb7-111"><a href="#cb7-111" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb7-112"><a href="#cb7-112" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> arviz.from_cmdstanpy(<span class="va">self</span>.raw_model_fit)</span>
<span id="cb7-113"><a href="#cb7-113" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-114"><a href="#cb7-114" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> save(<span class="va">self</span>, save_dir: <span class="bu">str</span> <span class="op">=</span> <span class="st">"."</span>):</span>
<span id="cb7-115"><a href="#cb7-115" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.raw_model_fit.save_csvfiles(save_dir)</span>
<span id="cb7-116"><a href="#cb7-116" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-117"><a href="#cb7-117" aria-hidden="true" tabindex="-1"></a>    <span class="at">@classmethod</span></span>
<span id="cb7-118"><a href="#cb7-118" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> from_csv(cls, path: <span class="bu">str</span>, <span class="op">**</span>kwargs):</span>
<span id="cb7-119"><a href="#cb7-119" aria-hidden="true" tabindex="-1"></a>        model <span class="op">=</span> cls(<span class="op">**</span>kwargs)</span>
<span id="cb7-120"><a href="#cb7-120" aria-hidden="true" tabindex="-1"></a>        model.raw_model_fit <span class="op">=</span> cmdstanpy.from_csv(path)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-tags="[]" data-execution_count="313">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> UnconstrainedSelectionModel(<span class="dv">2</span>, <span class="fl">1.</span>, <span class="va">False</span>).fit(data, fit_type<span class="op">=</span>FitType.OPTIMIZE)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-error">
<pre><code>TypeError: FuzzyLogicFactorizationModel.__init__() takes 2 positional arguments but 4 were given</code></pre>
</div>
</div>
<div class="cell" data-tags="[]" data-execution_count="32">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> spearmanr</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>data[<span class="st">"prediction"</span>] <span class="op">=</span> model.raw_model_fit.stan_variable(<span class="st">'mu'</span>)</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> sns.boxplot(data, x<span class="op">=</span><span class="st">"response"</span>, y<span class="op">=</span><span class="st">"prediction"</span>)</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>spearmanr(data[[<span class="st">"response"</span>, <span class="st">"prediction"</span>]])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="32">
<pre><code>SignificanceResult(statistic=0.40889891447222454, pvalue=0.0)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="index_files/figure-html/cell-9-output-2.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-tags="[]" data-execution_count="33">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>model.raw_model_fit.stan_variables()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="33">
<pre><code>{'verb_component_prior_aux': array([0.128443, 0.125146, 0.656217, 0.779327, 0.827608, 0.312784,
        0.848003, 0.808027, 0.422028, 0.375185, 0.353681, 0.327297,
        0.733399, 0.854325, 0.778634, 0.227325, 0.146691, 0.721576,
        0.527884, 0.123827, 0.275521, 0.370464, 0.702175, 0.879695,
        0.138056, 0.174648, 0.21029 , 0.766008, 0.151918, 0.292663]),
 'frame_component_prior_aux': array([0.128859, 0.439508, 0.856828, 0.384938, 0.652028, 0.662436,
        0.824644, 0.492884, 0.45846 , 0.13276 , 0.347303, 0.768129,
        0.386184, 0.876037, 0.26281 , 0.127104, 0.329268, 0.743779,
        0.685283, 0.393859, 0.327524, 0.212908, 0.138822, 0.342837,
        0.870582, 0.866983, 0.29064 , 0.391456, 0.875311, 0.81953 ]),
 'verb_component_prior_precision': array([3.94606 , 6.85934 , 2.14684 , 0.355818, 4.316   , 0.66685 ,
        2.00714 , 2.95657 , 0.277982, 0.313856, 3.66564 , 3.61452 ,
        0.270871, 6.10048 , 0.198073, 0.690347, 0.306669, 0.487583,
        0.321813, 0.260728, 0.31567 , 2.29999 , 2.5018  , 0.404016,
        1.23719 , 4.43367 , 0.811716, 2.26288 , 4.82592 , 0.685407]),
 'frame_component_prior_precision': array([2.47689 , 6.94865 , 1.14166 , 0.836653, 0.262048, 3.33315 ,
        1.06894 , 2.26159 , 0.192062, 2.89519 , 0.906216, 0.373096,
        2.43317 , 0.250202, 0.304647, 0.292793, 2.11231 , 0.964812,
        2.65006 , 1.22376 , 2.49388 , 1.91038 , 1.1461  , 0.1658  ,
        1.44303 , 4.07296 , 2.55249 , 3.40739 , 6.50941 , 0.165849]),
 'verb_component': array([[0.631036, 0.12458 , 0.750635, ..., 0.713654, 0.701122, 0.859162],
        [0.484222, 0.319344, 0.861388, ..., 0.580126, 0.725599, 0.86963 ],
        [0.851271, 0.499822, 0.655394, ..., 0.187742, 0.133366, 0.73629 ],
        ...,
        [0.456762, 0.502419, 0.210684, ..., 0.217777, 0.839811, 0.631872],
        [0.134225, 0.769278, 0.559535, ..., 0.195162, 0.213416, 0.876293],
        [0.207543, 0.879065, 0.863831, ..., 0.855847, 0.12572 , 0.339096]]),
 'frame_component': array([[0.148117, 0.139249, 0.867981, ..., 0.217972, 0.787618, 0.690592],
        [0.143749, 0.607432, 0.713306, ..., 0.49488 , 0.72556 , 0.812185],
        [0.239083, 0.560894, 0.251543, ..., 0.14582 , 0.198369, 0.138268],
        ...,
        [0.584786, 0.405192, 0.493362, ..., 0.797333, 0.353267, 0.154806],
        [0.298372, 0.119673, 0.287615, ..., 0.747307, 0.389407, 0.160099],
        [0.66831 , 0.50375 , 0.194715, ..., 0.608931, 0.436724, 0.751809]]),
 'scale': 0.342677,
 'subject_intercept': array([ 4.74424e-01,  5.81169e-01,  1.52451e-01, -1.21523e+00,
        -3.76642e-01,  4.12773e-01,  4.93730e-01, -1.55746e+00,
         4.30370e-01, -2.45055e-03, -4.16315e-01, -9.36667e-01,
        -1.57720e+00,  8.99032e-01, -3.84752e-01, -7.86858e-01,
         5.51128e-01, -8.23691e-01,  2.46000e-01, -9.24073e-01,
        -5.02015e-01,  5.28516e-01,  7.43493e-03, -6.26881e-02,
        -1.12118e+00, -8.09475e-01,  8.53874e-01,  3.55306e-01,
        -1.24594e+00, -6.87277e-02, -1.80899e-01, -1.91844e-01,
         3.68925e-01, -1.21469e+00, -9.09536e-01, -1.11137e+00,
         1.25902e-01, -3.76982e-01,  7.98636e-01,  5.91311e-02,
        -6.42357e-01,  2.30568e-01, -5.81096e-01,  3.53952e-01,
         2.48313e-01, -1.33410e+00,  7.01760e-01,  6.26869e-01,
        -1.04620e+00, -6.86099e-03,  6.30465e-01,  8.49885e-01,
        -1.13165e+00, -2.04142e+00,  3.30557e-01,  9.89475e-01,
         5.87273e-01, -8.70097e-01,  1.64817e+00, -3.46082e-01,
         2.48271e-01, -1.45393e-01,  7.38582e-01, -3.39631e-01,
         9.56582e-02, -7.41979e-01,  6.49592e-01,  9.33503e-01,
         1.56984e+00, -4.53466e-01,  5.06329e-01, -5.76661e-01,
         2.65088e+00,  9.89681e-01,  1.07587e+00, -1.29228e+00,
         4.34748e-01,  1.30630e-01,  5.28397e-02, -1.84634e+00,
        -3.37688e-02, -5.73385e-01, -1.37377e+00, -3.23291e-01,
         5.50752e-01, -1.52814e+00,  7.78625e-01,  2.76436e-01,
         3.18751e-01, -2.71143e-01,  2.58047e-01, -5.05047e-01,
         5.30805e-01,  3.67817e-01,  2.02014e-02, -1.44350e+00,
         3.49213e-02,  2.71423e-01,  5.93516e-01,  6.83710e-01,
        -8.02496e-01, -1.08427e+00, -7.12690e-01, -5.94339e-01,
         1.18571e+00, -1.60786e+00,  5.32612e-02,  7.92068e-01,
        -6.67420e-02,  8.86533e-02,  4.38447e-01,  1.93246e-02,
         4.69271e-01,  1.50089e-01, -6.52321e-03, -7.05430e-01,
         1.02084e+00, -1.44481e-01,  1.34385e+00, -7.06620e-01,
         5.99348e-01,  2.23753e-01,  3.03024e-01, -1.16437e+00,
         6.20510e-01,  2.39010e-01,  6.33210e-01,  7.83420e-02,
        -5.35018e-01, -7.68897e-01,  2.48338e-01, -8.21896e-01,
        -1.50753e-02,  7.70642e-01,  4.07584e-01, -3.21323e-01,
         2.71655e-01, -5.90605e-02,  4.25167e-01,  3.13657e-02,
        -8.97341e-01, -1.77354e+00,  8.26726e-01,  1.76854e+00,
        -5.74292e-01,  5.09806e-01,  7.04516e-01, -8.08557e-03,
        -9.93954e-01,  8.03876e-02,  6.90031e-01,  4.02817e-01,
        -7.98484e-01, -8.91539e-01,  1.28409e-01,  1.71990e-01,
         7.75928e-01, -1.03386e+00,  4.42372e-02,  5.15516e-01,
        -3.44331e-01,  1.18200e-03,  1.13494e+00, -4.79905e-02,
        -2.73264e-01, -5.49827e-01, -2.60540e-01,  2.46635e-01,
         6.07760e-01,  7.34930e-01,  3.75429e-01,  3.40623e-01,
         4.57374e-02,  1.63316e-01, -6.37417e-01, -3.88078e-01,
         9.41364e-02, -8.36724e-02,  5.30396e-01,  5.32977e-01,
        -7.62135e-02, -5.23548e-01, -1.02387e+00,  6.36379e-01,
        -1.52251e+00,  1.21847e-01, -2.27075e-01, -1.19180e+00,
         8.35557e-01, -8.33588e-01, -1.19962e-01,  2.15247e-01,
        -7.90993e-01, -3.38465e-01,  6.49465e-01, -9.55126e-01,
        -3.13049e-02,  1.81868e+00,  8.47810e-02, -2.25852e+00,
         2.29785e-01, -6.79092e-01, -3.57089e-02,  1.18436e+00,
         3.88629e-01, -1.56359e-01, -9.52949e-01,  1.04602e+00,
         1.24202e+00,  9.83614e-01, -2.74759e-02,  6.20111e-01,
         5.98930e-01,  2.17615e-01,  7.86091e-01, -8.29147e-01,
         6.39468e-01, -1.25558e+00,  9.26507e-03, -3.13464e-01,
         9.38088e-01,  2.27649e+00, -2.53768e+00, -3.83406e-01,
         2.79527e-01,  6.11449e-01,  6.82550e-01,  3.97554e-01,
         4.47691e-01, -5.54276e-01,  1.76410e-01,  8.73556e-02,
        -3.99629e-01,  6.94054e-01,  3.43673e-01,  1.01187e+00,
        -2.18517e+00, -5.70515e-01, -6.79002e-01,  2.22539e-01,
         4.84307e-01,  2.40932e+00, -6.47600e-01,  6.68794e-01,
         6.12225e-01,  5.45909e-01,  6.54368e-01,  1.03091e-02,
        -1.41465e-01,  1.56109e-01, -1.41005e+00,  7.13663e-01,
         1.11277e-01,  3.64858e-01,  3.34982e-01,  6.26717e-01,
         5.26949e-01, -4.01259e-01,  9.06606e-01, -1.19428e+00,
         1.52844e-01,  1.01377e+00,  6.43483e-01,  6.97471e-01,
         1.14382e+00, -3.99871e-03,  2.66114e-01, -1.49591e-01,
         2.57018e-01, -4.66524e-01,  9.44353e-01,  2.17188e-01,
         8.85961e-01,  2.14621e-02,  1.02294e+00,  6.70271e-01,
        -5.41427e-01, -1.48982e-01, -3.07123e-01, -1.10756e+00,
        -3.00867e-01,  3.96404e-01,  1.59119e-01, -3.03103e-01,
         5.77373e-02, -8.40116e-01, -5.53462e-01,  8.28390e-01,
        -4.80625e-01, -1.49606e+00,  1.87902e-01, -1.46884e+00,
        -6.33657e-01, -3.71626e-01, -8.77436e-01, -7.03373e-02,
         7.40037e-01, -8.93051e-01,  1.30231e+00, -1.45159e-01,
        -2.01342e-01, -1.97197e+00, -5.74940e-01,  8.54658e-01,
        -1.43819e-01, -7.21665e-02, -5.45656e-01,  1.07217e+00,
        -6.01677e-01, -1.59161e+00,  4.54926e-01, -1.59611e+00,
         2.19739e-01,  4.70924e-01, -5.36177e-01,  7.58519e-01,
         1.27801e-01,  4.78080e-01,  2.33537e-01, -6.89422e-01,
         8.83141e-01,  4.86207e-01,  2.37032e-01,  8.08333e-01,
         7.32945e-01, -1.17114e+00,  7.33238e-01, -1.08420e+00,
         1.93273e+00,  6.09959e-01,  1.83113e+00,  6.52965e-01,
         1.24981e+00, -2.20897e-01, -8.82339e-02, -8.73349e-01,
         7.39357e-01, -7.77731e-02,  7.29637e-01, -1.15229e+00,
         8.94273e-02,  2.04990e-01,  5.52298e-02, -1.13349e+00,
         8.61106e-01, -4.88224e-01,  9.01410e-01, -9.71639e-01,
         2.77285e-01, -1.21580e-01, -7.44914e-01,  8.31934e-01,
         2.40882e-01,  6.88906e-01, -7.45428e-01,  6.96323e-02,
        -1.30449e-01, -1.05073e+00,  5.51754e-02,  7.47091e-01,
        -1.19242e+00, -2.65441e-01, -2.56910e-01,  4.35275e-01,
        -1.23404e-01,  9.67246e-02,  2.44612e-01, -9.98314e-01,
         1.17133e-01,  1.50953e-01,  3.72173e-01,  1.81027e+00,
         6.08010e-01,  1.65044e-01,  6.97150e-01, -8.59175e-01,
         3.64691e-01, -9.03866e-01, -1.71463e-01, -4.97181e-01,
         3.59801e-01,  2.02395e-01, -6.40316e-01, -1.36781e+00,
         6.25449e-01,  3.91780e-01,  1.22762e-01, -2.09249e+00,
         1.59385e-01,  1.02802e+00,  1.30957e+00,  5.12622e-01,
        -3.10065e-03,  1.38047e+00,  6.46599e-01,  1.27330e+00,
         1.47127e+00, -1.94907e-01,  1.02943e+00, -1.27448e-01,
         6.99052e-01, -1.70971e-01,  2.70797e-01, -4.46774e-01,
        -2.18086e-01,  1.76370e-01,  3.67291e-01,  7.24871e-01,
         6.20429e-01,  4.54635e-01,  1.60206e-01,  2.11376e-01,
         6.58752e-01, -1.21890e+00, -3.25728e+00, -6.34088e-01,
         3.30526e-01,  3.92794e-01,  8.37157e-01, -8.29547e-02,
         1.07893e+00, -3.17053e-01, -1.09768e+00, -8.34819e-01,
         3.79134e-01,  1.58639e-01,  3.88338e-01, -1.26107e+00,
        -1.44337e+00, -6.61995e-01,  1.56509e-01,  1.07669e+00,
         4.32753e-01, -4.59803e-01, -3.60443e-01,  1.37046e+00,
        -1.08646e+00, -7.79049e-01, -8.56338e-01,  7.26129e-01,
         1.11191e+00, -5.38990e-01,  8.07547e-01, -5.00520e-01,
         9.30688e-01, -1.08224e+00, -2.32093e-01,  1.09179e+00,
        -1.07688e-01, -1.43090e+00, -3.02642e-01,  7.92652e-01,
         9.86079e-02,  6.58361e-01, -1.05491e+00,  8.25960e-01,
         1.26836e+00,  5.04173e-01,  8.12961e-01,  4.23600e-01,
         1.54567e+00, -1.27906e+00, -2.46772e-01, -6.27626e-01,
        -1.20863e+00,  8.53035e-01, -1.93384e+00, -1.37296e+00,
         7.02432e-03, -1.33295e+00, -3.05969e-01,  4.15330e-01,
         4.14983e-01,  3.42292e-01, -1.29219e+00,  1.79922e-01,
         2.98742e-02, -8.96372e-01,  3.42554e-01, -6.75668e-01,
        -8.03111e-02,  7.92982e-01,  1.09564e+00,  5.07590e-01,
        -3.43324e-01,  5.83436e-01, -8.66205e-01,  4.49343e-01,
         2.74063e-01, -1.07467e-03, -8.82549e-01,  3.26919e-02,
        -9.19501e-01,  1.00034e+00,  8.26838e-01,  3.25850e-01,
        -2.18428e-01,  3.44479e-01, -5.93609e-01,  5.44990e-01,
         4.69017e-01,  5.32558e-01, -5.76181e-01, -3.87983e-02,
        -1.38106e-02,  8.28738e-02,  6.83411e-01, -5.76905e-01,
         8.58287e-01,  1.16795e+00,  9.24057e-01,  1.14211e+00,
         4.92365e-02,  1.29232e-01,  8.43683e-02,  1.75745e-01,
         4.00143e-02,  6.23554e-01,  1.75570e-01, -1.96493e+00,
        -7.44102e-01, -1.19723e+00,  6.60265e-01,  2.02981e+00,
         7.68875e-01,  5.95512e-02, -2.64178e+00,  1.04027e-01,
        -4.58022e-02,  1.01061e+00, -6.00788e-01, -5.27978e-01,
         9.55317e-01,  1.01556e+00,  1.24528e-01, -7.53803e-01,
         1.64385e-01,  1.13961e-01, -2.21407e-01, -4.54925e-01,
        -4.62257e-01, -1.72978e-01, -1.51815e-01, -1.03305e+00,
         4.59110e-01, -3.58224e-02,  1.29174e-01,  1.17854e+00,
        -7.00523e-01,  1.18655e-01,  4.62443e-01, -2.73184e-01,
         4.26115e-01,  6.13271e-01, -9.68027e-02,  4.41299e-01,
        -6.01965e-01,  3.65829e-01,  3.65260e-01, -1.10523e+00,
         2.34591e-01,  8.73458e-01,  3.58993e-02, -5.87541e-03,
        -8.15921e-01,  5.31774e-01, -3.70548e-02,  2.39167e-01,
        -6.25066e-01,  2.41151e-01,  2.02517e-01,  1.17971e+00,
        -1.19871e+00, -3.86237e-01,  1.93197e-01,  3.59750e-01,
        -2.99647e-01, -1.87421e-01,  3.84670e+00, -4.39198e-01,
         6.66417e-01,  6.64133e-01, -1.23445e+00,  4.13822e-02,
         9.10363e-01,  7.03194e-01,  6.37879e-01, -1.54531e+00,
        -1.93263e+00,  5.77746e-01,  1.29742e+00, -2.80598e-01,
        -7.05573e-01, -3.06071e+00, -4.75422e-01,  3.65198e-01,
         9.74521e-01,  7.32553e-01, -8.00326e-01,  4.41971e-01,
        -1.95516e-01, -2.43647e-01, -6.74946e-02, -1.44551e-01,
        -1.31030e-01,  5.22529e-01,  2.52823e-01, -1.03373e-01,
        -6.31948e-01, -2.81622e-01, -9.36986e-04,  1.54589e-02,
        -5.68423e-01,  3.00506e-01,  4.62269e-01, -3.53738e-01,
        -2.06421e+00,  2.69334e-01,  3.93483e-01, -1.14338e+00,
         1.07983e+00,  5.48180e-01, -5.45344e-01,  3.05104e-02,
         3.15502e-01, -1.58942e+00, -9.85861e-01,  1.49249e-01,
        -7.88658e-01,  6.68504e-01,  5.33568e-01,  7.36544e-01,
        -1.05825e+00,  1.02985e-01, -2.35514e+00, -7.23614e-01,
        -6.70479e-01, -1.46119e-01,  4.97112e-01, -1.04240e+00,
         7.24753e-01,  5.18291e-01, -1.37861e+00, -1.04266e+00,
         4.86643e-01,  3.66984e-01,  7.86917e-01, -1.19986e+00,
        -9.10797e-02, -3.21514e-01,  6.13457e-01, -4.11578e-01,
        -7.19788e-02, -5.84740e-01, -1.54333e+00,  9.77076e-01,
         5.75926e-01, -1.00221e+00, -3.25447e-01, -1.46595e+00,
        -6.01940e-01, -7.13286e-01, -6.50424e-01,  7.77025e-01,
         6.20243e-01,  1.30215e-01,  2.77166e-03,  5.73520e-01,
        -9.29842e-01, -6.83950e-01,  5.97183e-01,  1.02583e+00,
         2.38601e-01, -2.39362e-01,  1.32720e-01,  4.07196e-01,
         7.34207e-01,  3.55592e-01,  3.64512e-01,  3.96730e-01,
         4.66226e-01, -7.16174e-01,  8.75962e-02,  2.02811e-01,
        -4.34386e-01, -8.45573e-01,  1.04871e+00,  5.96921e-01,
        -1.73109e+00,  7.61483e-01,  6.69625e-01,  1.85631e-01,
         2.67182e-01,  1.09866e+00, -5.32408e-01,  6.28556e-01,
         8.70480e-01, -1.96992e+00,  6.84554e-01, -3.95174e-01,
         2.01807e-01,  2.72352e-01, -5.72349e-01,  4.86605e-01,
         4.87756e-01,  3.66553e-01,  3.28475e-01,  3.75401e-01,
         5.53631e-01,  6.53921e-01, -1.49613e+00, -6.38289e-01,
        -1.65964e+00,  3.01679e-01,  8.20036e-03, -7.31041e-01,
        -7.63256e-02, -3.52873e-01,  1.07270e-01,  1.01285e+00,
        -1.52660e-01, -7.00161e-02, -8.24873e-01, -4.52995e-01,
        -3.28376e-01, -4.90847e-01, -2.89744e-01]),
 'cutpoints': array([-0.720339,  0.18709 ,  0.552617,  0.906846,  1.3986  ,  2.15084 ]),
 'verb_component_prior_mean': array([1.28443e-01, 1.60741e-02, 1.05481e-02, 8.22040e-03, 6.80327e-03,
        2.12795e-03, 1.80451e-03, 1.45810e-03, 6.15357e-04, 2.30873e-04,
        8.16554e-05, 2.67256e-05, 1.96005e-05, 1.67452e-05, 1.30384e-05,
        2.96395e-06, 4.34786e-07, 3.13732e-07, 1.65614e-07, 2.05075e-08,
        5.65024e-09, 2.09321e-09, 1.46980e-09, 1.29298e-09, 1.78503e-10,
        3.11753e-11, 6.55585e-12, 5.02183e-12, 7.62907e-13, 2.23275e-13]),
 'verb_component_prior_alpha': array([5.06843e-01, 1.10258e-01, 2.26451e-02, 2.92497e-03, 2.93629e-02,
        1.41903e-03, 3.62190e-03, 4.31096e-03, 1.71058e-04, 7.24609e-05,
        2.99320e-04, 9.66002e-05, 5.30920e-06, 1.02154e-04, 2.58255e-06,
        2.04616e-06, 1.33335e-07, 1.52970e-07, 5.32966e-08, 5.34687e-09,
        1.78361e-09, 4.81436e-09, 3.67715e-09, 5.22383e-10, 2.20843e-10,
        1.38221e-10, 5.32149e-12, 1.13638e-11, 3.68172e-12, 1.53034e-13]),
 'verb_component_prior_beta': array([3.43922 , 6.74908 , 2.1242  , 0.352893, 4.28663 , 0.665431,
        2.00352 , 2.95226 , 0.277811, 0.313784, 3.66534 , 3.61443 ,
        0.270865, 6.10038 , 0.19807 , 0.690345, 0.306669, 0.487583,
        0.321812, 0.260728, 0.31567 , 2.29999 , 2.5018  , 0.404016,
        1.23719 , 4.43367 , 0.811716, 2.26288 , 4.82592 , 0.685407]),
 'frame_component_prior_mean': array([1.28859e-01, 5.66346e-02, 4.85261e-02, 1.86795e-02, 1.21796e-02,
        8.06819e-03, 6.65339e-03, 3.27935e-03, 1.50345e-03, 1.99599e-04,
        6.93213e-05, 5.32477e-05, 2.05634e-05, 1.80143e-05, 4.73435e-06,
        6.01754e-07, 1.98138e-07, 1.47371e-07, 1.00991e-07, 3.97762e-08,
        1.30277e-08, 2.77370e-09, 3.85050e-10, 1.32009e-10, 1.14925e-10,
        9.96380e-11, 2.89588e-11, 1.13361e-11, 9.92260e-12, 8.13187e-12]),
 'frame_component_prior_alpha': array([3.19170e-01, 3.93534e-01, 5.54003e-02, 1.56283e-02, 3.19164e-03,
        2.68925e-02, 7.11207e-03, 7.41656e-03, 2.88757e-04, 5.77876e-04,
        6.28201e-05, 1.98665e-05, 5.00343e-05, 4.50722e-06, 1.44231e-06,
        1.76189e-07, 4.18530e-07, 1.42186e-07, 2.67632e-07, 4.86764e-08,
        3.24894e-08, 5.29883e-09, 4.41308e-10, 2.18872e-11, 1.65840e-10,
        4.05822e-10, 7.39170e-11, 3.86265e-11, 6.45902e-11, 1.34866e-12]),
 'frame_component_prior_beta': array([2.15772 , 6.55512 , 1.08626 , 0.821024, 0.258857, 3.30626 ,
        1.06183 , 2.25418 , 0.191774, 2.89461 , 0.906153, 0.373076,
        2.43312 , 0.250198, 0.304646, 0.292793, 2.11231 , 0.964812,
        2.65006 , 1.22376 , 2.49388 , 1.91038 , 1.1461  , 0.1658  ,
        1.44303 , 4.07296 , 2.55249 , 3.40739 , 6.50941 , 0.165849]),
 'verb_frame': array([[0.999849, 0.999951, 0.999031, ..., 0.998878, 0.999747, 0.999946],
        [0.999996, 0.999996, 0.999937, ..., 0.999911, 0.999997, 0.999995],
        [0.999773, 0.999885, 0.999436, ..., 0.999494, 0.999845, 0.99987 ],
        ...,
        [0.99999 , 0.999953, 0.999848, ..., 0.999734, 0.999978, 0.99993 ],
        [0.999919, 0.999907, 0.999864, ..., 0.999264, 0.999826, 0.999921],
        [0.999754, 0.999943, 0.999812, ..., 0.99994 , 0.999983, 0.99995 ]]),
 'mu': array([-0.20531  , -0.325849 ,  1.5518   , ...,  0.0194879, -0.319544 ,
        -0.462354 ])}</code></pre>
</div>
</div>
<div class="cell" data-tags="[]" data-execution_count="36">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>torch.tensor??</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div class="ansi-escaped-output">
<pre><span class="ansi-red-fg">Docstring:</span>
tensor(data, *, dtype=None, device=None, requires_grad=False, pin_memory=False) -&gt; Tensor
Constructs a tensor with no autograd history (also known as a "leaf tensor", see :doc:`/notes/autograd`) by copying :attr:`data`.
.. warning::
    When working with tensors prefer using :func:`torch.Tensor.clone`,
    :func:`torch.Tensor.detach`, and :func:`torch.Tensor.requires_grad_` for
    readability. Letting `t` be a tensor, ``torch.tensor(t)`` is equivalent to
    ``t.clone().detach()``, and ``torch.tensor(t, requires_grad=True)``
    is equivalent to ``t.clone().detach().requires_grad_(True)``.
.. seealso::
    :func:`torch.as_tensor` preserves autograd history and avoids copies where possible.
    :func:`torch.from_numpy` creates a tensor that shares storage with a NumPy array.
Args:
    data (array_like): Initial data for the tensor. Can be a list, tuple,
        NumPy ``ndarray``, scalar, and other types.
Keyword args:
    dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.
        Default: if ``None``, infers data type from :attr:`data`.
    device (:class:`torch.device`, optional): the device of the constructed tensor. If None and data is a tensor
        then the device of data is used. If None and data is not a tensor then
        the result tensor is constructed on the CPU.
    requires_grad (bool, optional): If autograd should record operations on the
        returned tensor. Default: ``False``.
    pin_memory (bool, optional): If set, returned tensor would be allocated in
        the pinned memory. Works only for CPU tensors. Default: ``False``.
Example::
    &gt;&gt;&gt; torch.tensor([[0.1, 1.2], [2.2, 3.1], [4.9, 5.2]])
    tensor([[ 0.1000,  1.2000],
            [ 2.2000,  3.1000],
            [ 4.9000,  5.2000]])
    &gt;&gt;&gt; torch.tensor([0, 1])  # Type inference on data
    tensor([ 0,  1])
    &gt;&gt;&gt; torch.tensor([[0.11111, 0.222222, 0.3333333]],
    ...              dtype=torch.float64,
    ...              device=torch.device('cuda:0'))  # creates a double tensor on a CUDA device
    tensor([[ 0.1111,  0.2222,  0.3333]], dtype=torch.float64, device='cuda:0')
    &gt;&gt;&gt; torch.tensor(3.14159)  # Create a zero-dimensional (scalar) tensor
    tensor(3.1416)
    &gt;&gt;&gt; torch.tensor([])  # Create an empty tensor (of size (0,))
    tensor([])
<span class="ansi-red-fg">Type:</span>      builtin_function_or_method</pre>
</div>
</div>
</div>
<div class="cell" data-tags="[]" data-execution_count="88">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="at">@dataclass</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> SelectionModelParameters:</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>    n_verb: <span class="bu">int</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>    n_frame: <span class="bu">int</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>    n_subj: <span class="bu">int</span></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>    n_resp_levels: <span class="bu">int</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a><span class="at">@dataclass</span></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> UnconstrainedSelectionModelParameters(SelectionModelParameters):</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>    n_component: <span class="bu">int</span></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a><span class="at">@dataclass</span></span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> SelectionData:</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>    verb: ndarray</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>    frame: ndarray</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>    subj: ndarray</span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a>    resp: ndarray</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-tags="[]" data-execution_count="80">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch <span class="im">import</span> Tensor</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> ordered_logistic_likelihood(value: Tensor, jumps: Tensor, center: <span class="bu">bool</span> <span class="op">=</span> <span class="va">True</span>) <span class="op">-&gt;</span> Tensor:</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Compute the ordered logistic likelihood given a value</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters</span></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a><span class="co">    ----------</span></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a><span class="co">    value</span></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a><span class="co">        The value to compute the likelihood for </span></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a><span class="co">        (shape: batch_size)</span></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a><span class="co">    jumps</span></span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a><span class="co">        The distance between cutpoints </span></span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a><span class="co">        (shape: batch_size x number of response levels - 1)</span></span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns</span></span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a><span class="co">    -------</span></span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a><span class="co">    log_likelihood</span></span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a><span class="co">        the ordered logistic log-likelihood</span></span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>    cutpoints <span class="op">=</span> torch.cumsum(jumps, <span class="dv">1</span>) </span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> center:</span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a>        cutpoints <span class="op">=</span> cutpoints <span class="op">-</span> cutpoints.mean()</span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a>    cdfs <span class="op">=</span> torch.sigmoid(cutpoints <span class="op">-</span> value[:,<span class="va">None</span>])</span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a>    low_prob <span class="op">=</span> torch.cat(</span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a>        [torch.zeros([cdfs.shape[<span class="dv">0</span>], <span class="dv">1</span>]), cdfs],</span>
<span id="cb16-30"><a href="#cb16-30" aria-hidden="true" tabindex="-1"></a>        axis<span class="op">=</span><span class="dv">1</span></span>
<span id="cb16-31"><a href="#cb16-31" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb16-32"><a href="#cb16-32" aria-hidden="true" tabindex="-1"></a>    high_prob <span class="op">=</span> torch.cat(</span>
<span id="cb16-33"><a href="#cb16-33" aria-hidden="true" tabindex="-1"></a>        [cdfs, torch.ones([cdfs.shape[<span class="dv">0</span>], <span class="dv">1</span>])],</span>
<span id="cb16-34"><a href="#cb16-34" aria-hidden="true" tabindex="-1"></a>        axis<span class="op">=</span><span class="dv">1</span></span>
<span id="cb16-35"><a href="#cb16-35" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb16-36"><a href="#cb16-36" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-37"><a href="#cb16-37" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> high_prob <span class="op">-</span> low_prob</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-tags="[]" data-execution_count="99">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> UnconstrainedSelectionModel(torch.nn.Module):</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>    parameter_class <span class="op">=</span> UnconstrainedSelectionModelParameters</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>    data_class <span class="op">=</span> SelectionData</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, parameters: UnconstrainedSelectionModelParameters):</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model_parameters <span class="op">=</span> parameters</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.verb_component_aux <span class="op">=</span> torch.nn.Parameter(</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>            torch.randn([</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>                parameters.n_verb, parameters.n_component</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>            ]), </span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>            requires_grad<span class="op">=</span><span class="va">True</span></span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.frame_component_aux <span class="op">=</span> torch.nn.Parameter(</span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a>            torch.randn([</span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a>                parameters.n_frame, parameters.n_component</span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a>            ]), </span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a>            requires_grad<span class="op">=</span><span class="va">True</span></span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.log_jumps <span class="op">=</span> torch.nn.Parameter(</span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a>            torch.ones([</span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a>                parameters.n_subj, parameters.n_resp_levels<span class="op">-</span><span class="dv">1</span></span>
<span id="cb17-26"><a href="#cb17-26" aria-hidden="true" tabindex="-1"></a>            ]), </span>
<span id="cb17-27"><a href="#cb17-27" aria-hidden="true" tabindex="-1"></a>            requires_grad<span class="op">=</span><span class="va">True</span></span>
<span id="cb17-28"><a href="#cb17-28" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb17-29"><a href="#cb17-29" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb17-30"><a href="#cb17-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-31"><a href="#cb17-31" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, data: SelectionData):</span>
<span id="cb17-32"><a href="#cb17-32" aria-hidden="true" tabindex="-1"></a>        verb_frame_prob <span class="op">=</span> <span class="va">self</span>.verb_frame_prob(data.verb, data.frame)</span>
<span id="cb17-33"><a href="#cb17-33" aria-hidden="true" tabindex="-1"></a>        verb_frame_logodds <span class="op">=</span> torch.log(verb_frame_prob) <span class="op">-</span> torch.log(<span class="fl">1.</span> <span class="op">-</span> verb_frame_prob)</span>
<span id="cb17-34"><a href="#cb17-34" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb17-35"><a href="#cb17-35" aria-hidden="true" tabindex="-1"></a>        jumps <span class="op">=</span> <span class="va">self</span>.jumps[data.subj]</span>
<span id="cb17-36"><a href="#cb17-36" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb17-37"><a href="#cb17-37" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> ordered_logistic_likelihood(</span>
<span id="cb17-38"><a href="#cb17-38" aria-hidden="true" tabindex="-1"></a>            verb_frame_logodds, jumps</span>
<span id="cb17-39"><a href="#cb17-39" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb17-40"><a href="#cb17-40" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb17-41"><a href="#cb17-41" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> verb_frame_prob(</span>
<span id="cb17-42"><a href="#cb17-42" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>, </span>
<span id="cb17-43"><a href="#cb17-43" aria-hidden="true" tabindex="-1"></a>        verb_idx: Optional[ndarray] <span class="op">=</span> <span class="va">None</span>, </span>
<span id="cb17-44"><a href="#cb17-44" aria-hidden="true" tabindex="-1"></a>        frame_idx: Optional[ndarray] <span class="op">=</span> <span class="va">None</span></span>
<span id="cb17-45"><a href="#cb17-45" aria-hidden="true" tabindex="-1"></a>    ) <span class="op">-&gt;</span> Tensor:</span>
<span id="cb17-46"><a href="#cb17-46" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> verb_idx <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="kw">or</span> frame_idx <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb17-47"><a href="#cb17-47" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="fl">1.</span> <span class="op">-</span> torch.prod(</span>
<span id="cb17-48"><a href="#cb17-48" aria-hidden="true" tabindex="-1"></a>                <span class="fl">1.</span> <span class="op">-</span> <span class="va">self</span>.verb_component_prob[verb_idx,:] <span class="op">*</span> </span>
<span id="cb17-49"><a href="#cb17-49" aria-hidden="true" tabindex="-1"></a>                     <span class="va">self</span>.frame_component_prob[frame_idx,:],</span>
<span id="cb17-50"><a href="#cb17-50" aria-hidden="true" tabindex="-1"></a>                axis<span class="op">=</span><span class="dv">1</span></span>
<span id="cb17-51"><a href="#cb17-51" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb17-52"><a href="#cb17-52" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> verb_idx <span class="kw">is</span> <span class="va">None</span> <span class="kw">and</span> frame_idx <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb17-53"><a href="#cb17-53" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="fl">1.</span> <span class="op">-</span> torch.prod(</span>
<span id="cb17-54"><a href="#cb17-54" aria-hidden="true" tabindex="-1"></a>                <span class="fl">1.</span> <span class="op">-</span> <span class="va">self</span>.verb_component_prob[:,<span class="va">None</span>,:] <span class="op">*</span> </span>
<span id="cb17-55"><a href="#cb17-55" aria-hidden="true" tabindex="-1"></a>                     <span class="va">self</span>.frame_component_prob[:,frame_idx,:],</span>
<span id="cb17-56"><a href="#cb17-56" aria-hidden="true" tabindex="-1"></a>                axis<span class="op">=</span><span class="dv">2</span></span>
<span id="cb17-57"><a href="#cb17-57" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb17-58"><a href="#cb17-58" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> verb_idx <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="kw">and</span> frame_idx <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb17-59"><a href="#cb17-59" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="fl">1.</span> <span class="op">-</span> torch.prod(</span>
<span id="cb17-60"><a href="#cb17-60" aria-hidden="true" tabindex="-1"></a>                <span class="fl">1.</span> <span class="op">-</span> <span class="va">self</span>.verb_component_prob[verb_idx,<span class="va">None</span>,:] <span class="op">*</span> </span>
<span id="cb17-61"><a href="#cb17-61" aria-hidden="true" tabindex="-1"></a>                     <span class="va">self</span>.frame_component_prob[<span class="va">None</span>,:,:],</span>
<span id="cb17-62"><a href="#cb17-62" aria-hidden="true" tabindex="-1"></a>                axis<span class="op">=</span><span class="dv">2</span></span>
<span id="cb17-63"><a href="#cb17-63" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb17-64"><a href="#cb17-64" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb17-65"><a href="#cb17-65" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="fl">1.</span> <span class="op">-</span> torch.prod(</span>
<span id="cb17-66"><a href="#cb17-66" aria-hidden="true" tabindex="-1"></a>                <span class="fl">1.</span> <span class="op">-</span> <span class="va">self</span>.verb_component_prob[:,<span class="va">None</span>,:] <span class="op">*</span> </span>
<span id="cb17-67"><a href="#cb17-67" aria-hidden="true" tabindex="-1"></a>                     <span class="va">self</span>.frame_component_prob[<span class="va">None</span>,:,:],</span>
<span id="cb17-68"><a href="#cb17-68" aria-hidden="true" tabindex="-1"></a>                axis<span class="op">=</span><span class="dv">2</span></span>
<span id="cb17-69"><a href="#cb17-69" aria-hidden="true" tabindex="-1"></a>            )       </span>
<span id="cb17-70"><a href="#cb17-70" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb17-71"><a href="#cb17-71" aria-hidden="true" tabindex="-1"></a>    <span class="at">@property</span></span>
<span id="cb17-72"><a href="#cb17-72" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> verb_component_prob(<span class="va">self</span>) <span class="op">-&gt;</span> Tensor:</span>
<span id="cb17-73"><a href="#cb17-73" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.sigmoid(<span class="va">self</span>.verb_component_aux)</span>
<span id="cb17-74"><a href="#cb17-74" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb17-75"><a href="#cb17-75" aria-hidden="true" tabindex="-1"></a>    <span class="at">@property</span></span>
<span id="cb17-76"><a href="#cb17-76" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> frame_component_prob(<span class="va">self</span>) <span class="op">-&gt;</span> Tensor:</span>
<span id="cb17-77"><a href="#cb17-77" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.sigmoid(<span class="va">self</span>.frame_component_aux)</span>
<span id="cb17-78"><a href="#cb17-78" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb17-79"><a href="#cb17-79" aria-hidden="true" tabindex="-1"></a>    <span class="at">@property</span></span>
<span id="cb17-80"><a href="#cb17-80" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> jumps(<span class="va">self</span>):</span>
<span id="cb17-81"><a href="#cb17-81" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.exp(<span class="va">self</span>.log_jumps)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-tags="[]" data-execution_count="100">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> abc <span class="im">import</span> ABC, abstractmethod</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> SelectionModelTrainer(ABC):</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>    data_class <span class="op">=</span> SelectionData</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">@abstractmethod</span></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> construct_model_parameters(<span class="va">self</span>, data: pd.DataFrame) <span class="op">-&gt;</span> SelectionModelParameters:</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">NotImplementedError</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> construct_model_data(<span class="va">self</span>, data: pd.DataFrame) <span class="op">-&gt;</span> SelectionData:            </span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">hasattr</span>(<span class="va">self</span>, <span class="st">"frame_hash_map"</span>):</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>            _, frame_hashed <span class="op">=</span> hash_series(data.frame, <span class="va">self</span>.frame_hash_map, indexation<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.frame_hash_map, frame_hashed <span class="op">=</span> hash_series(data.frame, indexation<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">hasattr</span>(<span class="va">self</span>, <span class="st">"verb_hash_map"</span>):</span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a>            _, verb_hashed <span class="op">=</span> hash_series(data.verb, <span class="va">self</span>.verb_hash_map, indexation<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.verb_hash_map, verb_hashed <span class="op">=</span> hash_series(data.verb, indexation<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">hasattr</span>(<span class="va">self</span>, <span class="st">"subj_hash_map"</span>):</span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a>            _, subj_hashed <span class="op">=</span> hash_series(data.participant, <span class="va">self</span>.subj_hash_map, indexation<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.subj_hash_map, subj_hashed <span class="op">=</span> hash_series(data.participant, indexation<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb18-26"><a href="#cb18-26" aria-hidden="true" tabindex="-1"></a>        model_data <span class="op">=</span> {</span>
<span id="cb18-27"><a href="#cb18-27" aria-hidden="true" tabindex="-1"></a>            <span class="st">"verb"</span>: verb_hashed,</span>
<span id="cb18-28"><a href="#cb18-28" aria-hidden="true" tabindex="-1"></a>            <span class="st">"frame"</span>: frame_hashed,</span>
<span id="cb18-29"><a href="#cb18-29" aria-hidden="true" tabindex="-1"></a>            <span class="st">"subj"</span>: subj_hashed,</span>
<span id="cb18-30"><a href="#cb18-30" aria-hidden="true" tabindex="-1"></a>            <span class="st">"resp"</span>: data.response.astype(<span class="bu">int</span>).values <span class="op">-</span> <span class="dv">1</span></span>
<span id="cb18-31"><a href="#cb18-31" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb18-32"><a href="#cb18-32" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb18-33"><a href="#cb18-33" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.data_class(<span class="op">**</span>model_data)</span>
<span id="cb18-34"><a href="#cb18-34" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-35"><a href="#cb18-35" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _initialize_model(<span class="va">self</span>, data: pd.DataFrame):</span>
<span id="cb18-36"><a href="#cb18-36" aria-hidden="true" tabindex="-1"></a>        model_parameters <span class="op">=</span> <span class="va">self</span>.construct_model_parameters(data)</span>
<span id="cb18-37"><a href="#cb18-37" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb18-38"><a href="#cb18-38" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.model_class(model_parameters)</span>
<span id="cb18-39"><a href="#cb18-39" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-40"><a href="#cb18-40" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> fit(</span>
<span id="cb18-41"><a href="#cb18-41" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>, data: pd.DataFrame, batch_size<span class="op">=</span><span class="dv">1000</span>, n_epochs:<span class="bu">int</span><span class="op">=</span><span class="dv">1000</span>, </span>
<span id="cb18-42"><a href="#cb18-42" aria-hidden="true" tabindex="-1"></a>        lr: <span class="bu">float</span> <span class="op">=</span> <span class="fl">1e-5</span>, verbosity: <span class="bu">int</span><span class="op">=</span><span class="dv">100</span></span>
<span id="cb18-43"><a href="#cb18-43" aria-hidden="true" tabindex="-1"></a>    ) <span class="op">-&gt;</span> UnconstrainedSelectionModel:</span>
<span id="cb18-44"><a href="#cb18-44" aria-hidden="true" tabindex="-1"></a>        <span class="co"># necessary for initializing hashes</span></span>
<span id="cb18-45"><a href="#cb18-45" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model_data <span class="op">=</span> <span class="va">self</span>.construct_model_data(data)</span>
<span id="cb18-46"><a href="#cb18-46" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model <span class="op">=</span> <span class="va">self</span>._initialize_model(data)</span>
<span id="cb18-47"><a href="#cb18-47" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb18-48"><a href="#cb18-48" aria-hidden="true" tabindex="-1"></a>        optimizer <span class="op">=</span> torch.optim.Adam(<span class="va">self</span>.model.parameters(), lr<span class="op">=</span>lr)</span>
<span id="cb18-49"><a href="#cb18-49" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb18-50"><a href="#cb18-50" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> e <span class="kw">in</span> <span class="bu">range</span>(n_epochs):</span>
<span id="cb18-51"><a href="#cb18-51" aria-hidden="true" tabindex="-1"></a>            data_shuffled <span class="op">=</span> data.sample(frac<span class="op">=</span><span class="fl">1.</span>).reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb18-52"><a href="#cb18-52" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb18-53"><a href="#cb18-53" aria-hidden="true" tabindex="-1"></a>            n_batches <span class="op">=</span> <span class="bu">int</span>(data_shuffled.shape[<span class="dv">0</span>]<span class="op">/</span>batch_size)</span>
<span id="cb18-54"><a href="#cb18-54" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb18-55"><a href="#cb18-55" aria-hidden="true" tabindex="-1"></a>            epoch_total_loss <span class="op">=</span> <span class="fl">0.</span></span>
<span id="cb18-56"><a href="#cb18-56" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb18-57"><a href="#cb18-57" aria-hidden="true" tabindex="-1"></a>            correlations <span class="op">=</span> []</span>
<span id="cb18-58"><a href="#cb18-58" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb18-59"><a href="#cb18-59" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_batches):</span>
<span id="cb18-60"><a href="#cb18-60" aria-hidden="true" tabindex="-1"></a>                lower_bound <span class="op">=</span> i<span class="op">*</span>batch_size</span>
<span id="cb18-61"><a href="#cb18-61" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb18-62"><a href="#cb18-62" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> i <span class="op">==</span> (n_batches <span class="op">-</span> <span class="dv">1</span>):</span>
<span id="cb18-63"><a href="#cb18-63" aria-hidden="true" tabindex="-1"></a>                    upper_bound <span class="op">=</span> data_shuffled.shape[<span class="dv">0</span>]</span>
<span id="cb18-64"><a href="#cb18-64" aria-hidden="true" tabindex="-1"></a>                <span class="cf">else</span>:</span>
<span id="cb18-65"><a href="#cb18-65" aria-hidden="true" tabindex="-1"></a>                    upper_bound <span class="op">=</span> (i<span class="op">+</span><span class="dv">1</span>)<span class="op">*</span>batch_size</span>
<span id="cb18-66"><a href="#cb18-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-67"><a href="#cb18-67" aria-hidden="true" tabindex="-1"></a>                data_sub <span class="op">=</span> <span class="va">self</span>.construct_model_data(data_shuffled.iloc[lower_bound:upper_bound])</span>
<span id="cb18-68"><a href="#cb18-68" aria-hidden="true" tabindex="-1"></a>                target <span class="op">=</span> torch.tensor(data_sub.resp)</span>
<span id="cb18-69"><a href="#cb18-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-70"><a href="#cb18-70" aria-hidden="true" tabindex="-1"></a>                optimizer.zero_grad()</span>
<span id="cb18-71"><a href="#cb18-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-72"><a href="#cb18-72" aria-hidden="true" tabindex="-1"></a>                probs <span class="op">=</span> <span class="va">self</span>.model(data_sub)</span>
<span id="cb18-73"><a href="#cb18-73" aria-hidden="true" tabindex="-1"></a>                logprobs <span class="op">=</span> torch.log(probs)</span>
<span id="cb18-74"><a href="#cb18-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-75"><a href="#cb18-75" aria-hidden="true" tabindex="-1"></a>                loss <span class="op">=</span> <span class="va">self</span>.loss_function(logprobs, target)</span>
<span id="cb18-76"><a href="#cb18-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-77"><a href="#cb18-77" aria-hidden="true" tabindex="-1"></a>                <span class="co"># compute correlation between expected value and target</span></span>
<span id="cb18-78"><a href="#cb18-78" aria-hidden="true" tabindex="-1"></a>                expected_value <span class="op">=</span> torch.<span class="bu">sum</span>(</span>
<span id="cb18-79"><a href="#cb18-79" aria-hidden="true" tabindex="-1"></a>                    torch.arange(<span class="dv">1</span>, probs.shape[<span class="dv">1</span>]<span class="op">+</span><span class="dv">1</span>)[<span class="va">None</span>,:] <span class="op">*</span> probs, </span>
<span id="cb18-80"><a href="#cb18-80" aria-hidden="true" tabindex="-1"></a>                    axis<span class="op">=</span><span class="dv">1</span></span>
<span id="cb18-81"><a href="#cb18-81" aria-hidden="true" tabindex="-1"></a>                )</span>
<span id="cb18-82"><a href="#cb18-82" aria-hidden="true" tabindex="-1"></a>                corr <span class="op">=</span> torch.corrcoef(</span>
<span id="cb18-83"><a href="#cb18-83" aria-hidden="true" tabindex="-1"></a>                    torch.cat([</span>
<span id="cb18-84"><a href="#cb18-84" aria-hidden="true" tabindex="-1"></a>                        expected_value[<span class="va">None</span>,:], </span>
<span id="cb18-85"><a href="#cb18-85" aria-hidden="true" tabindex="-1"></a>                        target[<span class="va">None</span>,:]</span>
<span id="cb18-86"><a href="#cb18-86" aria-hidden="true" tabindex="-1"></a>                    ], axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb18-87"><a href="#cb18-87" aria-hidden="true" tabindex="-1"></a>                )</span>
<span id="cb18-88"><a href="#cb18-88" aria-hidden="true" tabindex="-1"></a>                correlations.append(corr[<span class="dv">0</span>,<span class="dv">1</span>].item())</span>
<span id="cb18-89"><a href="#cb18-89" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb18-90"><a href="#cb18-90" aria-hidden="true" tabindex="-1"></a>                loss.backward()</span>
<span id="cb18-91"><a href="#cb18-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-92"><a href="#cb18-92" aria-hidden="true" tabindex="-1"></a>                optimizer.step()</span>
<span id="cb18-93"><a href="#cb18-93" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb18-94"><a href="#cb18-94" aria-hidden="true" tabindex="-1"></a>                epoch_total_loss <span class="op">+=</span> loss.item()</span>
<span id="cb18-95"><a href="#cb18-95" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb18-96"><a href="#cb18-96" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> verbosity <span class="kw">and</span> <span class="kw">not</span> e <span class="op">%</span> verbosity:</span>
<span id="cb18-97"><a href="#cb18-97" aria-hidden="true" tabindex="-1"></a>                <span class="bu">print</span>(<span class="ss">f"Epoch:       </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb18-98"><a href="#cb18-98" aria-hidden="true" tabindex="-1"></a>                <span class="bu">print</span>(<span class="ss">f"Loss:        </span><span class="sc">{</span>np<span class="sc">.</span><span class="bu">round</span>(epoch_total_loss, <span class="dv">2</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb18-99"><a href="#cb18-99" aria-hidden="true" tabindex="-1"></a>                <span class="bu">print</span>(<span class="ss">f"Mean corr.:  </span><span class="sc">{</span>np<span class="sc">.</span><span class="bu">round</span>(np.mean(correlations), <span class="dv">2</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb18-100"><a href="#cb18-100" aria-hidden="true" tabindex="-1"></a>                <span class="bu">print</span>()</span>
<span id="cb18-101"><a href="#cb18-101" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb18-102"><a href="#cb18-102" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb18-103"><a href="#cb18-103" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span></span>
<span id="cb18-104"><a href="#cb18-104" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-105"><a href="#cb18-105" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> expected_value(<span class="va">self</span>, data: pd.DataFrame):</span>
<span id="cb18-106"><a href="#cb18-106" aria-hidden="true" tabindex="-1"></a>        model_data <span class="op">=</span> <span class="va">self</span>.construct_model_data(data)</span>
<span id="cb18-107"><a href="#cb18-107" aria-hidden="true" tabindex="-1"></a>        probs <span class="op">=</span> <span class="va">self</span>.model(model_data)</span>
<span id="cb18-108"><a href="#cb18-108" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb18-109"><a href="#cb18-109" aria-hidden="true" tabindex="-1"></a>        expected_value <span class="op">=</span> torch.<span class="bu">sum</span>(</span>
<span id="cb18-110"><a href="#cb18-110" aria-hidden="true" tabindex="-1"></a>            torch.arange(<span class="dv">1</span>, <span class="dv">8</span>)[<span class="va">None</span>,:] <span class="op">*</span> probs, </span>
<span id="cb18-111"><a href="#cb18-111" aria-hidden="true" tabindex="-1"></a>            axis<span class="op">=</span><span class="dv">1</span></span>
<span id="cb18-112"><a href="#cb18-112" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb18-113"><a href="#cb18-113" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb18-114"><a href="#cb18-114" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> expected_value</span>
<span id="cb18-115"><a href="#cb18-115" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-116"><a href="#cb18-116" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> likelihood(<span class="va">self</span>, data: pd.DataFrame):</span>
<span id="cb18-117"><a href="#cb18-117" aria-hidden="true" tabindex="-1"></a>        model_data <span class="op">=</span> <span class="va">self</span>.construct_model_data(data)</span>
<span id="cb18-118"><a href="#cb18-118" aria-hidden="true" tabindex="-1"></a>        probs <span class="op">=</span> <span class="va">self</span>.model(model_data)</span>
<span id="cb18-119"><a href="#cb18-119" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb18-120"><a href="#cb18-120" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> probs[model_data.resp]</span>
<span id="cb18-121"><a href="#cb18-121" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-122"><a href="#cb18-122" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> predict(<span class="va">self</span>, data: pd.DataFrame):</span>
<span id="cb18-123"><a href="#cb18-123" aria-hidden="true" tabindex="-1"></a>        model_data <span class="op">=</span> <span class="va">self</span>.construct_model_data(data)</span>
<span id="cb18-124"><a href="#cb18-124" aria-hidden="true" tabindex="-1"></a>        probs <span class="op">=</span> <span class="va">self</span>.model(model_data)</span>
<span id="cb18-125"><a href="#cb18-125" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb18-126"><a href="#cb18-126" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> probs[model_data.resp]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-tags="[]" data-execution_count="101">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> UnconstrainedSelectionModelTrainer(SelectionModelTrainer):</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>    parameter_class <span class="op">=</span> UnconstrainedSelectionModelParameters</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>    model_class <span class="op">=</span> UnconstrainedSelectionModel</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, n_component: <span class="bu">int</span>):</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n_component <span class="op">=</span> n_component</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.loss_function <span class="op">=</span> torch.nn.CrossEntropyLoss(reduction<span class="op">=</span><span class="st">"sum"</span>)</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> construct_model_parameters(<span class="va">self</span>, data: pd.DataFrame) <span class="op">-&gt;</span> UnconstrainedSelectionModelParameters:</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>        model_parameters <span class="op">=</span> {</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>            <span class="st">"n_verb"</span>: <span class="va">self</span>.verb_hash_map.shape[<span class="dv">0</span>],</span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>            <span class="st">"n_frame"</span>: <span class="va">self</span>.frame_hash_map.shape[<span class="dv">0</span>],</span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>            <span class="st">"n_subj"</span>: <span class="va">self</span>.subj_hash_map.shape[<span class="dv">0</span>],</span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>            <span class="st">"n_resp_levels"</span>: <span class="dv">7</span>,</span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a>            <span class="st">"n_component"</span>: <span class="va">self</span>.n_component</span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.parameter_class(<span class="op">**</span>model_parameters)</span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a>m <span class="op">=</span> UnconstrainedSelectionModelTrainer(<span class="dv">2</span>)</span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a>m.fit(data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch:       0
Loss:        1147684.59
Mean corr.:  0.03

Epoch:       100
Loss:        950132.16
Mean corr.:  0.19

Epoch:       200
Loss:        792799.86
Mean corr.:  0.28
</code></pre>
</div>
<div class="cell-output cell-output-error">
<pre><code>KeyboardInterrupt: </code></pre>
</div>
</div>
<div class="cell" data-tags="[]" data-execution_count="74">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> spearmanr</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>data[<span class="st">"expected_value"</span>] <span class="op">=</span> m.expected_value(data).data</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> sns.boxplot(data, x<span class="op">=</span><span class="st">"response"</span>, y<span class="op">=</span><span class="st">"expected_value"</span>)</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>spearmanr(data[[<span class="st">"response"</span>, <span class="st">"expected_value"</span>]])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="74">
<pre><code>SignificanceResult(statistic=0.42813175602327286, pvalue=0.0)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="index_files/figure-html/cell-17-output-2.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-tags="[]" data-execution_count="76">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co">#sns.clustermap(pd.DataFrame(m.model.frame_component_prob.data, index=m.frame_hash_map), cmap="vlag", yticklabels=True)</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>sns.clustermap(pd.DataFrame(m.model.verb_component_prob.data, index<span class="op">=</span>m.verb_hash_map), cmap<span class="op">=</span><span class="st">"vlag"</span>, yticklabels<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="index_files/figure-html/cell-18-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-tags="[]" data-execution_count="108">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="at">@dataclass</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ConstrainedSelectionModelParameters(SelectionModelParameters):</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>    n_clause_component: <span class="bu">int</span></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>    n_nonclause_component: <span class="bu">int</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-tags="[]" data-execution_count="113">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch <span class="im">import</span> Tensor</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ConstrainedSelectionModel(torch.nn.Module):</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>    parameter_class <span class="op">=</span> ConstrainedSelectionModelParameters</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, parameters: ConstrainedSelectionModelParameters):</span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model_parameters <span class="op">=</span> parameters</span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.verb_clause_aux <span class="op">=</span> torch.nn.Parameter(</span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a>            torch.randn([parameters.n_verb]), </span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true" tabindex="-1"></a>            requires_grad<span class="op">=</span><span class="va">True</span></span>
<span id="cb26-15"><a href="#cb26-15" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb26-16"><a href="#cb26-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.verb_nonclause_aux <span class="op">=</span> torch.nn.Parameter(</span>
<span id="cb26-17"><a href="#cb26-17" aria-hidden="true" tabindex="-1"></a>            torch.randn([</span>
<span id="cb26-18"><a href="#cb26-18" aria-hidden="true" tabindex="-1"></a>                parameters.n_verb, parameters.n_nonclause_component</span>
<span id="cb26-19"><a href="#cb26-19" aria-hidden="true" tabindex="-1"></a>            ]), </span>
<span id="cb26-20"><a href="#cb26-20" aria-hidden="true" tabindex="-1"></a>            requires_grad<span class="op">=</span><span class="va">True</span></span>
<span id="cb26-21"><a href="#cb26-21" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb26-22"><a href="#cb26-22" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb26-23"><a href="#cb26-23" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.frame_clause_aux <span class="op">=</span> torch.nn.Parameter(</span>
<span id="cb26-24"><a href="#cb26-24" aria-hidden="true" tabindex="-1"></a>            torch.randn([parameters.n_frame]), </span>
<span id="cb26-25"><a href="#cb26-25" aria-hidden="true" tabindex="-1"></a>            requires_grad<span class="op">=</span><span class="va">True</span></span>
<span id="cb26-26"><a href="#cb26-26" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb26-27"><a href="#cb26-27" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.frame_nonclause_aux <span class="op">=</span> torch.nn.Parameter(</span>
<span id="cb26-28"><a href="#cb26-28" aria-hidden="true" tabindex="-1"></a>            torch.randn([</span>
<span id="cb26-29"><a href="#cb26-29" aria-hidden="true" tabindex="-1"></a>                parameters.n_frame, parameters.n_nonclause_component</span>
<span id="cb26-30"><a href="#cb26-30" aria-hidden="true" tabindex="-1"></a>            ]), </span>
<span id="cb26-31"><a href="#cb26-31" aria-hidden="true" tabindex="-1"></a>            requires_grad<span class="op">=</span><span class="va">True</span></span>
<span id="cb26-32"><a href="#cb26-32" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb26-33"><a href="#cb26-33" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb26-34"><a href="#cb26-34" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.log_clause_jumps <span class="op">=</span> torch.nn.Parameter(</span>
<span id="cb26-35"><a href="#cb26-35" aria-hidden="true" tabindex="-1"></a>            torch.ones(parameters.n_clause_component<span class="op">-</span><span class="dv">1</span>), </span>
<span id="cb26-36"><a href="#cb26-36" aria-hidden="true" tabindex="-1"></a>            requires_grad<span class="op">=</span><span class="va">True</span></span>
<span id="cb26-37"><a href="#cb26-37" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb26-38"><a href="#cb26-38" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb26-39"><a href="#cb26-39" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.log_jumps <span class="op">=</span> torch.nn.Parameter(</span>
<span id="cb26-40"><a href="#cb26-40" aria-hidden="true" tabindex="-1"></a>            torch.ones([</span>
<span id="cb26-41"><a href="#cb26-41" aria-hidden="true" tabindex="-1"></a>                parameters.n_subj, parameters.n_resp_levels<span class="op">-</span><span class="dv">1</span></span>
<span id="cb26-42"><a href="#cb26-42" aria-hidden="true" tabindex="-1"></a>            ]), </span>
<span id="cb26-43"><a href="#cb26-43" aria-hidden="true" tabindex="-1"></a>            requires_grad<span class="op">=</span><span class="va">True</span></span>
<span id="cb26-44"><a href="#cb26-44" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb26-45"><a href="#cb26-45" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb26-46"><a href="#cb26-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-47"><a href="#cb26-47" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, data: SelectionData):</span>
<span id="cb26-48"><a href="#cb26-48" aria-hidden="true" tabindex="-1"></a>        verb_frame_prob <span class="op">=</span> <span class="va">self</span>.verb_frame_prob(data.verb, data.frame)</span>
<span id="cb26-49"><a href="#cb26-49" aria-hidden="true" tabindex="-1"></a>        verb_frame_logodds <span class="op">=</span> torch.log(verb_frame_prob) <span class="op">-</span> torch.log(<span class="fl">1.</span> <span class="op">-</span> verb_frame_prob)</span>
<span id="cb26-50"><a href="#cb26-50" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb26-51"><a href="#cb26-51" aria-hidden="true" tabindex="-1"></a>        jumps <span class="op">=</span> <span class="va">self</span>.jumps[data.subj]</span>
<span id="cb26-52"><a href="#cb26-52" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb26-53"><a href="#cb26-53" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> ordered_logistic_likelihood(</span>
<span id="cb26-54"><a href="#cb26-54" aria-hidden="true" tabindex="-1"></a>            verb_frame_logodds, jumps</span>
<span id="cb26-55"><a href="#cb26-55" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb26-56"><a href="#cb26-56" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb26-57"><a href="#cb26-57" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> verb_frame_prob(</span>
<span id="cb26-58"><a href="#cb26-58" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>, </span>
<span id="cb26-59"><a href="#cb26-59" aria-hidden="true" tabindex="-1"></a>        verb_idx: Optional[ndarray] <span class="op">=</span> <span class="va">None</span>, </span>
<span id="cb26-60"><a href="#cb26-60" aria-hidden="true" tabindex="-1"></a>        frame_idx: Optional[ndarray] <span class="op">=</span> <span class="va">None</span></span>
<span id="cb26-61"><a href="#cb26-61" aria-hidden="true" tabindex="-1"></a>    ) <span class="op">-&gt;</span> Tensor:</span>
<span id="cb26-62"><a href="#cb26-62" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.verb_frame_clause_prob(verb_idx, frame_idx) <span class="op">*\</span></span>
<span id="cb26-63"><a href="#cb26-63" aria-hidden="true" tabindex="-1"></a>               <span class="va">self</span>.verb_frame_nonclause_prob(verb_idx, frame_idx)</span>
<span id="cb26-64"><a href="#cb26-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-65"><a href="#cb26-65" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> verb_frame_clause_prob(</span>
<span id="cb26-66"><a href="#cb26-66" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>, </span>
<span id="cb26-67"><a href="#cb26-67" aria-hidden="true" tabindex="-1"></a>        verb_idx: Optional[ndarray] <span class="op">=</span> <span class="va">None</span>, </span>
<span id="cb26-68"><a href="#cb26-68" aria-hidden="true" tabindex="-1"></a>        frame_idx: Optional[ndarray] <span class="op">=</span> <span class="va">None</span></span>
<span id="cb26-69"><a href="#cb26-69" aria-hidden="true" tabindex="-1"></a>    ) <span class="op">-&gt;</span> Tensor:</span>
<span id="cb26-70"><a href="#cb26-70" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> verb_idx <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="kw">or</span> frame_idx <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb26-71"><a href="#cb26-71" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="fl">1.</span> <span class="op">-</span> torch.prod(</span>
<span id="cb26-72"><a href="#cb26-72" aria-hidden="true" tabindex="-1"></a>                <span class="fl">1.</span> <span class="op">-</span> <span class="va">self</span>.verb_clause_component_prob[verb_idx,:] <span class="op">*</span> </span>
<span id="cb26-73"><a href="#cb26-73" aria-hidden="true" tabindex="-1"></a>                     <span class="va">self</span>.frame_clause_component_prob[frame_idx,:],</span>
<span id="cb26-74"><a href="#cb26-74" aria-hidden="true" tabindex="-1"></a>                axis<span class="op">=</span><span class="dv">1</span></span>
<span id="cb26-75"><a href="#cb26-75" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb26-76"><a href="#cb26-76" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> verb_idx <span class="kw">is</span> <span class="va">None</span> <span class="kw">and</span> frame_idx <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb26-77"><a href="#cb26-77" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="fl">1.</span> <span class="op">-</span> torch.prod(</span>
<span id="cb26-78"><a href="#cb26-78" aria-hidden="true" tabindex="-1"></a>                <span class="fl">1.</span> <span class="op">-</span> <span class="va">self</span>.verb_clause_component_prob[:,<span class="va">None</span>,:] <span class="op">*</span> </span>
<span id="cb26-79"><a href="#cb26-79" aria-hidden="true" tabindex="-1"></a>                     <span class="va">self</span>.frame_clause_component_prob[:,frame_idx,:],</span>
<span id="cb26-80"><a href="#cb26-80" aria-hidden="true" tabindex="-1"></a>                axis<span class="op">=</span><span class="dv">2</span></span>
<span id="cb26-81"><a href="#cb26-81" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb26-82"><a href="#cb26-82" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> verb_idx <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="kw">and</span> frame_idx <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb26-83"><a href="#cb26-83" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="fl">1.</span> <span class="op">-</span> torch.prod(</span>
<span id="cb26-84"><a href="#cb26-84" aria-hidden="true" tabindex="-1"></a>                <span class="fl">1.</span> <span class="op">-</span> <span class="va">self</span>.verb_clause_component_prob[verb_idx,<span class="va">None</span>,:] <span class="op">*</span> </span>
<span id="cb26-85"><a href="#cb26-85" aria-hidden="true" tabindex="-1"></a>                     <span class="va">self</span>.frame_clause_component_prob[<span class="va">None</span>,:,:],</span>
<span id="cb26-86"><a href="#cb26-86" aria-hidden="true" tabindex="-1"></a>                axis<span class="op">=</span><span class="dv">2</span></span>
<span id="cb26-87"><a href="#cb26-87" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb26-88"><a href="#cb26-88" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb26-89"><a href="#cb26-89" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="fl">1.</span> <span class="op">-</span> torch.prod(</span>
<span id="cb26-90"><a href="#cb26-90" aria-hidden="true" tabindex="-1"></a>                <span class="fl">1.</span> <span class="op">-</span> <span class="va">self</span>.verb_clause_component_prob[:,<span class="va">None</span>,:] <span class="op">*</span> </span>
<span id="cb26-91"><a href="#cb26-91" aria-hidden="true" tabindex="-1"></a>                     <span class="va">self</span>.frame_clause_component_prob[<span class="va">None</span>,:,:],</span>
<span id="cb26-92"><a href="#cb26-92" aria-hidden="true" tabindex="-1"></a>                axis<span class="op">=</span><span class="dv">2</span></span>
<span id="cb26-93"><a href="#cb26-93" aria-hidden="true" tabindex="-1"></a>            ) </span>
<span id="cb26-94"><a href="#cb26-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-95"><a href="#cb26-95" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> verb_frame_nonclause_prob(</span>
<span id="cb26-96"><a href="#cb26-96" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>, </span>
<span id="cb26-97"><a href="#cb26-97" aria-hidden="true" tabindex="-1"></a>        verb_idx: Optional[ndarray] <span class="op">=</span> <span class="va">None</span>, </span>
<span id="cb26-98"><a href="#cb26-98" aria-hidden="true" tabindex="-1"></a>        frame_idx: Optional[ndarray] <span class="op">=</span> <span class="va">None</span></span>
<span id="cb26-99"><a href="#cb26-99" aria-hidden="true" tabindex="-1"></a>    ) <span class="op">-&gt;</span> Tensor:</span>
<span id="cb26-100"><a href="#cb26-100" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> verb_idx <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="kw">or</span> frame_idx <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb26-101"><a href="#cb26-101" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="fl">1.</span> <span class="op">-</span> torch.prod(</span>
<span id="cb26-102"><a href="#cb26-102" aria-hidden="true" tabindex="-1"></a>                <span class="fl">1.</span> <span class="op">-</span> <span class="va">self</span>.verb_nonclause_component_prob[verb_idx,:] <span class="op">*</span> </span>
<span id="cb26-103"><a href="#cb26-103" aria-hidden="true" tabindex="-1"></a>                     <span class="va">self</span>.frame_nonclause_component_prob[frame_idx,:],</span>
<span id="cb26-104"><a href="#cb26-104" aria-hidden="true" tabindex="-1"></a>                axis<span class="op">=</span><span class="dv">1</span></span>
<span id="cb26-105"><a href="#cb26-105" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb26-106"><a href="#cb26-106" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> verb_idx <span class="kw">is</span> <span class="va">None</span> <span class="kw">and</span> frame_idx <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb26-107"><a href="#cb26-107" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="fl">1.</span> <span class="op">-</span> torch.prod(</span>
<span id="cb26-108"><a href="#cb26-108" aria-hidden="true" tabindex="-1"></a>                <span class="fl">1.</span> <span class="op">-</span> <span class="va">self</span>.verb_nonclause_component_prob[:,<span class="va">None</span>,:] <span class="op">*</span> </span>
<span id="cb26-109"><a href="#cb26-109" aria-hidden="true" tabindex="-1"></a>                     <span class="va">self</span>.frame_nonclause_component_prob[:,frame_idx,:],</span>
<span id="cb26-110"><a href="#cb26-110" aria-hidden="true" tabindex="-1"></a>                axis<span class="op">=</span><span class="dv">2</span></span>
<span id="cb26-111"><a href="#cb26-111" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb26-112"><a href="#cb26-112" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> verb_idx <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="kw">and</span> frame_idx <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb26-113"><a href="#cb26-113" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="fl">1.</span> <span class="op">-</span> torch.prod(</span>
<span id="cb26-114"><a href="#cb26-114" aria-hidden="true" tabindex="-1"></a>                <span class="fl">1.</span> <span class="op">-</span> <span class="va">self</span>.verb_nonclause_component_prob[verb_idx,<span class="va">None</span>,:] <span class="op">*</span> </span>
<span id="cb26-115"><a href="#cb26-115" aria-hidden="true" tabindex="-1"></a>                     <span class="va">self</span>.frame_nonclause_component_prob[<span class="va">None</span>,:,:],</span>
<span id="cb26-116"><a href="#cb26-116" aria-hidden="true" tabindex="-1"></a>                axis<span class="op">=</span><span class="dv">2</span></span>
<span id="cb26-117"><a href="#cb26-117" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb26-118"><a href="#cb26-118" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb26-119"><a href="#cb26-119" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="fl">1.</span> <span class="op">-</span> torch.prod(</span>
<span id="cb26-120"><a href="#cb26-120" aria-hidden="true" tabindex="-1"></a>                <span class="fl">1.</span> <span class="op">-</span> <span class="va">self</span>.verb_nonclause_component_prob[:,<span class="va">None</span>,:] <span class="op">*</span> </span>
<span id="cb26-121"><a href="#cb26-121" aria-hidden="true" tabindex="-1"></a>                     <span class="va">self</span>.frame_nonclause_component_prob[<span class="va">None</span>,:,:],</span>
<span id="cb26-122"><a href="#cb26-122" aria-hidden="true" tabindex="-1"></a>                axis<span class="op">=</span><span class="dv">2</span></span>
<span id="cb26-123"><a href="#cb26-123" aria-hidden="true" tabindex="-1"></a>            )       </span>
<span id="cb26-124"><a href="#cb26-124" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb26-125"><a href="#cb26-125" aria-hidden="true" tabindex="-1"></a>    <span class="at">@property</span></span>
<span id="cb26-126"><a href="#cb26-126" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> verb_clause_component_prob(<span class="va">self</span>) <span class="op">-&gt;</span> Tensor:</span>
<span id="cb26-127"><a href="#cb26-127" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> ordered_logistic_likelihood(</span>
<span id="cb26-128"><a href="#cb26-128" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.verb_clause_aux, <span class="va">self</span>.clause_jumps[<span class="va">None</span>,:]</span>
<span id="cb26-129"><a href="#cb26-129" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb26-130"><a href="#cb26-130" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb26-131"><a href="#cb26-131" aria-hidden="true" tabindex="-1"></a>    <span class="at">@property</span></span>
<span id="cb26-132"><a href="#cb26-132" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> frame_clause_component_prob(<span class="va">self</span>) <span class="op">-&gt;</span> Tensor:</span>
<span id="cb26-133"><a href="#cb26-133" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> ordered_logistic_likelihood(</span>
<span id="cb26-134"><a href="#cb26-134" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.frame_clause_aux, <span class="va">self</span>.clause_jumps[<span class="va">None</span>,:]</span>
<span id="cb26-135"><a href="#cb26-135" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb26-136"><a href="#cb26-136" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb26-137"><a href="#cb26-137" aria-hidden="true" tabindex="-1"></a>    <span class="at">@property</span></span>
<span id="cb26-138"><a href="#cb26-138" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> verb_nonclause_component_prob(<span class="va">self</span>) <span class="op">-&gt;</span> Tensor:</span>
<span id="cb26-139"><a href="#cb26-139" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.sigmoid(<span class="va">self</span>.verb_nonclause_aux)</span>
<span id="cb26-140"><a href="#cb26-140" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb26-141"><a href="#cb26-141" aria-hidden="true" tabindex="-1"></a>    <span class="at">@property</span></span>
<span id="cb26-142"><a href="#cb26-142" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> frame_nonclause_component_prob(<span class="va">self</span>) <span class="op">-&gt;</span> Tensor:</span>
<span id="cb26-143"><a href="#cb26-143" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.sigmoid(<span class="va">self</span>.frame_nonclause_aux)</span>
<span id="cb26-144"><a href="#cb26-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-145"><a href="#cb26-145" aria-hidden="true" tabindex="-1"></a>    <span class="at">@property</span></span>
<span id="cb26-146"><a href="#cb26-146" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> clause_jumps(<span class="va">self</span>):</span>
<span id="cb26-147"><a href="#cb26-147" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.exp(<span class="va">self</span>.log_clause_jumps)</span>
<span id="cb26-148"><a href="#cb26-148" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb26-149"><a href="#cb26-149" aria-hidden="true" tabindex="-1"></a>    <span class="at">@property</span></span>
<span id="cb26-150"><a href="#cb26-150" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> jumps(<span class="va">self</span>):</span>
<span id="cb26-151"><a href="#cb26-151" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.exp(<span class="va">self</span>.log_jumps)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-tags="[]" data-execution_count="125">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ConstrainedSelectionModelTrainer(SelectionModelTrainer):</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>    parameter_class <span class="op">=</span> ConstrainedSelectionModelParameters</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>    model_class <span class="op">=</span> ConstrainedSelectionModel</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, n_clause_component: <span class="bu">int</span>, n_nonclause_component: <span class="bu">int</span>):</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n_clause_component <span class="op">=</span> n_clause_component</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n_nonclause_component <span class="op">=</span> n_nonclause_component</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.loss_function <span class="op">=</span> torch.nn.CrossEntropyLoss(reduction<span class="op">=</span><span class="st">"sum"</span>)</span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> construct_model_parameters(<span class="va">self</span>, data: pd.DataFrame) <span class="op">-&gt;</span> UnconstrainedSelectionModelParameters:</span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a>        model_parameters <span class="op">=</span> {</span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a>            <span class="st">"n_verb"</span>: <span class="va">self</span>.verb_hash_map.shape[<span class="dv">0</span>],</span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a>            <span class="st">"n_frame"</span>: <span class="va">self</span>.frame_hash_map.shape[<span class="dv">0</span>],</span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a>            <span class="st">"n_subj"</span>: <span class="va">self</span>.subj_hash_map.shape[<span class="dv">0</span>],</span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a>            <span class="st">"n_resp_levels"</span>: <span class="dv">7</span>,</span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a>            <span class="st">"n_clause_component"</span>: <span class="va">self</span>.n_clause_component,</span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a>            <span class="st">"n_nonclause_component"</span>: <span class="va">self</span>.n_nonclause_component</span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb27-21"><a href="#cb27-21" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.parameter_class(<span class="op">**</span>model_parameters)</span>
<span id="cb27-22"><a href="#cb27-22" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb27-23"><a href="#cb27-23" aria-hidden="true" tabindex="-1"></a>m <span class="op">=</span> ConstrainedSelectionModelTrainer(<span class="dv">3</span>, <span class="dv">2</span>)</span>
<span id="cb27-24"><a href="#cb27-24" aria-hidden="true" tabindex="-1"></a>m.fit(data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch:       0
Loss:        1078181.55
Mean corr.:  0.02
</code></pre>
</div>
<div class="cell-output cell-output-error">
<pre><code>KeyboardInterrupt: </code></pre>
</div>
</div>
<div class="cell" data-tags="[]" data-execution_count="123">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>sns.clustermap(pd.DataFrame(m.model.frame_clause_component_prob.data, index<span class="op">=</span>m.frame_hash_map), yticklabels<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a><span class="co">#sns.clustermap(pd.DataFrame(m.model.verb_component_prob.data, index=m.verb_hash_map), cmap="vlag", yticklabels=True)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-error">
<pre><code>ValueError: The condensed distance matrix must contain only finite values.</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="index_files/figure-html/cell-22-output-2.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-tags="[]" data-execution_count="78">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>ordered_logistic_likelihood??</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div class="ansi-escaped-output">
<pre><span class="ansi-red-fg">Signature:</span>
ordered_logistic_likelihood<span class="ansi-blue-fg">(</span>
    value<span class="ansi-blue-fg">:</span> torch<span class="ansi-blue-fg">.</span>Tensor<span class="ansi-blue-fg">,</span>
    jumps<span class="ansi-blue-fg">:</span> torch<span class="ansi-blue-fg">.</span>Tensor<span class="ansi-blue-fg">,</span>
    center<span class="ansi-blue-fg">:</span> bool <span class="ansi-blue-fg">=</span> <span class="ansi-green-fg">True</span><span class="ansi-blue-fg">,</span>
<span class="ansi-blue-fg">)</span> <span class="ansi-blue-fg">-&gt;</span> torch<span class="ansi-blue-fg">.</span>Tensor
<span class="ansi-red-fg">Source:</span>   
<span class="ansi-green-fg">def</span> ordered_logistic_likelihood<span class="ansi-blue-fg">(</span>value<span class="ansi-blue-fg">:</span> Tensor<span class="ansi-blue-fg">,</span> jumps<span class="ansi-blue-fg">:</span> Tensor<span class="ansi-blue-fg">,</span> center<span class="ansi-blue-fg">:</span> bool <span class="ansi-blue-fg">=</span> <span class="ansi-green-fg">True</span><span class="ansi-blue-fg">)</span> <span class="ansi-blue-fg">-&gt;</span> Tensor<span class="ansi-blue-fg">:</span>
    <span class="ansi-blue-fg">"""Compute the ordered logistic likelihood given a value</span>
<span class="ansi-blue-fg">    </span>
<span class="ansi-blue-fg">    Parameters</span>
<span class="ansi-blue-fg">    ----------</span>
<span class="ansi-blue-fg">    value</span>
<span class="ansi-blue-fg">        The value to compute the likelihood for </span>
<span class="ansi-blue-fg">        (shape: batch_size)</span>
<span class="ansi-blue-fg">    jumps</span>
<span class="ansi-blue-fg">        The distance between cutpoints </span>
<span class="ansi-blue-fg">        (shape: batch_size x number of response levels - 1)</span>
<span class="ansi-blue-fg">    Returns</span>
<span class="ansi-blue-fg">    -------</span>
<span class="ansi-blue-fg">    log_likelihood</span>
<span class="ansi-blue-fg">        the ordered logistic log-likelihood</span>
<span class="ansi-blue-fg">    """</span>
    cutpoints <span class="ansi-blue-fg">=</span> torch<span class="ansi-blue-fg">.</span>cumsum<span class="ansi-blue-fg">(</span>jumps<span class="ansi-blue-fg">,</span> <span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">)</span> 
    
    <span class="ansi-green-fg">if</span> center<span class="ansi-blue-fg">:</span>
        cutpoints <span class="ansi-blue-fg">=</span> cutpoints <span class="ansi-blue-fg">-</span> cutpoints<span class="ansi-blue-fg">.</span>mean<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
    
    cdfs <span class="ansi-blue-fg">=</span> torch<span class="ansi-blue-fg">.</span>sigmoid<span class="ansi-blue-fg">(</span>cutpoints <span class="ansi-blue-fg">-</span> value<span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">:</span><span class="ansi-blue-fg">,</span><span class="ansi-green-fg">None</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">)</span>
    low_prob <span class="ansi-blue-fg">=</span> torch<span class="ansi-blue-fg">.</span>cat<span class="ansi-blue-fg">(</span>
        <span class="ansi-blue-fg">[</span>torch<span class="ansi-blue-fg">.</span>zeros<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">[</span>cdfs<span class="ansi-blue-fg">.</span>shape<span class="ansi-blue-fg">[</span><span class="ansi-cyan-fg">0</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">,</span> <span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span> cdfs<span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">,</span>
        axis<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">1</span>
    <span class="ansi-blue-fg">)</span>
    high_prob <span class="ansi-blue-fg">=</span> torch<span class="ansi-blue-fg">.</span>cat<span class="ansi-blue-fg">(</span>
        <span class="ansi-blue-fg">[</span>cdfs<span class="ansi-blue-fg">,</span> torch<span class="ansi-blue-fg">.</span>ones<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">[</span>cdfs<span class="ansi-blue-fg">.</span>shape<span class="ansi-blue-fg">[</span><span class="ansi-cyan-fg">0</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">,</span> <span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">,</span>
        axis<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">1</span>
    <span class="ansi-blue-fg">)</span>
    
    <span class="ansi-green-fg">return</span> high_prob <span class="ansi-blue-fg">-</span> low_prob
<span class="ansi-red-fg">File:</span>      /tmp/ipykernel_31725/3045571987.py
<span class="ansi-red-fg">Type:</span>      function</pre>
</div>
</div>
</div>





<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" role="list">
<div id="ref-lohninger_typology_2020" class="csl-entry" role="listitem">
Lohninger, Magdalena, and Susanne Wurmbrand. to appear. <span>“Typology of Complement Clauses.”</span> Edited by Anton Benz, Werner Frey, Manfred Krifka, Thomas McFadden, and Marzena Żygis. <em>Handbook of Clausal Embedding</em>, to appear, 1–53.
</div>
<div id="ref-paatero_positive_1994" class="csl-entry" role="listitem">
Paatero, Pentti, and Unto Tapper. 1994. <span>“Positive Matrix Factorization: <span>A</span> Non-Negative Factor Model with Optimal Utilization of Error Estimates of Data Values.”</span> <em>Environmetrics</em> 5 (2): 111–26. <a href="https://doi.org/10.1002/env.3170050203">https://doi.org/10.1002/env.3170050203</a>.
</div>
<div id="ref-pearson_lines_1901" class="csl-entry" role="listitem">
Pearson, Karl. 1901. <span>“On Lines and Planes of Closest Fit to Systems of Points in Space.”</span> <em>The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science</em> 2 (11): 559–72. <a href="https://doi.org/10.1080/14786440109462720">https://doi.org/10.1080/14786440109462720</a>.
</div>
<div id="ref-white_computational_2016" class="csl-entry" role="listitem">
White, Aaron Steven, and Kyle Rawlins. 2016. <span>“A Computational Model of <span>S</span>-Selection.”</span> Edited by Mary Moroney, Carol-Rose Little, Jacob Collard, and Dan Burgdorf. <em>Semantics and Linguistic Theory</em> 26 (October): 641–63. <a href="https://doi.org/10.3765/salt.v26i0.3819">https://doi.org/10.3765/salt.v26i0.3819</a>.
</div>
<div id="ref-white_frequency_2020" class="csl-entry" role="listitem">
———. 2020. <span>“Frequency, Acceptability, and Selection: <span>A</span> Case Study of Clause-Embedding.”</span> <em>Glossa: A Journal of General Linguistics</em> 5 (1): 105. <a href="https://doi.org/10.5334/gjgl.1001">https://doi.org/10.5334/gjgl.1001</a>.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>In fact, not all predicates found in their sentences are necessarily verbs. Some–e.g.&nbsp;<em>annoy</em>–are likely to be (deverbal) adjectives in some frames. We’ll continue to just refer to these predicates as verbs.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://giscus.app/client.js" data-repo="aaronstevenwhite/representation-learning-course" data-repo-id="R_kgDOJsrvfQ" data-category="General" data-category-id="DIC_kwDOJsrvfc4CXIDs" data-mapping="title" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="top" data-theme="light" data-lang="en" crossorigin="anonymous" async="">
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../projective-content/model-fitting-and-comparison.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Model fitting and comparison</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../thematic-roles/index.html" class="pagination-link">
        <span class="nav-page-text">Module 4: Thematic Roles</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



<script src="../site_libs/quarto-contrib/line-highlight-1.0.0/line-highlight.js" defer="true"></script>
</body></html>