<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.321">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Representation Learning for Syntactic and Semantic Theory - Model definition</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../selection/model-fitting-and-comparison.html" rel="next">
<link href="../selection/a-brief-primer-on-gradient-based-optimization.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/quarto-contrib/line-highlight-1.0.0/line-highlight.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../selection/index.html">Module 3: Selection</a></li><li class="breadcrumb-item"><a href="../selection/model-definition.html">Model definition</a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Representation Learning for Syntactic and Semantic Theory</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">About</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../installation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Installation</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../motivations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Motivations</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../methodological-approach.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Methodological Approach</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../course-structure-and-content.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Course Structure and Content</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Foundational Concepts in Probability and Statistics</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../foundational-concepts-in-probability-and-statistics/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">What is a probability?</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../foundational-concepts-in-probability-and-statistics/random-variables-and-probability-distributions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Random variables and probability distributions</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../foundational-concepts-in-probability-and-statistics/statistical-inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Statistical Inference</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
 <span class="menu-text">Module 1: Island Effects</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../island-effects/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../island-effects/model-definition.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Model definition</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../island-effects/model-fitting-and-comparison.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Model Fitting and Comparison</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
 <span class="menu-text">Module 2: Projective Content</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../projective-content/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../projective-content/inferentially-defined-classes-of-predicates.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Inferentially defined classes of predicates</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../projective-content/model-definition.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Model definition</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../projective-content/model-fitting-and-comparison.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Model fitting and comparison</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
 <span class="menu-text">Module 3: Selection</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../selection/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../selection/a-brief-primer-on-gradient-based-optimization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">A brief primer on gradient-based optimization</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../selection/model-definition.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Model definition</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../selection/model-fitting-and-comparison.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Model fitting and comparison</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../thematic-roles/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Module 4: Thematic Roles</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#the-megaacceptability-dataset" id="toc-the-megaacceptability-dataset" class="nav-link active" data-scroll-target="#the-megaacceptability-dataset">The MegaAcceptability dataset</a></li>
  <li><a href="#inducing-semantic-types-by-matrix-factorization" id="toc-inducing-semantic-types-by-matrix-factorization" class="nav-link" data-scroll-target="#inducing-semantic-types-by-matrix-factorization">Inducing semantic types by matrix factorization</a>
  <ul class="collapse">
  <li><a href="#matrix-factorization" id="toc-matrix-factorization" class="nav-link" data-scroll-target="#matrix-factorization">Matrix factorization</a></li>
  <li><a href="#selecting-a-number-of-types" id="toc-selecting-a-number-of-types" class="nav-link" data-scroll-target="#selecting-a-number-of-types">Selecting a number of types</a></li>
  <li><a href="#implementation-in-stan" id="toc-implementation-in-stan" class="nav-link" data-scroll-target="#implementation-in-stan">Implementation in STAN</a></li>
  <li><a href="#implementation-in-pytorch" id="toc-implementation-in-pytorch" class="nav-link" data-scroll-target="#implementation-in-pytorch">Implementation in PyTorch</a></li>
  </ul></li>
  <li><a href="#complex-syntactic-and-semantic-types" id="toc-complex-syntactic-and-semantic-types" class="nav-link" data-scroll-target="#complex-syntactic-and-semantic-types">Complex syntactic and semantic types</a>
  <ul class="collapse">
  <li><a href="#relationships-among-representations" id="toc-relationships-among-representations" class="nav-link" data-scroll-target="#relationships-among-representations">Relationships among representations</a></li>
  <li><a href="#implementing-the-unconstrained-model" id="toc-implementing-the-unconstrained-model" class="nav-link" data-scroll-target="#implementing-the-unconstrained-model">Implementing the unconstrained model</a></li>
  <li><a href="#implementing-the-constrained-model" id="toc-implementing-the-constrained-model" class="nav-link" data-scroll-target="#implementing-the-constrained-model">Implementing the constrained model</a></li>
  </ul></li>
  <li><a href="#summing-up" id="toc-summing-up" class="nav-link" data-scroll-target="#summing-up">Summing up</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Model definition</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p><span class="citation" data-cites="lohninger_typology_2020">Lohninger and Wurmbrand (<a href="#ref-lohninger_typology_2020" role="doc-biblioref">to appear</a>)</span> review evidence from a variety of both “functional-typological and structural-grammatical approaches to complementation” <span class="citation" data-cites="givon_binding_1980 cristofaro_subordination_2005 noonan_complementation_2007 dixon_basic_2009 wurmbrand_implicational_2023">(<a href="#ref-givon_binding_1980" role="doc-biblioref">Givón 1980</a>; <a href="#ref-cristofaro_subordination_2005" role="doc-biblioref">Cristofaro and Cristofaro 2005</a>; <a href="#ref-noonan_complementation_2007" role="doc-biblioref">Noonan 2007</a>; <a href="#ref-dixon_basic_2009" role="doc-biblioref">Dixon 2009</a>; <a href="#ref-wurmbrand_implicational_2023" role="doc-biblioref">Wurmbrand and Lohninger 2023</a>)</span> that “…there is a possibly universal implicational complementation hierarchy which is defined semantically and detectable through a diverse set of grammatical properties” and that “[w]hile the distribution of morphosyntactic properties varies significantly across languages, the semantic grouping of complement types shows a (more) stable distribution” (<em>ibid</em>, p.&nbsp;33). The argue specifically that, while “different classification systems arise” in different works “[d]epending on the scope, focus and terminology of an approach”, “a common property found in all approaches, in one form or another, is that complementation configurations are ranked along some kind of hierarchy” (<em>ibid</em>, p.&nbsp;2).</p>
<p>In this module, we’ll consider how we might develop a model that encodes this notion of hierarchy as a means of testing this idea at the scale of an entire lexicon. We of course won’t be able to assess the idea cross-linguistically; but since all of these approaches make predictions of hierarchy language-internally, we will be able to probe it’s ability to cover English.</p>
<section id="the-megaacceptability-dataset" class="level2">
<h2 class="anchored" data-anchor-id="the-megaacceptability-dataset">The MegaAcceptability dataset</h2>
<p>We’ll use the <a href="http://megaattitude.io/projects/mega-acceptability/">MegaAcceptability dataset</a>–collected by <span class="citation" data-cites="white_computational_2016">White and Rawlins (<a href="#ref-white_computational_2016" role="doc-biblioref">2016</a>)</span> and reported on in detail by <span class="citation" data-cites="white_frequency_2020">White and Rawlins (<a href="#ref-white_frequency_2020" role="doc-biblioref">2020</a>)</span>.</p>
<div class="cell" data-tags="[]" data-execution_count="1">
<details>
<summary>Download the data</summary>
<div class="sourceCode cell-code" id="cb1" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># !wget http://megaattitude.io/projects/mega-acceptability/mega-acceptability-v1.zip -P data/</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="co"># !unzip data/mega-acceptability-v1.zip -d data/</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>data_dir <span class="op">=</span> <span class="st">"./data/mega-acceptability-v1/"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-tags="[]" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pandas <span class="im">import</span> DataFrame, read_csv</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> load_data(fname: <span class="bu">str</span>, verbose: <span class="bu">bool</span> <span class="op">=</span> <span class="va">True</span>) <span class="op">-&gt;</span> DataFrame:</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># read the raw data skipping comment rows at the beginning</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>    data <span class="op">=</span> read_csv(fname, sep<span class="op">=</span><span class="st">"</span><span class="ch">\t</span><span class="st">"</span>)</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> verbose:</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>        n_datapoints <span class="op">=</span> data.shape[<span class="dv">0</span>]</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"The full dataset has </span><span class="sc">{</span>n_datapoints<span class="sc">}</span><span class="ss"> datapoints."</span>)</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># remove non-native speakers</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>    data <span class="op">=</span> data.query(<span class="st">"nativeenglish"</span>)</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> verbose:</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>        n_datapoints_native <span class="op">=</span> data.shape[<span class="dv">0</span>]</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Removing </span><span class="sc">{</span>n_datapoints <span class="op">-</span> n_datapoints_native<span class="sc">}</span><span class="ss"> "</span></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>              <span class="st">"responses from nonnative speakers."</span>)</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># remove NaN judgments</span></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>    data <span class="op">=</span> data.query(<span class="st">"~response.isnull()"</span>)</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> verbose:</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>        n_datapoints_nonnull <span class="op">=</span> data.shape[<span class="dv">0</span>]</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Removing </span><span class="sc">{</span>n_datapoints_native <span class="op">-</span> n_datapoints_nonnull<span class="sc">}</span><span class="ss"> NA responses."</span>)</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> data</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Most importantly for our purposes, the dataset contains the <code>verb</code> and <code>frame</code> instantiated in the <code>sentence</code> that each <code>participant</code> rated on a 1-7 Likert <code>response</code> scale.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<div class="cell" data-tags="[]" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> load_data(os.path.join(data_dir, <span class="st">"mega-acceptability-v1.tsv"</span>))</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>data[[<span class="st">"participant"</span>, <span class="st">"verb"</span>, <span class="st">"frame"</span>, <span class="st">"sentence"</span>, <span class="st">"response"</span>]].head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre data-code-line-numbers=""><code>The full dataset has 250000 datapoints.
Removing 600 responses from nonnative speakers.
Removing 10 NA responses.</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="3">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">participant</th>
<th data-quarto-table-cell-role="th">list</th>
<th data-quarto-table-cell-role="th">presentationorder</th>
<th data-quarto-table-cell-role="th">verb</th>
<th data-quarto-table-cell-role="th">frame</th>
<th data-quarto-table-cell-role="th">response</th>
<th data-quarto-table-cell-role="th">nativeenglish</th>
<th data-quarto-table-cell-role="th">sentence</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>4</td>
<td>862</td>
<td>1</td>
<td>turn_out</td>
<td>NP was Ved whichNP to VP</td>
<td>2.0</td>
<td>True</td>
<td>Someone was turned out which thing to do.</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>381</td>
<td>862</td>
<td>1</td>
<td>turn_out</td>
<td>NP was Ved whichNP to VP</td>
<td>1.0</td>
<td>True</td>
<td>Someone was turned out which thing to do.</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>395</td>
<td>862</td>
<td>1</td>
<td>turn_out</td>
<td>NP was Ved whichNP to VP</td>
<td>2.0</td>
<td>True</td>
<td>Someone was turned out which thing to do.</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>621</td>
<td>862</td>
<td>1</td>
<td>turn_out</td>
<td>NP was Ved whichNP to VP</td>
<td>1.0</td>
<td>True</td>
<td>Someone was turned out which thing to do.</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>527</td>
<td>862</td>
<td>1</td>
<td>turn_out</td>
<td>NP was Ved whichNP to VP</td>
<td>1.0</td>
<td>True</td>
<td>Someone was turned out which thing to do.</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>The full distribution of ratings is similar to the one we saw for Sprouse et al.’s Experiments 1 and 3 in the sense that it shows that, in general, subjects prefer the ends of the scale. It differs mainly in the fact that there is a substantial bias toward 1 responses.</p>
<div class="cell" data-tags="[]" data-execution_count="5">
<details>
<summary>Plotting code</summary>
<div class="sourceCode cell-code" id="cb5" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> numpy <span class="im">import</span> arange</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib.pyplot <span class="im">import</span> subplot</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> subplot()</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>ax.hist(data.response, bins<span class="op">=</span>arange(<span class="dv">1</span>, <span class="dv">9</span>), rwidth<span class="op">=</span><span class="fl">0.5</span>, align<span class="op">=</span><span class="st">"left"</span>)</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">"Likert scale acceptability judgments (Experiments 1 and 3)"</span>)</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">"Likert scale acceptability judgment"</span>)</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> ax.set_ylabel(<span class="st">"Count"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="model-definition_files/figure-html/cell-5-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>This bias is perhaps unsurprising in light of the way that the dataset was constructed: many of the verb-frame combinations are bound to be bad together; and it gives a sense for how “sparse” the verb-frame acceptability matrix we attempt to estimate using our models is likely to be. On average, the mean <code>response</code> for each verb-frame pair is below 4.</p>
<div class="cell" data-tags="[]" data-execution_count="23">
<details>
<summary>Plotting code</summary>
<div class="sourceCode cell-code" id="cb6" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>warnings.filterwarnings(<span class="st">"ignore"</span>)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> numpy <span class="im">import</span> <span class="bu">round</span>, corrcoef</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pandas <span class="im">import</span> Series</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> seaborn <span class="im">import</span> clustermap</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>verb_frame_means <span class="op">=</span> data.pivot_table(</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>    index<span class="op">=</span><span class="st">"verb"</span>, columns<span class="op">=</span><span class="st">"frame"</span>, values<span class="op">=</span><span class="st">"response"</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> clustermap(</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>    verb_frame_means, cmap<span class="op">=</span><span class="st">"vlag"</span>, figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">10</span>), </span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>    center<span class="op">=</span><span class="dv">4</span>, xticklabels<span class="op">=</span><span class="va">True</span>, yticklabels<span class="op">=</span><span class="va">False</span></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="model-definition_files/figure-html/cell-6-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>For reasons discussed in Module 1, we need to be careful in interpreting this sparsity–not least because there were many distinct lists and the distribution of true acceptability in the list almost certainly affected how subjects calibrated to the response scale. And so, following <span class="citation" data-cites="white_computational_2016">White and Rawlins (<a href="#ref-white_computational_2016" role="doc-biblioref">2016</a>)</span>, we’ll integrate an ordered logistic likelihood into all of our models. We’ll first reimplement the model proposed by <span class="citation" data-cites="white_computational_2016">White and Rawlins (<a href="#ref-white_computational_2016" role="doc-biblioref">2016</a>)</span>, then incrementally extend it to model the idea of homomorphic hierarchies of semantic and syntactic types discussed by <span class="citation" data-cites="lohninger_typology_2020">Lohninger and Wurmbrand (<a href="#ref-lohninger_typology_2020" role="doc-biblioref">to appear</a>)</span>.</p>
</section>
<section id="inducing-semantic-types-by-matrix-factorization" class="level2">
<h2 class="anchored" data-anchor-id="inducing-semantic-types-by-matrix-factorization">Inducing semantic types by matrix factorization</h2>
<p><span class="citation" data-cites="white_computational_2016">White and Rawlins (<a href="#ref-white_computational_2016" role="doc-biblioref">2016</a>)</span> model the ordinal acceptability judgments <span class="math inline">\(r_n\)</span> associated with a sentence <span class="math inline">\(\text{sent}(n)\)</span> to be a function of the probability <span class="math inline">\(\alpha_{vf}\)</span> that the main clause verb <span class="math inline">\(v = \text{verb}(n)\)</span> in <span class="math inline">\(\text{sent}(n)\)</span> is acceptable in the syntactic frame <span class="math inline">\(f = \text{frame}(i)\)</span> instantiated in <span class="math inline">\(\text{sent}(n)\)</span>. They model this probability as a function of two other kinds of probability: (i) the probability <span class="math inline">\(\lambda_{vs}\)</span> that a particular verb <span class="math inline">\(v\)</span> can have a particular semantic type <span class="math inline">\(s\)</span>; and (ii) the probability <span class="math inline">\(\pi_{fs}\)</span> that a particular semantic type <span class="math inline">\(s\)</span> can be mapped onto a particular syntactic frame <span class="math inline">\(f\)</span>. We’ll refer to the collection of these <span class="math inline">\(\lambda_{vs}\)</span>s and <span class="math inline">\(\pi_{fs}\)</span>s as matrices <span class="math inline">\(\boldsymbol\Lambda \in [0, 1]^{V \times K_\text{semtype}}\)</span> and <span class="math inline">\(\boldsymbol\Pi \in [0, 1]^{F \times K_\text{semtype}}\)</span>, where <span class="math inline">\(V\)</span> and <span class="math inline">\(F\)</span> are the numbers of verbs and frames, respectively.</p>
<p>The basic idea is that we should predict a verb to be good–modulo other factors <span class="citation" data-cites="grimshaw_complement_1979">(<a href="#ref-grimshaw_complement_1979" role="doc-biblioref">Grimshaw 1979</a>)</span>, such as its case assignment properties <span class="citation" data-cites="pesetsky_zero_1991">(<a href="#ref-pesetsky_zero_1991" role="doc-biblioref">Pesetsky 1991</a>)</span>–in a particular syntactic frame insofar as it can have at least one semantic type signature that maps onto that frame. That is, they define the probability <span class="math inline">\(\alpha_{vf}\)</span> that a main clause verb <span class="math inline">\(v\)</span> is acceptable in a syntactic frame <span class="math inline">\(f\)</span> to be <span class="math inline">\(p\left(\bigvee_s l_{vs} \land b_{fs}\right)\)</span>, where:</p>
<p><span class="math display">\[\begin{align*}
l_{vs} &amp;= \begin{cases}
\top &amp; \text{if } v \text{ can have semantic type signature } s\\
\bot &amp; \text{otherwise}
\end{cases}\\
b_{fs} &amp;= \begin{cases}
\top &amp; \text{if } s \text{ can map onto syntactic frame } f\\
\bot &amp; \text{otherwise}
\end{cases}
\end{align*}\]</span></p>
<p>As with <span class="math inline">\(\boldsymbol\Lambda\)</span> and <span class="math inline">\(\boldsymbol\Pi\)</span>, we can view the collection of <span class="math inline">\(l_{vs}\)</span>s and <span class="math inline">\(b_{fs}\)</span>s as boolean matrices <span class="math inline">\(\mathbf{L} \in \mathbb{B}^{V \times K_\text{semtype}}\)</span> <span class="math inline">\(\mathbf{B} \in \mathbb{B}^{F \times K_\text{semtype}}\)</span>.</p>
<p>Insofar as a verb’s having a particular type signature is independent of that type signature mapping onto a particular syntactic frame, this probability can be rewritten into an expression in terms of <span class="math inline">\(\lambda_{vs}\)</span> and <span class="math inline">\(\pi_{fs}\)</span>:</p>
<p><span class="math display">\[\begin{align*}
p\left(\bigvee_s l_{vs} \land b_{fs}\right) &amp;= p\left(\lnot\lnot\bigvee_s l_{vs} \land b_{fs}\right)\\
&amp;= 1 - p\left(\lnot\bigvee_s l_{vs} \land b_{fs}\right)\\
&amp;= 1 - p\left(\bigwedge_s \lnot\left[ l_{vs} \land b_{fs}\right]\right)\\
&amp;= 1 - \prod_s p\left(\lnot\left[ l_{vs} \land b_{fs}\right]\right)\\
&amp;= 1 - \prod_s 1 - p\left(l_{vs} \land b_{fs}\right)\\
&amp;= 1 - \prod_s 1 - p\left(l_{vs}\right)p\left(b_{fs}\right)\\
&amp;= 1 - \prod_s 1 - \lambda_{vs}\pi_{fs}\\
\end{align*}\]</span></p>
<p>As we saw in Module 2, this form coresponds to a probabilistic fuzzy logic disjunction over the semantic types. That is, if we interpret <span class="math inline">\(\lor\)</span> and <span class="math inline">\(\land\)</span> as probabilistic fuzzy logic disjunction, we can write:</p>
<p><span class="math display">\[\alpha_{vf} = \bigvee_s \lambda_{vs} \land \pi_{fs} = 1 - \prod_s 1 - \lambda_{vs}\pi_{fs}\]</span></p>
<p>Importantly, they assume: (a) that verbs can be compatible with multiple semantic type signatures; (b) that multiple semantic type signatures can map onto the same frame; and (c) that multiple frames can be mapped onto by the same semantic type signature. So <span class="math inline">\(\sum_s \lambda_{vs}\)</span> and <span class="math inline">\(\sum_s \pi_{fs}\)</span> can be anywhere between <span class="math inline">\(0\)</span> and the number of type signatures, and <span class="math inline">\(\sum_f \pi_{fs}\)</span> can be anywhere between <span class="math inline">\(0\)</span> and the number of syntactic frames. None of the three need to be <span class="math inline">\(1\)</span>.</p>
<section id="matrix-factorization" class="level3">
<h3 class="anchored" data-anchor-id="matrix-factorization">Matrix factorization</h3>
<p>Solving for <span class="math inline">\(\boldsymbol\Lambda\)</span> and <span class="math inline">\(\boldsymbol\Pi\)</span>, from which <span class="math inline">\(\alpha_{vf}\)</span> can be computed deterministically, is an instance of a <a href="https://en.wikipedia.org/wiki/Matrix_decomposition">matrix factorization</a> problem–of which <a href="https://en.wikipedia.org/wiki/Principal_component_analysis">principal component analysis</a> [PCA; <span class="citation" data-cites="pearson_lines_1901">Pearson (<a href="#ref-pearson_lines_1901" role="doc-biblioref">1901</a>)</span>], <a href="https://en.wikipedia.org/wiki/Factor_analysis">factor analysis</a>, and <a href="https://en.wikipedia.org/wiki/Non-negative_matrix_factorization">postive/non-negative matrix factorization</a> <span class="citation" data-cites="paatero_positive_1994">(<a href="#ref-paatero_positive_1994" role="doc-biblioref">Paatero and Tapper 1994</a>)</span> are common forms.</p>
<p>In matrix factorization, we assume some matrix <span class="math inline">\(\mathbf{Y} \in \mathbb{R}^{N \times M}\)</span> whose elements <span class="math inline">\(y_{nm} \sim f(x_{nm}, \boldsymbol\theta)\)</span> for some distribution <span class="math inline">\(f\)</span>. The matrix <span class="math inline">\(\mathbf{X}\)</span> is itself <em>factorized</em> (or <em>decomposed</em>) into two matrices <span class="math inline">\(\mathbf{U} \in \mathbb{R}^{N \times K}\)</span> and <span class="math inline">\(\mathbf{V} \in \mathbb{R}^{K \times M}\)</span> such that <span class="math inline">\(\mathbf{X} \equiv \mathbf{UV}\)</span>. For instance, in factor analysis (FA), <span class="math inline">\(f \equiv \mathcal{N}\)</span> and <span class="math inline">\(\boldsymbol\theta \equiv \sigma^2\)</span>; and in postive/non-negative matrix factorization, all the matrices are constrained to contain positive/non-negative reals, with <span class="math inline">\(f \equiv \text{HalfNormal}\)</span> and <span class="math inline">\(\boldsymbol\theta \equiv \sigma^2\)</span>.</p>
<p>To see why we can think of the model presented by <span class="citation" data-cites="white_computational_2016">White and Rawlins (<a href="#ref-white_computational_2016" role="doc-biblioref">2016</a>)</span> as a form of matrix factorization, remember that, to say that <span class="math inline">\(\mathbf{X} \equiv \mathbf{UV}\)</span> is just to say that <span class="math inline">\(x_{ij} = \sum_k u_{ik} \cdot v_{kj}\)</span> for all <span class="math inline">\(i, j\)</span>. If we simply replace <span class="math inline">\(\sum\)</span> with <span class="math inline">\(\bigvee\)</span> and <span class="math inline">\(\cdot\)</span> with <span class="math inline">\(\land\)</span>, we get exactly the form used by White and Rawlins.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> The distribution <span class="math inline">\(f\)</span> is then defined as an ordered logistic, whose auxiliary parameters are the by-subject cutpoints.</p>
</section>
<section id="selecting-a-number-of-types" class="level3">
<h3 class="anchored" data-anchor-id="selecting-a-number-of-types">Selecting a number of types</h3>
<p>Following a method common in applications of matrix factorization, <span class="citation" data-cites="white_computational_2016">White and Rawlins (<a href="#ref-white_computational_2016" role="doc-biblioref">2016</a>)</span> select the number of semantic types on the basis of an information criterion: the Akaike Information Criterion (AIC). Specifically, they sweep many values for the number of semantic types <span class="math inline">\(K_\text{semtype}\)</span>–i.e.&nbsp;the dimensionality of <span class="math inline">\(\boldsymbol\Lambda\)</span> and <span class="math inline">\(\boldsymbol\Pi\)</span>–fitting the model then asking which model yields the lowest AIC.</p>
<p>Rather than sweep many possible numbers of <span class="math inline">\(K_\text{semtype}\)</span>, we’re going to take a slightly different approach using a nonparametric prior. Very roughly, the nonparametric prior we will use assumes that <span class="math inline">\(\boldsymbol\lambda_v\)</span> and <span class="math inline">\(\boldsymbol\pi_f\)</span>–and consequently, <span class="math inline">\(\mathbf{l}_v\)</span> and <span class="math inline">\(\mathbf{b}_v\)</span>–have infinite dimension but that in our finite sample, we only observe a finite number of those dimensions being non-zero–or more specifically, non-trivially larger than zero. This assumption is nice because it accords with one that we generally make in the formal semantics literature: the set of semantic types is defined inductively and is therefore infinite–though in a finite lexicon we are unlikely to see a predicate associated with every such type.</p>
<p>To implement this idea, we’ll use a <em>stick-breaking process</em> proposed by <span class="citation" data-cites="teh_stick-breaking_2007">Teh, Grür, and Ghahramani (<a href="#ref-teh_stick-breaking_2007" role="doc-biblioref">2007</a>)</span> (equation 5) to define our prior on the <span class="math inline">\(\boldsymbol\lambda_v\)</span>s and the <span class="math inline">\(\boldsymbol\pi_f\)</span>s. What this proces is going to provide for us is the mean <span class="math inline">\(\mu_s\)</span> for an arbitrary semantic type <span class="math inline">\(s\)</span>. We’ll assume that these means may be distinct for the verb matrix <span class="math inline">\(\boldsymbol\Lambda\)</span> and the frame matrix <span class="math inline">\(\boldsymbol\Pi\)</span>–<span class="math inline">\(\boldsymbol\mu^\text{verb}\)</span> and <span class="math inline">\(\boldsymbol\mu^\text{frame}\)</span>, respectively–and we’ll assume that the elements of <span class="math inline">\(\boldsymbol\Lambda\)</span> and <span class="math inline">\(\bolsymbol\Pi\)</span> are distributed beta with sample sizes (or <em>precisions</em>) <span class="math inline">\(\boldsymbol\nu^\text{verb}\)</span> and <span class="math inline">\(\boldsymbol\nu^\text{frame}\)</span>, respectively.</p>
<p><span class="math display">\[\begin{align*}
\lambda_{vs} &amp;\sim \text{Beta}\left(\nu^\text{verb}_s\mu^\text{verb}_s, \nu^\text{verb}_s\left(1-\mu^\text{verb}_s\right)\right)\\
\pi_{fs} &amp;\sim \text{Beta}\left(\nu^\text{frame}_s\mu^\text{frame}_s, \nu^\text{frame}_s\left(1-\mu^\text{frame}_s\right)\right)
\end{align*}\]</span></p>
<p>Teh et al.’s process iteratively constructs the prior mean <span class="math inline">\(\mu_s\)</span> for each dimension (or <em>component</em>) <span class="math inline">\(k\)</span> in the following way.<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></p>
<p><span class="math display">\[\mu_s \equiv \begin{cases}
\sigma_s &amp; \text{if } s = 1\\
\mu_{s-1}\sigma_s &amp; \text{otherwise}
\end{cases}\]</span></p>
<p>where <span class="math inline">\(\sigma_s \sim \text{Beta}(a, 1)\)</span>.</p>
<div class="cell" data-tags="[]" data-execution_count="109">
<div class="sourceCode cell-code" id="cb7" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> beta</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> numpy <span class="im">import</span> ndarray</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sample_stick_breaking_process(k: <span class="bu">int</span>, a: <span class="bu">float</span>) <span class="op">-&gt;</span> ndarray:</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> beta(a, <span class="dv">1</span>).rvs(k).cumprod()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This process is useful because it allows us to approximate the prior means up to a particular number of components–usually relatively a large number. One important thing to note about this process is that it strictly orders the types in terms of their mean, which can be seen if we sample many vectors of means from it.</p>
<div class="cell" data-tags="[]" data-execution_count="110">
<details>
<summary>Plotting code</summary>
<div class="sourceCode cell-code" id="cb8" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> numpy <span class="im">import</span> array</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> numpy <span class="im">import</span> random</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib.pyplot <span class="im">import</span> subplots</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>random.seed(<span class="dv">30298</span>)</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> subplots(<span class="dv">1</span>, <span class="dv">4</span>, figsize<span class="op">=</span>(<span class="dv">18</span>, <span class="dv">10</span>))</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, a <span class="kw">in</span> <span class="bu">enumerate</span>([<span class="fl">1.</span>, <span class="fl">10.</span>, <span class="fl">20.</span>, <span class="fl">100.</span>]):</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>    samples <span class="op">=</span> array([</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>        sample_stick_breaking_process(k<span class="op">=</span><span class="dv">50</span>, a<span class="op">=</span>a) <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">50</span>)</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>    ])</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> axes[i].imshow(samples)</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>    axes[i].set_xlabel(<span class="st">"Component"</span>)</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>    axes[i].set_ylabel(<span class="st">"Sample from stick-breaking process"</span>)</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>    axes[i].set_title(<span class="vs">r"$a =$"</span> <span class="op">+</span> <span class="bu">str</span>(alpha))</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>    img.set_cmap(<span class="st">'binary'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="model-definition_files/figure-html/cell-8-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>To get a sense for the sort of matrices <span class="math inline">\(\boldsymbol\Lambda\)</span> and <span class="math inline">\(\boldsymbol\Pi\)</span> this generates, we can simulate a draw, assuming that the precisions have distributions <span class="math inline">\(\nu^\text{verb}_s \sim \text{Exponential}(1)\)</span> and <span class="math inline">\(\nu^\text{frame}_s \sim \text{Exponential}(1)\)</span>.</p>
<div class="cell" data-tags="[]" data-execution_count="111">
<details>
<summary>Plotting code</summary>
<div class="sourceCode cell-code" id="cb9" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> expon</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>random.seed(<span class="dv">30298</span>)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> subplots(<span class="dv">1</span>, <span class="dv">4</span>, figsize<span class="op">=</span>(<span class="dv">18</span>, <span class="dv">10</span>))</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, a <span class="kw">in</span> <span class="bu">enumerate</span>([<span class="fl">1.</span>, <span class="fl">10.</span>, <span class="fl">20.</span>, <span class="fl">100.</span>]):</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>    means <span class="op">=</span> sample_stick_breaking_process(k<span class="op">=</span><span class="dv">50</span>, a<span class="op">=</span>a)</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>    precisions <span class="op">=</span> expon(<span class="dv">1</span>).rvs(<span class="dv">50</span>)</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>    samples <span class="op">=</span> array([</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>        beta(n<span class="op">*</span>m, n<span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>m)).rvs(<span class="dv">50</span>) <span class="cf">for</span> m, n <span class="kw">in</span> <span class="bu">zip</span>(means, precisions)</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>    ]).T</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> axes[i].imshow(samples)</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>    axes[i].set_xlabel(<span class="st">"Component"</span>)</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>    axes[i].set_ylabel(<span class="st">"Simulated Verb/Frame"</span>)</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>    axes[i].set_title(<span class="vs">r"$a =$"</span> <span class="op">+</span> <span class="bu">str</span>(alpha))</span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>    img.set_cmap(<span class="st">'binary'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="model-definition_files/figure-html/cell-9-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>Based on the observation by <span class="citation" data-cites="white_computational_2016">White and Rawlins (<a href="#ref-white_computational_2016" role="doc-biblioref">2016</a>)</span> that AIC selects a value of 12 components, a value of <span class="math inline">\(a=2.5\)</span> seems likely to be a reasonable setting for the hyperprior.</p>
<div class="cell" data-tags="[]" data-execution_count="112">
<details>
<summary>Plotting code</summary>
<div class="sourceCode cell-code" id="cb10" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> expon</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>random.seed(<span class="dv">30298</span>)</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> subplots(<span class="dv">1</span>, <span class="dv">4</span>, figsize<span class="op">=</span>(<span class="dv">18</span>, <span class="dv">10</span>))</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, a <span class="kw">in</span> <span class="bu">enumerate</span>([<span class="fl">1.</span>, <span class="fl">2.5</span>, <span class="fl">5.</span>, <span class="fl">10.</span>]):</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>    means <span class="op">=</span> sample_stick_breaking_process(k<span class="op">=</span><span class="dv">50</span>, a<span class="op">=</span>a)</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>    precisions <span class="op">=</span> expon(<span class="dv">1</span>).rvs(<span class="dv">50</span>)</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>    samples <span class="op">=</span> array([</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>        beta(n<span class="op">*</span>m, n<span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>m)).rvs(<span class="dv">50</span>) <span class="cf">for</span> m, n <span class="kw">in</span> <span class="bu">zip</span>(means, precisions)</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>    ]).T</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> axes[i].imshow(samples)</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>    axes[i].set_xlabel(<span class="st">"Component"</span>)</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>    axes[i].set_ylabel(<span class="st">"Simulated Verb/Frame"</span>)</span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>    axes[i].set_title(<span class="vs">r"$\alpha =$"</span> <span class="op">+</span> <span class="bu">str</span>(alpha))</span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>    img.set_cmap(<span class="st">'binary'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="model-definition_files/figure-html/cell-10-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="implementation-in-stan" class="level3">
<h3 class="anchored" data-anchor-id="implementation-in-stan">Implementation in STAN</h3>
<p>We can implement this model in STAN fairly straightforwardly.</p>
<div class="sourceCode" id="cb11" data-startfrom="1" data-code-line-numbers=""><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="kw">data</span> {</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; N_verb;                           <span class="co">// number of verbs</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; N_frame;                          <span class="co">// number of frames</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; N_component;                      <span class="co">// number of components</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; N_subj;                           <span class="co">// number of subjects</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; N_resp;                           <span class="co">// number of responses</span></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; N_resp_levels;                    <span class="co">// number of ordinal response levels</span></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">1</span>,<span class="kw">upper</span>=N_verb&gt; verb[N_resp];        <span class="co">// the verb associated with respone n</span></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">1</span>,<span class="kw">upper</span>=N_frame&gt; frame[N_resp];      <span class="co">// the frame associated with respone n</span></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">1</span>,<span class="kw">upper</span>=N_subj&gt; subj[N_resp];        <span class="co">// the subject associated with respone n</span></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">1</span>,<span class="kw">upper</span>=N_resp_levels&gt; resp[N_resp]; <span class="co">// the response</span></span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb12" data-startfrom="14" data-code-line-numbers=""><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan" style="counter-reset: source-line 13;"><span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a><span class="kw">parameters</span> {</span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>  <span class="co">// the auxiliary variables that determine the component means</span></span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>,<span class="kw">upper</span>=<span class="dv">1</span>&gt;[N_component] verb_component_prior_mean_aux;</span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>,<span class="kw">upper</span>=<span class="dv">1</span>&gt;[N_component] frame_component_prior_mean_aux;</span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>  <span class="co">// the precision of the components</span></span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt;[N_component] verb_component_prior_precision;</span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt;[N_component] frame_component_prior_precision;</span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a>  <span class="co">// the relationship between a {verb, frame} and a component</span></span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a>  <span class="dt">matrix</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>,<span class="kw">upper</span>=<span class="dv">1</span>&gt;[N_verb,N_component] verb_component;</span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a>  <span class="dt">matrix</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>,<span class="kw">upper</span>=<span class="dv">1</span>&gt;[N_frame,N_component] frame_component;</span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a>  <span class="co">// the subject intercepts</span></span>
<span id="cb12-28"><a href="#cb12-28" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>[N_subj] subject_intercept;</span>
<span id="cb12-29"><a href="#cb12-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-30"><a href="#cb12-30" aria-hidden="true" tabindex="-1"></a>  <span class="co">// the cutpoints</span></span>
<span id="cb12-31"><a href="#cb12-31" aria-hidden="true" tabindex="-1"></a>  <span class="dt">ordered</span>[N_resp_levels<span class="dv">-1</span>] cutpoints;</span>
<span id="cb12-32"><a href="#cb12-32" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb13" data-startfrom="34" data-code-line-numbers=""><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan" style="counter-reset: source-line 33;"><span id="cb13-34"><a href="#cb13-34" aria-hidden="true" tabindex="-1"></a><span class="kw">transformed parameters</span> {</span>
<span id="cb13-35"><a href="#cb13-35" aria-hidden="true" tabindex="-1"></a>  <span class="co">// the component means</span></span>
<span id="cb13-36"><a href="#cb13-36" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>,<span class="kw">upper</span>=<span class="dv">1</span>&gt;[N_component] verb_component_prior_mean;</span>
<span id="cb13-37"><a href="#cb13-37" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>,<span class="kw">upper</span>=<span class="dv">1</span>&gt;[N_component] frame_component_prior_mean;</span>
<span id="cb13-38"><a href="#cb13-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-39"><a href="#cb13-39" aria-hidden="true" tabindex="-1"></a>  <span class="co">// declare the prior parameters alpha and beta for each verb component</span></span>
<span id="cb13-40"><a href="#cb13-40" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt;[N_component] verb_component_prior_alpha;</span>
<span id="cb13-41"><a href="#cb13-41" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt;[N_component] verb_component_prior_beta;</span>
<span id="cb13-42"><a href="#cb13-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-43"><a href="#cb13-43" aria-hidden="true" tabindex="-1"></a>  <span class="co">// declare the prior parameters alpha and beta for each frame component</span></span>
<span id="cb13-44"><a href="#cb13-44" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt;[N_component] frame_component_prior_alpha;</span>
<span id="cb13-45"><a href="#cb13-45" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt;[N_component] frame_component_prior_beta;</span>
<span id="cb13-46"><a href="#cb13-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-47"><a href="#cb13-47" aria-hidden="true" tabindex="-1"></a>  <span class="co">// set the first component mean to the first auxiliary variability</span></span>
<span id="cb13-48"><a href="#cb13-48" aria-hidden="true" tabindex="-1"></a>  <span class="co">// this is the first bit of stick broken from the interval</span></span>
<span id="cb13-49"><a href="#cb13-49" aria-hidden="true" tabindex="-1"></a>  verb_component_prior_mean[<span class="dv">1</span>] = verb_component_prior_mean_aux[<span class="dv">1</span>];</span>
<span id="cb13-50"><a href="#cb13-50" aria-hidden="true" tabindex="-1"></a>  frame_component_prior_mean[<span class="dv">1</span>] = frame_component_prior_mean_aux[<span class="dv">1</span>];</span>
<span id="cb13-51"><a href="#cb13-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-52"><a href="#cb13-52" aria-hidden="true" tabindex="-1"></a>  <span class="co">// compute the first verb component alpha and beta</span></span>
<span id="cb13-53"><a href="#cb13-53" aria-hidden="true" tabindex="-1"></a>  verb_component_prior_alpha[<span class="dv">1</span>] = verb_component_prior_mean[<span class="dv">1</span>] *</span>
<span id="cb13-54"><a href="#cb13-54" aria-hidden="true" tabindex="-1"></a>                                  verb_component_prior_precision[<span class="dv">1</span>];</span>
<span id="cb13-55"><a href="#cb13-55" aria-hidden="true" tabindex="-1"></a>  verb_component_prior_beta[<span class="dv">1</span>] = (<span class="fl">1.0</span> - verb_component_prior_mean[<span class="dv">1</span>]) *</span>
<span id="cb13-56"><a href="#cb13-56" aria-hidden="true" tabindex="-1"></a>                                  verb_component_prior_precision[<span class="dv">1</span>];</span>
<span id="cb13-57"><a href="#cb13-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-58"><a href="#cb13-58" aria-hidden="true" tabindex="-1"></a>  <span class="co">// compute the first frame component alpha and beta</span></span>
<span id="cb13-59"><a href="#cb13-59" aria-hidden="true" tabindex="-1"></a>  frame_component_prior_alpha[<span class="dv">1</span>] = frame_component_prior_mean[<span class="dv">1</span>] *</span>
<span id="cb13-60"><a href="#cb13-60" aria-hidden="true" tabindex="-1"></a>                                    frame_component_prior_precision[<span class="dv">1</span>];</span>
<span id="cb13-61"><a href="#cb13-61" aria-hidden="true" tabindex="-1"></a>  frame_component_prior_beta[<span class="dv">1</span>] = (<span class="fl">1.0</span> - frame_component_prior_mean[<span class="dv">1</span>]) *</span>
<span id="cb13-62"><a href="#cb13-62" aria-hidden="true" tabindex="-1"></a>                                  frame_component_prior_precision[<span class="dv">1</span>];</span>
<span id="cb13-63"><a href="#cb13-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-64"><a href="#cb13-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-65"><a href="#cb13-65" aria-hidden="true" tabindex="-1"></a>  <span class="co">// compute the remaining components</span></span>
<span id="cb13-66"><a href="#cb13-66" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (c <span class="cf">in</span> <span class="dv">2</span>:N_component) {</span>
<span id="cb13-67"><a href="#cb13-67" aria-hidden="true" tabindex="-1"></a>    verb_component_prior_mean[c] = verb_component_prior_mean_aux[c] * </span>
<span id="cb13-68"><a href="#cb13-68" aria-hidden="true" tabindex="-1"></a>                                   verb_component_prior_mean[c<span class="dv">-1</span>];</span>
<span id="cb13-69"><a href="#cb13-69" aria-hidden="true" tabindex="-1"></a>    verb_component_prior_alpha[c] = verb_component_prior_mean[c] *</span>
<span id="cb13-70"><a href="#cb13-70" aria-hidden="true" tabindex="-1"></a>                                    verb_component_prior_precision[c];</span>
<span id="cb13-71"><a href="#cb13-71" aria-hidden="true" tabindex="-1"></a>    verb_component_prior_beta[c] = (<span class="fl">1.0</span> - verb_component_prior_mean[c]) *</span>
<span id="cb13-72"><a href="#cb13-72" aria-hidden="true" tabindex="-1"></a>                                   verb_component_prior_precision[c];</span>
<span id="cb13-73"><a href="#cb13-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-74"><a href="#cb13-74" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-75"><a href="#cb13-75" aria-hidden="true" tabindex="-1"></a>    frame_component_prior_mean[c] = frame_component_prior_mean_aux[c] * </span>
<span id="cb13-76"><a href="#cb13-76" aria-hidden="true" tabindex="-1"></a>                                    frame_component_prior_mean[c<span class="dv">-1</span>];</span>
<span id="cb13-77"><a href="#cb13-77" aria-hidden="true" tabindex="-1"></a>    frame_component_prior_alpha[c] = frame_component_prior_mean[c] *</span>
<span id="cb13-78"><a href="#cb13-78" aria-hidden="true" tabindex="-1"></a>                                     frame_component_prior_precision[c];</span>
<span id="cb13-79"><a href="#cb13-79" aria-hidden="true" tabindex="-1"></a>    frame_component_prior_beta[c] = (<span class="fl">1.0</span> - frame_component_prior_mean[c]) *</span>
<span id="cb13-80"><a href="#cb13-80" aria-hidden="true" tabindex="-1"></a>                                    frame_component_prior_precision[c];</span>
<span id="cb13-81"><a href="#cb13-81" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb13-82"><a href="#cb13-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-83"><a href="#cb13-83" aria-hidden="true" tabindex="-1"></a>  <span class="co">// component the verb-frame acceptability</span></span>
<span id="cb13-84"><a href="#cb13-84" aria-hidden="true" tabindex="-1"></a>  <span class="dt">matrix</span>[N_verb,N_frame] verb_frame;</span>
<span id="cb13-85"><a href="#cb13-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-86"><a href="#cb13-86" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (v <span class="cf">in</span> <span class="dv">1</span>:N_verb) {</span>
<span id="cb13-87"><a href="#cb13-87" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (f <span class="cf">in</span> <span class="dv">1</span>:N_frame) {</span>
<span id="cb13-88"><a href="#cb13-88" aria-hidden="true" tabindex="-1"></a>      verb_frame[v,f] = <span class="fl">1.0</span>;</span>
<span id="cb13-89"><a href="#cb13-89" aria-hidden="true" tabindex="-1"></a>      <span class="cf">for</span> (c <span class="cf">in</span> <span class="dv">1</span>:N_component) {</span>
<span id="cb13-90"><a href="#cb13-90" aria-hidden="true" tabindex="-1"></a>        verb_frame[v,f] *= <span class="fl">1.0</span> - verb_component[v,c] * frame_component[f,c];</span>
<span id="cb13-91"><a href="#cb13-91" aria-hidden="true" tabindex="-1"></a>      }</span>
<span id="cb13-92"><a href="#cb13-92" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb13-93"><a href="#cb13-93" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb13-94"><a href="#cb13-94" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb13-95"><a href="#cb13-95" aria-hidden="true" tabindex="-1"></a>  verb_frame = <span class="fl">1.0</span> - verb_frame;</span>
<span id="cb13-96"><a href="#cb13-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-97"><a href="#cb13-97" aria-hidden="true" tabindex="-1"></a>  <span class="co">// compute the log-odds</span></span>
<span id="cb13-98"><a href="#cb13-98" aria-hidden="true" tabindex="-1"></a>  <span class="co">// used as a parameter of the ordered logistic</span></span>
<span id="cb13-99"><a href="#cb13-99" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>[N_resp] mu;</span>
<span id="cb13-100"><a href="#cb13-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-101"><a href="#cb13-101" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (n <span class="cf">in</span> <span class="dv">1</span>:N_resp) {</span>
<span id="cb13-102"><a href="#cb13-102" aria-hidden="true" tabindex="-1"></a>    mu[n] = logit(verb_frame[verb[n],frame[n]]);</span>
<span id="cb13-103"><a href="#cb13-103" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb13-104"><a href="#cb13-104" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb14" data-startfrom="106" data-code-line-numbers=""><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan" style="counter-reset: source-line 105;"><span id="cb14-106"><a href="#cb14-106" aria-hidden="true" tabindex="-1"></a><span class="kw">model</span> {</span>
<span id="cb14-107"><a href="#cb14-107" aria-hidden="true" tabindex="-1"></a>  <span class="co">// sample the component mean auxiliary variable hyperpriors</span></span>
<span id="cb14-108"><a href="#cb14-108" aria-hidden="true" tabindex="-1"></a>  verb_component_prior_mean_aux ~ beta(alpha, <span class="dv">1</span>);</span>
<span id="cb14-109"><a href="#cb14-109" aria-hidden="true" tabindex="-1"></a>  frame_component_prior_mean_aux ~ beta(alpha, <span class="dv">1</span>);</span>
<span id="cb14-110"><a href="#cb14-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-111"><a href="#cb14-111" aria-hidden="true" tabindex="-1"></a>  <span class="co">// sample the component precision hyperpriors</span></span>
<span id="cb14-112"><a href="#cb14-112" aria-hidden="true" tabindex="-1"></a>  verb_component_prior_precision ~ exponential(<span class="dv">1</span>);</span>
<span id="cb14-113"><a href="#cb14-113" aria-hidden="true" tabindex="-1"></a>  frame_component_prior_precision ~ exponential(<span class="dv">1</span>);</span>
<span id="cb14-114"><a href="#cb14-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-115"><a href="#cb14-115" aria-hidden="true" tabindex="-1"></a>  <span class="co">// sample the component priors</span></span>
<span id="cb14-116"><a href="#cb14-116" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (v <span class="cf">in</span> <span class="dv">1</span>:N_verb)</span>
<span id="cb14-117"><a href="#cb14-117" aria-hidden="true" tabindex="-1"></a>    verb_component[v] ~ beta(verb_component_prior_alpha, verb_component_prior_beta);</span>
<span id="cb14-118"><a href="#cb14-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-119"><a href="#cb14-119" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (f <span class="cf">in</span> <span class="dv">1</span>:N_frame)</span>
<span id="cb14-120"><a href="#cb14-120" aria-hidden="true" tabindex="-1"></a>    frame_component[f] ~ beta(frame_component_prior_alpha, frame_component_prior_beta);</span>
<span id="cb14-121"><a href="#cb14-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-122"><a href="#cb14-122" aria-hidden="true" tabindex="-1"></a>  <span class="co">// sample the cutpoints</span></span>
<span id="cb14-123"><a href="#cb14-123" aria-hidden="true" tabindex="-1"></a>  cutpoints ~ normal(<span class="dv">0</span>, <span class="dv">1</span>);</span>
<span id="cb14-124"><a href="#cb14-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-125"><a href="#cb14-125" aria-hidden="true" tabindex="-1"></a>  <span class="co">// sample the responses</span></span>
<span id="cb14-126"><a href="#cb14-126" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (n <span class="cf">in</span> <span class="dv">1</span>:N_resp) {</span>
<span id="cb14-127"><a href="#cb14-127" aria-hidden="true" tabindex="-1"></a>    resp[n] ~ ordered_logistic(mu[n], cutpoints);</span>
<span id="cb14-128"><a href="#cb14-128" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb14-129"><a href="#cb14-129" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>One issue with the implementation in STAN is that sampling under this parameterization turns out to be infeasible, so we need to turn to the sort of optimization discussed in the last section. STAN <a href="https://mc-stan.org/docs/reference-manual/optimization.html#optimization.chapter">supports</a> this sort of optimization, but (as far I know) it does not support stochastic gradient ascent/descent.<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a></p>
</section>
<section id="implementation-in-pytorch" class="level3">
<h3 class="anchored" data-anchor-id="implementation-in-pytorch">Implementation in PyTorch</h3>
<p>Using <code>torch</code> will give us the ability to implement MAP estimation with stochastic gradient descent. We basically need to design two components: (i) a <code>torch.nn.Module</code>, which is effectively used as a container for our models parameters that also specifies the analogue of STAN’s <code>transformed parameters</code> block; and (ii) a trainer class that computes the posterior of those parameters against some data and runs stochastic gradient descent.<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a> We’ll specify the first here and the second in the next section.</p>
<p>We’ll first specify a <code>dataclass</code> representing the data.</p>
<div class="cell" data-tags="[]" data-execution_count="105">
<div class="sourceCode cell-code" id="cb15" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dataclasses <span class="im">import</span> dataclass</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="at">@dataclass</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> SelectionData:</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>    verb: ndarray</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>    frame: ndarray</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>    subj: ndarray</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>    resp: ndarray</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We’ll also specify <code>dataclass</code>es that declare the paremeters that the model needs to have access to. We’ll use <code>SelectionModelParametersABC</code> across all of our models.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb16" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="at">@dataclass</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> SelectionModelParametersABC:</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>    n_verb: <span class="bu">int</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>    n_frame: <span class="bu">int</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>    n_subj: <span class="bu">int</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>    n_resp_levels: <span class="bu">int</span></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a><span class="at">@dataclass</span></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> SelectionModelParameters(BaseSelectionModelParametersABC):</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>    n_component: <span class="bu">int</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Note that <code>SelectionModelParameters</code> does specify the parameter <span class="math inline">\(a\)</span> of the stick-breaking process. This is because we only need <span class="math inline">\(a\)</span> for computing the posterior–specifically, when we compute the prior–and so only the trainer needs to know it.</p>
<p>As in Module 1, we’ll us an ordered logistic likelihood. In contrast to that module, however, we will implement all cutpoints as subject-specific, and we’ll place an exponential prior on their distances.</p>
<p><span class="math display">\[C_{sr} - C_{s(r-1)} \sim \text{Exponential}\left(\lambda^\text{subj}_r\right)\]</span></p>
<p>We’ll furthermore center them so that the 4 bin generally corresponds to an acceptability of 0.5. This assumption is important not only for identifiability reasons, but also because, following <span class="citation" data-cites="white_computational_2016">White and Rawlins (<a href="#ref-white_computational_2016" role="doc-biblioref">2016</a>)</span>, we assume that the value getting binned is <span class="math inline">\(\text{logit}(\alpha_{vf})\)</span>, rather than <span class="math inline">\(\alpha_{vf}\)</span> itself.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb17" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch <span class="im">import</span> Tensor</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> ordered_logistic_likelihood(value: Tensor, jumps: Tensor, center: <span class="bu">bool</span> <span class="op">=</span> <span class="va">True</span>) <span class="op">-&gt;</span> Tensor:</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Compute the ordered logistic likelihood given a value</span></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters</span></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a><span class="co">    ----------</span></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a><span class="co">    value</span></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a><span class="co">        The value to compute the likelihood for </span></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a><span class="co">        (shape: batch_size)</span></span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a><span class="co">    jumps</span></span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a><span class="co">        The distance between cutpoints </span></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a><span class="co">        (shape: batch_size x number of response levels - 1)</span></span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns</span></span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a><span class="co">    -------</span></span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a><span class="co">    log_likelihood</span></span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a><span class="co">        the ordered logistic log-likelihood</span></span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a>    cutpoints <span class="op">=</span> torch.cumsum(jumps, axis<span class="op">=</span><span class="dv">1</span>) </span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> center:</span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a>        cutpoints <span class="op">=</span> cutpoints <span class="op">-</span> cutpoints.mean(<span class="dv">1</span>)[:,<span class="va">None</span>]</span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb17-26"><a href="#cb17-26" aria-hidden="true" tabindex="-1"></a>    cdfs <span class="op">=</span> torch.sigmoid(cutpoints <span class="op">-</span> value[:,<span class="va">None</span>])</span>
<span id="cb17-27"><a href="#cb17-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-28"><a href="#cb17-28" aria-hidden="true" tabindex="-1"></a>    low_prob <span class="op">=</span> torch.cat(</span>
<span id="cb17-29"><a href="#cb17-29" aria-hidden="true" tabindex="-1"></a>        [torch.zeros([cdfs.shape[<span class="dv">0</span>], <span class="dv">1</span>]), cdfs],</span>
<span id="cb17-30"><a href="#cb17-30" aria-hidden="true" tabindex="-1"></a>        axis<span class="op">=</span><span class="dv">1</span></span>
<span id="cb17-31"><a href="#cb17-31" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb17-32"><a href="#cb17-32" aria-hidden="true" tabindex="-1"></a>    high_prob <span class="op">=</span> torch.cat(</span>
<span id="cb17-33"><a href="#cb17-33" aria-hidden="true" tabindex="-1"></a>        [cdfs, torch.ones([cdfs.shape[<span class="dv">0</span>], <span class="dv">1</span>])],</span>
<span id="cb17-34"><a href="#cb17-34" aria-hidden="true" tabindex="-1"></a>        axis<span class="op">=</span><span class="dv">1</span></span>
<span id="cb17-35"><a href="#cb17-35" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb17-36"><a href="#cb17-36" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb17-37"><a href="#cb17-37" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> high_prob <span class="op">-</span> low_prob</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The reasoning behind this assumption has to do with the fact that we can’t simply bin directly on <span class="math inline">\([0, 1]\)</span> due to the assumption that the noise term implicit in an ordered logistic is assumed to be distributed standard logistic and therefore most of the middle categories would get very little probability.<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb18" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch <span class="im">import</span> manual_seed</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.nn <span class="im">import</span> Module, randn</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>ZERO <span class="op">=</span> <span class="fl">1e-3</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>ONE <span class="op">=</span> <span class="fl">1.</span> <span class="op">-</span> ZERO</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> SelectionModel(Module):</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>    parameter_class <span class="op">=</span> SelectionModelParameters</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>    data_class <span class="op">=</span> SelectionData</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, parameters: SelectionModelParameters):</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model_parameters <span class="op">=</span> parameters</span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>        <span class="co"># prior parameters</span></span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.verb_component_prior_mean_aux <span class="op">=</span> torch.nn.Parameter(</span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a>            randn(parameters.n_component), </span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a>            requires_grad<span class="op">=</span><span class="va">True</span></span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.frame_component_prior_mean_aux <span class="op">=</span> torch.nn.Parameter(</span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a>            randn(parameters.n_component), </span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a>            requires_grad<span class="op">=</span><span class="va">True</span></span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb18-26"><a href="#cb18-26" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.verb_component_prior_precision_aux <span class="op">=</span> torch.nn.Parameter(</span>
<span id="cb18-27"><a href="#cb18-27" aria-hidden="true" tabindex="-1"></a>            randn(parameters.n_component), </span>
<span id="cb18-28"><a href="#cb18-28" aria-hidden="true" tabindex="-1"></a>            requires_grad<span class="op">=</span><span class="va">True</span></span>
<span id="cb18-29"><a href="#cb18-29" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb18-30"><a href="#cb18-30" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.frame_component_prior_precision_aux <span class="op">=</span> torch.nn.Parameter(</span>
<span id="cb18-31"><a href="#cb18-31" aria-hidden="true" tabindex="-1"></a>            randn(parameters.n_component), </span>
<span id="cb18-32"><a href="#cb18-32" aria-hidden="true" tabindex="-1"></a>            requires_grad<span class="op">=</span><span class="va">True</span></span>
<span id="cb18-33"><a href="#cb18-33" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb18-34"><a href="#cb18-34" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb18-35"><a href="#cb18-35" aria-hidden="true" tabindex="-1"></a>        <span class="co"># latent matrices</span></span>
<span id="cb18-36"><a href="#cb18-36" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.verb_component_aux <span class="op">=</span> torch.nn.Parameter(</span>
<span id="cb18-37"><a href="#cb18-37" aria-hidden="true" tabindex="-1"></a>            randn([</span>
<span id="cb18-38"><a href="#cb18-38" aria-hidden="true" tabindex="-1"></a>                parameters.n_verb, parameters.n_component</span>
<span id="cb18-39"><a href="#cb18-39" aria-hidden="true" tabindex="-1"></a>            ]), </span>
<span id="cb18-40"><a href="#cb18-40" aria-hidden="true" tabindex="-1"></a>            requires_grad<span class="op">=</span><span class="va">True</span></span>
<span id="cb18-41"><a href="#cb18-41" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb18-42"><a href="#cb18-42" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.frame_component_aux <span class="op">=</span> torch.nn.Parameter(</span>
<span id="cb18-43"><a href="#cb18-43" aria-hidden="true" tabindex="-1"></a>            randn([</span>
<span id="cb18-44"><a href="#cb18-44" aria-hidden="true" tabindex="-1"></a>                parameters.n_frame, parameters.n_component</span>
<span id="cb18-45"><a href="#cb18-45" aria-hidden="true" tabindex="-1"></a>            ]), </span>
<span id="cb18-46"><a href="#cb18-46" aria-hidden="true" tabindex="-1"></a>            requires_grad<span class="op">=</span><span class="va">True</span></span>
<span id="cb18-47"><a href="#cb18-47" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb18-48"><a href="#cb18-48" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb18-49"><a href="#cb18-49" aria-hidden="true" tabindex="-1"></a>        <span class="co"># likelihood parameters</span></span>
<span id="cb18-50"><a href="#cb18-50" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.log_jumps <span class="op">=</span> torch.nn.Parameter(</span>
<span id="cb18-51"><a href="#cb18-51" aria-hidden="true" tabindex="-1"></a>            torch.ones([</span>
<span id="cb18-52"><a href="#cb18-52" aria-hidden="true" tabindex="-1"></a>                parameters.n_subj, parameters.n_resp_levels<span class="op">-</span><span class="dv">1</span></span>
<span id="cb18-53"><a href="#cb18-53" aria-hidden="true" tabindex="-1"></a>            ]), </span>
<span id="cb18-54"><a href="#cb18-54" aria-hidden="true" tabindex="-1"></a>            requires_grad<span class="op">=</span><span class="va">True</span></span>
<span id="cb18-55"><a href="#cb18-55" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb18-56"><a href="#cb18-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-57"><a href="#cb18-57" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, data: SelectionData):</span>
<span id="cb18-58"><a href="#cb18-58" aria-hidden="true" tabindex="-1"></a>        <span class="co"># compute the verb frame probabilities</span></span>
<span id="cb18-59"><a href="#cb18-59" aria-hidden="true" tabindex="-1"></a>        verb_frame_prob <span class="op">=</span> <span class="va">self</span>.verb_frame_prob(</span>
<span id="cb18-60"><a href="#cb18-60" aria-hidden="true" tabindex="-1"></a>            data.verb, data.frame,</span>
<span id="cb18-61"><a href="#cb18-61" aria-hidden="true" tabindex="-1"></a>            clamp<span class="op">=</span><span class="va">True</span></span>
<span id="cb18-62"><a href="#cb18-62" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb18-63"><a href="#cb18-63" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb18-64"><a href="#cb18-64" aria-hidden="true" tabindex="-1"></a>        <span class="co"># apply a logit to those probabilities</span></span>
<span id="cb18-65"><a href="#cb18-65" aria-hidden="true" tabindex="-1"></a>        verb_frame_logodds <span class="op">=</span> torch.log(verb_frame_prob) <span class="op">-\</span></span>
<span id="cb18-66"><a href="#cb18-66" aria-hidden="true" tabindex="-1"></a>                             torch.log(<span class="fl">1.</span> <span class="op">-</span> verb_frame_prob)</span>
<span id="cb18-67"><a href="#cb18-67" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb18-68"><a href="#cb18-68" aria-hidden="true" tabindex="-1"></a>        <span class="co"># compute the jumps for each subject</span></span>
<span id="cb18-69"><a href="#cb18-69" aria-hidden="true" tabindex="-1"></a>        jumps <span class="op">=</span> <span class="va">self</span>.jumps[data.subj]</span>
<span id="cb18-70"><a href="#cb18-70" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb18-71"><a href="#cb18-71" aria-hidden="true" tabindex="-1"></a>        <span class="co"># return the ordered logistic probabilities</span></span>
<span id="cb18-72"><a href="#cb18-72" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> ordered_logistic_likelihood(</span>
<span id="cb18-73"><a href="#cb18-73" aria-hidden="true" tabindex="-1"></a>            verb_frame_logodds, jumps</span>
<span id="cb18-74"><a href="#cb18-74" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb18-75"><a href="#cb18-75" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-76"><a href="#cb18-76" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> verb_frame_prob(</span>
<span id="cb18-77"><a href="#cb18-77" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>, </span>
<span id="cb18-78"><a href="#cb18-78" aria-hidden="true" tabindex="-1"></a>        verb_idx: Optional[ndarray] <span class="op">=</span> <span class="va">None</span>, </span>
<span id="cb18-79"><a href="#cb18-79" aria-hidden="true" tabindex="-1"></a>        frame_idx: Optional[ndarray] <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb18-80"><a href="#cb18-80" aria-hidden="true" tabindex="-1"></a>        clamp: <span class="bu">bool</span> <span class="op">=</span> <span class="va">False</span></span>
<span id="cb18-81"><a href="#cb18-81" aria-hidden="true" tabindex="-1"></a>    ) <span class="op">-&gt;</span> Tensor:</span>
<span id="cb18-82"><a href="#cb18-82" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> verb_idx <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="kw">or</span> frame_idx <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb18-83"><a href="#cb18-83" aria-hidden="true" tabindex="-1"></a>            acc <span class="op">=</span> <span class="fl">1.</span> <span class="op">-</span> torch.prod(</span>
<span id="cb18-84"><a href="#cb18-84" aria-hidden="true" tabindex="-1"></a>                <span class="fl">1.</span> <span class="op">-</span> <span class="va">self</span>.verb_component_prob[verb_idx,:] <span class="op">*</span> </span>
<span id="cb18-85"><a href="#cb18-85" aria-hidden="true" tabindex="-1"></a>                     <span class="va">self</span>.frame_component_prob[frame_idx,:],</span>
<span id="cb18-86"><a href="#cb18-86" aria-hidden="true" tabindex="-1"></a>                axis<span class="op">=</span><span class="dv">1</span></span>
<span id="cb18-87"><a href="#cb18-87" aria-hidden="true" tabindex="-1"></a>            ).clamp(ZERO, ONE)</span>
<span id="cb18-88"><a href="#cb18-88" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> verb_idx <span class="kw">is</span> <span class="va">None</span> <span class="kw">and</span> frame_idx <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb18-89"><a href="#cb18-89" aria-hidden="true" tabindex="-1"></a>            acc <span class="op">=</span> <span class="fl">1.</span> <span class="op">-</span> torch.prod(</span>
<span id="cb18-90"><a href="#cb18-90" aria-hidden="true" tabindex="-1"></a>                <span class="fl">1.</span> <span class="op">-</span> <span class="va">self</span>.verb_component_prob[:,<span class="va">None</span>,:] <span class="op">*</span> </span>
<span id="cb18-91"><a href="#cb18-91" aria-hidden="true" tabindex="-1"></a>                     <span class="va">self</span>.frame_component_prob[:,frame_idx,:],</span>
<span id="cb18-92"><a href="#cb18-92" aria-hidden="true" tabindex="-1"></a>                axis<span class="op">=</span><span class="dv">2</span></span>
<span id="cb18-93"><a href="#cb18-93" aria-hidden="true" tabindex="-1"></a>            ).clamp(ZERO, ONE)</span>
<span id="cb18-94"><a href="#cb18-94" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> verb_idx <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="kw">and</span> frame_idx <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb18-95"><a href="#cb18-95" aria-hidden="true" tabindex="-1"></a>            acc <span class="op">=</span> <span class="fl">1.</span> <span class="op">-</span> torch.prod(</span>
<span id="cb18-96"><a href="#cb18-96" aria-hidden="true" tabindex="-1"></a>                <span class="fl">1.</span> <span class="op">-</span> <span class="va">self</span>.verb_component_prob[verb_idx,<span class="va">None</span>,:] <span class="op">*</span> </span>
<span id="cb18-97"><a href="#cb18-97" aria-hidden="true" tabindex="-1"></a>                     <span class="va">self</span>.frame_component_prob[<span class="va">None</span>,:,:],</span>
<span id="cb18-98"><a href="#cb18-98" aria-hidden="true" tabindex="-1"></a>                axis<span class="op">=</span><span class="dv">2</span></span>
<span id="cb18-99"><a href="#cb18-99" aria-hidden="true" tabindex="-1"></a>            ).clamp(ZERO, ONE)</span>
<span id="cb18-100"><a href="#cb18-100" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb18-101"><a href="#cb18-101" aria-hidden="true" tabindex="-1"></a>            acc <span class="op">=</span> <span class="fl">1.</span> <span class="op">-</span> torch.prod(</span>
<span id="cb18-102"><a href="#cb18-102" aria-hidden="true" tabindex="-1"></a>                <span class="fl">1.</span> <span class="op">-</span> <span class="va">self</span>.verb_component_prob[:,<span class="va">None</span>,:] <span class="op">*</span> </span>
<span id="cb18-103"><a href="#cb18-103" aria-hidden="true" tabindex="-1"></a>                     <span class="va">self</span>.frame_component_prob[<span class="va">None</span>,:,:],</span>
<span id="cb18-104"><a href="#cb18-104" aria-hidden="true" tabindex="-1"></a>                axis<span class="op">=</span><span class="dv">2</span></span>
<span id="cb18-105"><a href="#cb18-105" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb18-106"><a href="#cb18-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-107"><a href="#cb18-107" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> clamp:</span>
<span id="cb18-108"><a href="#cb18-108" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> acc.clamp(ZERO, ONE)</span>
<span id="cb18-109"><a href="#cb18-109" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb18-110"><a href="#cb18-110" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> acc</span>
<span id="cb18-111"><a href="#cb18-111" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-112"><a href="#cb18-112" aria-hidden="true" tabindex="-1"></a>    <span class="at">@property</span></span>
<span id="cb18-113"><a href="#cb18-113" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> verb_component_prob(<span class="va">self</span>) <span class="op">-&gt;</span> Tensor:</span>
<span id="cb18-114"><a href="#cb18-114" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.sigmoid(<span class="va">self</span>.verb_component_aux)</span>
<span id="cb18-115"><a href="#cb18-115" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-116"><a href="#cb18-116" aria-hidden="true" tabindex="-1"></a>    <span class="at">@property</span></span>
<span id="cb18-117"><a href="#cb18-117" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> frame_component_prob(<span class="va">self</span>) <span class="op">-&gt;</span> Tensor:</span>
<span id="cb18-118"><a href="#cb18-118" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.sigmoid(<span class="va">self</span>.frame_component_aux)</span>
<span id="cb18-119"><a href="#cb18-119" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-120"><a href="#cb18-120" aria-hidden="true" tabindex="-1"></a>    <span class="at">@property</span></span>
<span id="cb18-121"><a href="#cb18-121" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> jumps(<span class="va">self</span>):</span>
<span id="cb18-122"><a href="#cb18-122" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.exp(<span class="va">self</span>.log_jumps)</span>
<span id="cb18-123"><a href="#cb18-123" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-124"><a href="#cb18-124" aria-hidden="true" tabindex="-1"></a>    <span class="at">@property</span></span>
<span id="cb18-125"><a href="#cb18-125" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> verb_component_prior_mean(<span class="va">self</span>):</span>
<span id="cb18-126"><a href="#cb18-126" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.sigmoid(<span class="va">self</span>.verb_component_prior_mean_aux)</span>
<span id="cb18-127"><a href="#cb18-127" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-128"><a href="#cb18-128" aria-hidden="true" tabindex="-1"></a>    <span class="at">@property</span></span>
<span id="cb18-129"><a href="#cb18-129" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> frame_component_prior_mean(<span class="va">self</span>):</span>
<span id="cb18-130"><a href="#cb18-130" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.sigmoid(<span class="va">self</span>.frame_component_prior_mean_aux)</span>
<span id="cb18-131"><a href="#cb18-131" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-132"><a href="#cb18-132" aria-hidden="true" tabindex="-1"></a>    <span class="at">@property</span></span>
<span id="cb18-133"><a href="#cb18-133" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> verb_component_prior_precision(<span class="va">self</span>):</span>
<span id="cb18-134"><a href="#cb18-134" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.exp(<span class="va">self</span>.verb_component_prior_precision_aux)</span>
<span id="cb18-135"><a href="#cb18-135" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-136"><a href="#cb18-136" aria-hidden="true" tabindex="-1"></a>    <span class="at">@property</span></span>
<span id="cb18-137"><a href="#cb18-137" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> frame_component_prior_precision(<span class="va">self</span>):</span>
<span id="cb18-138"><a href="#cb18-138" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.exp(<span class="va">self</span>.frame_component_prior_precision_aux)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="complex-syntactic-and-semantic-types" class="level2">
<h2 class="anchored" data-anchor-id="complex-syntactic-and-semantic-types">Complex syntactic and semantic types</h2>
<p>As mentioned by <span class="citation" data-cites="white_computational_2016">White and Rawlins (<a href="#ref-white_computational_2016" role="doc-biblioref">2016</a>)</span>, this model of selection is very coarse-grained in that it fails to capture that both semantic and syntactic types have structure. This structure is important in the current context because the hypotheses that <span class="citation" data-cites="lohninger_typology_2020">Lohninger and Wurmbrand (<a href="#ref-lohninger_typology_2020" role="doc-biblioref">to appear</a>)</span> present make important reference to the relationship between particular elements (or <em>primitive types</em>) that constitute a structured (or <em>complex</em>) type. For instance, <span class="citation" data-cites="wurmbrand_implicational_2023">Wurmbrand and Lohninger (<a href="#ref-wurmbrand_implicational_2023" role="doc-biblioref">2023</a>)</span> suggest that, while particular languages may make finer-grained distinctions, there are three coarse-grained semantic types that are mapped monotonically to three coarse-grained syntactic types, both ordered by some notion of containment <span class="citation" data-cites="ramchand_deriving_2014">(<a href="#ref-ramchand_deriving_2014" role="doc-biblioref">Ramchand and Svenonius 2014</a>)</span>.</p>
<p>To incorporate this idea of structure into our models, the first thing we need to figure out is how to represent the distinction between a primitive type and a complex type. As I mentioned in <a href="#selecting-a-number-of-types">introducing the non-parametric prior</a> we added to White and Rawlins’ model, in formal semantics following <span class="citation" data-cites="montague_proper_1973">Montague (<a href="#ref-montague_proper_1973" role="doc-biblioref">1973</a>)</span>, we tend to assume that complex semantic types <span class="math inline">\(\mathcal{T} \equiv \bigcup_{j=1}^\infty \mathcal{T}_j\)</span> are inductively defined in terms of some finite set of primitive types <span class="math inline">\(\mathcal{T}_0\)</span> and <span class="math inline">\(\mathcal{T}_i = \left[\bigcup_{j=1}^{i-1} \mathcal{T}_j\right]^2\)</span>.</p>
<div class="cell" data-tags="[]" data-execution_count="96">
<div class="sourceCode cell-code" id="cb19" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> typing <span class="im">import</span> Generator, Optional, Union, Tuple, Set</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> defaultdict</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> itertools <span class="im">import</span> product</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>PrimitiveType <span class="op">=</span> <span class="bu">str</span></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>ComplexType <span class="op">=</span> Union[PrimitiveType, Tuple[<span class="st">'ComplexType'</span>, <span class="st">'ComplexType'</span>]]</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> natural_numbers() <span class="op">-&gt;</span> Generator[<span class="bu">int</span>, <span class="va">None</span>, <span class="va">None</span>]:</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""The natural numbers excluding 0"""</span></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>    i <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> <span class="va">True</span>:</span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>        i <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">yield</span> i</span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> complex_types(</span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a>    primitive_types: Set[PrimitiveType], max_size: Optional[<span class="bu">int</span>] <span class="op">=</span> <span class="va">None</span></span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a>) <span class="op">-&gt;</span> Generator[MontagueType, <span class="va">None</span>, <span class="va">None</span>]:</span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a>    types <span class="op">=</span> defaultdict(<span class="bu">list</span>)</span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> t <span class="kw">in</span> primitive_types:</span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a>        types[<span class="dv">0</span>].append(t)</span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a>        <span class="cf">yield</span> t</span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb19-25"><a href="#cb19-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> natural_numbers():</span>
<span id="cb19-26"><a href="#cb19-26" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> max_size <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="kw">and</span> i <span class="op">&gt;</span> max_size:</span>
<span id="cb19-27"><a href="#cb19-27" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span></span>
<span id="cb19-28"><a href="#cb19-28" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb19-29"><a href="#cb19-29" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j1 <span class="kw">in</span> <span class="bu">range</span>(i):</span>
<span id="cb19-30"><a href="#cb19-30" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> j2 <span class="kw">in</span> <span class="bu">range</span>(i):</span>
<span id="cb19-31"><a href="#cb19-31" aria-hidden="true" tabindex="-1"></a>                <span class="cf">for</span> t <span class="kw">in</span> product(types[j1], types[j2]):</span>
<span id="cb19-32"><a href="#cb19-32" aria-hidden="true" tabindex="-1"></a>                    types[i].append(t)</span>
<span id="cb19-33"><a href="#cb19-33" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">yield</span> t</span>
<span id="cb19-34"><a href="#cb19-34" aria-hidden="true" tabindex="-1"></a>                    </span>
<span id="cb19-35"><a href="#cb19-35" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, t <span class="kw">in</span> <span class="bu">enumerate</span>(complex_types({<span class="st">"e"</span>, <span class="st">"t"</span>})):</span>
<span id="cb19-36"><a href="#cb19-36" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> i <span class="op">&lt;</span> <span class="dv">20</span>:</span>
<span id="cb19-37"><a href="#cb19-37" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(t)</span>
<span id="cb19-38"><a href="#cb19-38" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb19-39"><a href="#cb19-39" aria-hidden="true" tabindex="-1"></a>        <span class="cf">break</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre data-code-line-numbers=""><code>e
t
('e', 'e')
('e', 't')
('t', 'e')
('t', 't')
('e', 'e')
('e', 't')
('t', 'e')
('t', 't')
('e', ('e', 'e'))
('e', ('e', 't'))
('e', ('t', 'e'))
('e', ('t', 't'))
('t', ('e', 'e'))
('t', ('e', 't'))
('t', ('t', 'e'))
('t', ('t', 't'))
(('e', 'e'), 'e')
(('e', 'e'), 't')</code></pre>
</div>
</div>
<p>A similar approach is taken to syntactic structures in combinatory categorial grammar, where directed <em>type constructors</em> <code>\</code> and <code>/</code> are added <span class="citation" data-cites="steedman_combinatory_2011">(see <a href="#ref-steedman_combinatory_2011" role="doc-biblioref">Steedman and Baldridge 2011</a> and references therein)</span>.</p>
<div class="cell" data-tags="[]" data-execution_count="95">
<div class="sourceCode cell-code" id="cb21" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>TypeConstructor <span class="op">=</span> <span class="bu">str</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>ComplexType <span class="op">=</span> Union[PrimitiveType, Tuple[<span class="st">'ComplexType'</span>, TypeConstructor, <span class="st">'ComplexType'</span>]]</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> natural_numbers() <span class="op">-&gt;</span> Generator[<span class="bu">int</span>, <span class="va">None</span>, <span class="va">None</span>]:</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""The natural numbers excluding 0"""</span></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>    i <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> <span class="va">True</span>:</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>        i <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>        <span class="cf">yield</span> i</span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> complex_types(</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>    primitive_types: Set[PrimitiveType], </span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>    type_constructors: Set[TypeConstructor], </span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>    max_size: Optional[<span class="bu">int</span>] <span class="op">=</span> <span class="va">None</span></span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>) <span class="op">-&gt;</span> Generator[MontagueType, <span class="va">None</span>, <span class="va">None</span>]:</span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>    types <span class="op">=</span> defaultdict(<span class="bu">list</span>)</span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> t <span class="kw">in</span> primitive_types:</span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a>        types[<span class="dv">0</span>].append(t)</span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a>        <span class="cf">yield</span> t</span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> natural_numbers():</span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> max_size <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="kw">and</span> i <span class="op">&gt;</span> max_size:</span>
<span id="cb21-25"><a href="#cb21-25" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span></span>
<span id="cb21-26"><a href="#cb21-26" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb21-27"><a href="#cb21-27" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j1 <span class="kw">in</span> <span class="bu">range</span>(i):</span>
<span id="cb21-28"><a href="#cb21-28" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> j2 <span class="kw">in</span> <span class="bu">range</span>(i):</span>
<span id="cb21-29"><a href="#cb21-29" aria-hidden="true" tabindex="-1"></a>                <span class="cf">for</span> t <span class="kw">in</span> product(types[j1], type_constructors, types[j2]):</span>
<span id="cb21-30"><a href="#cb21-30" aria-hidden="true" tabindex="-1"></a>                    types[i].append(t)</span>
<span id="cb21-31"><a href="#cb21-31" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">yield</span> t</span>
<span id="cb21-32"><a href="#cb21-32" aria-hidden="true" tabindex="-1"></a>                    </span>
<span id="cb21-33"><a href="#cb21-33" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, t <span class="kw">in</span> <span class="bu">enumerate</span>(complex_types({<span class="st">"NP"</span>, <span class="st">"S"</span>}, {<span class="vs">r"\\"</span>, <span class="st">"/"</span>})):</span>
<span id="cb21-34"><a href="#cb21-34" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> i <span class="op">&lt;</span> <span class="dv">20</span>:</span>
<span id="cb21-35"><a href="#cb21-35" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(t)</span>
<span id="cb21-36"><a href="#cb21-36" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb21-37"><a href="#cb21-37" aria-hidden="true" tabindex="-1"></a>        <span class="cf">break</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre data-code-line-numbers=""><code>NP
S
('NP', '\\\\', 'NP')
('NP', '\\\\', 'S')
('NP', '/', 'NP')
('NP', '/', 'S')
('S', '\\\\', 'NP')
('S', '\\\\', 'S')
('S', '/', 'NP')
('S', '/', 'S')
('NP', '\\\\', 'NP')
('NP', '\\\\', 'S')
('NP', '/', 'NP')
('NP', '/', 'S')
('S', '\\\\', 'NP')
('S', '\\\\', 'S')
('S', '/', 'NP')
('S', '/', 'S')
('NP', '\\\\', ('NP', '\\\\', 'NP'))
('NP', '\\\\', ('NP', '\\\\', 'S'))</code></pre>
</div>
</div>
<p>So both complex semantic types and complex syntactic types can be viewed as binary trees with type constructors as the non-terminals and the primitive types as the terminals.</p>
<p>We could imagine stating the generalizations described by <span class="citation" data-cites="lohninger_typology_2020">Lohninger and Wurmbrand (<a href="#ref-lohninger_typology_2020" role="doc-biblioref">to appear</a>)</span> in terms of ordered equivalence classes on these sorts of types. What’s crucial in this case is that the types form an equivalence class–not which types are contained in each class. So really we just want to be able to represent the equivalence class, which we can do without recognizing its constituency. That is, we can simply view the equivalence classes as primitive (i.e.&nbsp;unstructured) types that potentially have an ordering relation on them (probably determined by their constituency). A simple way to do this is to represent primitive semantic and syntactic types as integers.</p>
<p>Can we get away from having to represent complex types at all then? No.&nbsp;The reason is that clauses are not the only constituents in many of these sentences. <span id="exm-tell-good"></span> <span id="exm-tell-bad"></span> For instance, to explain why (1) is more acceptable than (2), we want to be able to appeal to two things: (i) that <em>tell</em> is good with finite clauses–e.g.&nbsp;because its type lives in a semantic equivalence class that maps onto a syntactic equivalence class that can be realized as <em>that something happened</em>; but also (ii) that <em>tell</em> prefers to have a direct object.</p>
<ol class="example" type="1">
<li>Someone told someone that something happened.</li>
<li>Someone told that something happened.</li>
</ol>
<p>So basically, we can’t abstract away <em>all</em> of the structure in the semantic and syntactic types. We need to retain some sorts of structure–e.g.&nbsp;the distinction between direct objects and clausal complements–while abstracting away others–e.g.&nbsp;what exactly the semantic and syntactic type of the clausal complement is in a relatively fine-grained type system like Montague’s. We’ll do this by viewing complex semantic and syntactic types as strings of primitive types. We’ll consider two ways of doing this: one that constrains the explanation of acceptability by an inherent ordering on primitive types and another that is unconstrained by this ordering.</p>
<p>So complex types will be strings of integers. Adding this structure in turn requires us to handle types of different complexity–e.g.&nbsp;that the complex syntactic type associated with (1) contains two primitive types while the one associated with (2) contains two. We’ll do this by thinking of all types as having the same complexity but by introducing the notion of a special null primitive type that “pads out” types of lower complexity.</p>
<section id="relationships-among-representations" class="level3">
<h3 class="anchored" data-anchor-id="relationships-among-representations">Relationships among representations</h3>
<p>The second thing we must handle is how to represent some additional relationships that we didn’t have to before.</p>
<section id="primitive-type-relationships" class="level4">
<h4 class="anchored" data-anchor-id="primitive-type-relationships">Primitive type relationships</h4>
<p>We’ll need to represent the relationship between semantic and syntactic primitive types as well as the relationship between syntactic primitive types and the constituents that may realize them. We’ll do both using matrices of probabilities similar to the ones we used in implemented White and Rawlins’ model–i.e.&nbsp;that are interpreted representing the probability that a particular object <em>can</em> be associated with some other object.</p>
<p>We’ll represent the relationship between semantic and syntactic primitive types in a matrix of probabilities <span class="math inline">\(\boldsymbol\Phi^\text{synsem} \in [0, 1]^{(K_\text{sem} + 1) \times (K_\text{syn} + 1)}\)</span>, where <span class="math inline">\(K_\text{sem}\)</span> is the number of semantic primitive types, <span class="math inline">\(K_\text{syn}\)</span> is the number of syntactic primitive types, and the additional type handles a null type. We’ll assume that null primitive semantic types only map onto null primitive syntactic types–<span class="math inline">\(\phi^\text{synsem}_{00} = 1\)</span> and <span class="math inline">\(\phi^\text{synsem}_{0t} = 0\)</span> for all non-null types <span class="math inline">\(t\)</span>–but we want to allow that null primitive syntactic types can be mapped onto by non-null primitive semantic types.</p>
<p><span id="exm-nca-leadup"></span> <span id="exm-nca"></span> We need this latter assumption to handle null complement anaphora, as in (4).</p>
<ol start="3" class="example" type="1">
<li><strong>A:</strong> Bo left.</li>
<li><strong>B:</strong> I {know, remember, heard, …}.</li>
</ol>
<p><span id="exm-nca-equivalent"></span> Baically, we want to be able to capture that (4) is interpreted as (5).</p>
<ol start="5" class="example" type="1">
<li><strong>B’:</strong> I {know, remember, heard, …} that Bo left.</li>
</ol>
<p>When the model incorporates ordering on the primitive types, we will constrain the mapping by the ordering by assuming that each non-null primitive type <span class="math inline">\(t\)</span> is associated with some probability distribution over <span class="math inline">\(K_\text{rank}\)</span> ranks <span class="math inline">\(\chi^\text{synsem} \sim \text{OrderedLogistic}(\zeta_t^\text{sem}, \mathbf{\kappa})\)</span> and that <span class="math inline">\(\phi^\text{synsem}_{tt'} \equiv \mathbb{P}\left(\chi_{t} = \chi_{t'}\right) = \sum_i \mathbb{P}\left(\chi_{t} = i\right)\mathbb{P}\left(\chi_{t'} = i\right)\)</span>. For instance, for wurmbrand_implicational_2023, <span class="math inline">\(K_\text{rank} = 3\)</span>.</p>
<p>We’ll represent the relationship between syntactic primitive types and the constituents that may realize them in a similar way: a matrix of probabilities <span class="math inline">\(\boldsymbol\Phi^\text{syn} \in [0, 1]^{(K_\text{syn} + 1) \times K_\text{const}}\)</span>. We’ll assume that <span class="math inline">\(\phi^\text{syn}_{0i} = 0\)</span> for all constituents <span class="math inline">\(i\)</span>–i.e.&nbsp;that the null type doesn’t map to any constituent–and that frames are decomposed into constituents in the following way (expand to see the frame-to-constituent mapping).</p>
<div class="cell" data-tags="[]" data-execution_count="97">
<details>
<summary>Frame-to-constitutent mapping</summary>
<div class="sourceCode cell-code" id="cb23" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> OrderedDict</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>frame_to_constituents <span class="op">=</span> OrderedDict({</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP was Ved whichNP to VP'</span>: {</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP_obj"</span>, <span class="st">"whichNP to VP"</span>),</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_obj"</span>, <span class="st">"whichNP to VP"</span>)</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>    }, </span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP Ved for NP to VP'</span>: {</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"for NP to VP"</span>), </span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"PP_for"</span>, <span class="st">"to VP"</span>)</span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP Ved NP to VP[+eventive]'</span>: {</span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP to VP[+eventive]"</span>), </span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP_obj"</span>, <span class="st">"to VP[+eventive]"</span>)</span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a>    }, </span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP was Ved whether to VP'</span>: {</span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP_obj"</span>, <span class="st">"whether to VP"</span>),</span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_obj"</span>, <span class="st">"whether to VP"</span>)</span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb23-20"><a href="#cb23-20" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP Ved to VP[+eventive]'</span>: {</span>
<span id="cb23-21"><a href="#cb23-21" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"to VP[+eventive]"</span>)</span>
<span id="cb23-22"><a href="#cb23-22" aria-hidden="true" tabindex="-1"></a>    }, </span>
<span id="cb23-23"><a href="#cb23-23" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP Ved NP to NP'</span>: {</span>
<span id="cb23-24"><a href="#cb23-24" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP_obj"</span>, <span class="st">"NP_iobj"</span>) </span>
<span id="cb23-25"><a href="#cb23-25" aria-hidden="true" tabindex="-1"></a>    }, </span>
<span id="cb23-26"><a href="#cb23-26" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP Ved NP that S'</span>: {</span>
<span id="cb23-27"><a href="#cb23-27" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP_obj"</span>, <span class="st">"that S"</span>) </span>
<span id="cb23-28"><a href="#cb23-28" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb23-29"><a href="#cb23-29" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP was Ved about NP'</span>: {</span>
<span id="cb23-30"><a href="#cb23-30" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP_obj"</span>, <span class="st">"about NP"</span>) ,</span>
<span id="cb23-31"><a href="#cb23-31" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_obj"</span>, <span class="st">"about NP"</span>) </span>
<span id="cb23-32"><a href="#cb23-32" aria-hidden="true" tabindex="-1"></a>    }, </span>
<span id="cb23-33"><a href="#cb23-33" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP was Ved that S[-tense]'</span>: {</span>
<span id="cb23-34"><a href="#cb23-34" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP_obj"</span>, <span class="st">"S[-tense]"</span>) ,</span>
<span id="cb23-35"><a href="#cb23-35" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_obj"</span>, <span class="st">"S[-tense]"</span>) </span>
<span id="cb23-36"><a href="#cb23-36" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb23-37"><a href="#cb23-37" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP Ved to NP that S[+future]'</span>: {</span>
<span id="cb23-38"><a href="#cb23-38" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP_iobj"</span>, <span class="st">"that S[+future]"</span>) </span>
<span id="cb23-39"><a href="#cb23-39" aria-hidden="true" tabindex="-1"></a>    }, </span>
<span id="cb23-40"><a href="#cb23-40" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP Ved whether to VP'</span>: {</span>
<span id="cb23-41"><a href="#cb23-41" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"whether to VP"</span>)</span>
<span id="cb23-42"><a href="#cb23-42" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb23-43"><a href="#cb23-43" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP Ved whichNP to VP'</span>: {</span>
<span id="cb23-44"><a href="#cb23-44" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"whichNP to VP"</span>)</span>
<span id="cb23-45"><a href="#cb23-45" aria-hidden="true" tabindex="-1"></a>    }, </span>
<span id="cb23-46"><a href="#cb23-46" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP Ved about whether S'</span>: {</span>
<span id="cb23-47"><a href="#cb23-47" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"about whether S"</span>) </span>
<span id="cb23-48"><a href="#cb23-48" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb23-49"><a href="#cb23-49" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP Ved whichNP S'</span>: {</span>
<span id="cb23-50"><a href="#cb23-50" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"whichNP S"</span>)</span>
<span id="cb23-51"><a href="#cb23-51" aria-hidden="true" tabindex="-1"></a>    }, </span>
<span id="cb23-52"><a href="#cb23-52" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP Ved that S[-tense]'</span>: {</span>
<span id="cb23-53"><a href="#cb23-53" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"that S[-tense]"</span>) </span>
<span id="cb23-54"><a href="#cb23-54" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb23-55"><a href="#cb23-55" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP Ved whether S[+future]'</span>: {</span>
<span id="cb23-56"><a href="#cb23-56" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"whether S[+future]"</span>) </span>
<span id="cb23-57"><a href="#cb23-57" aria-hidden="true" tabindex="-1"></a>    }, </span>
<span id="cb23-58"><a href="#cb23-58" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP was Ved that S[+future]'</span>: {</span>
<span id="cb23-59"><a href="#cb23-59" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP_obj"</span>, <span class="st">"that S[+future]"</span>) ,</span>
<span id="cb23-60"><a href="#cb23-60" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_obj"</span>, <span class="st">"that S[+future]"</span>) </span>
<span id="cb23-61"><a href="#cb23-61" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb23-62"><a href="#cb23-62" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP Ved to NP whether S'</span>: {</span>
<span id="cb23-63"><a href="#cb23-63" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP_iobj"</span>, <span class="st">"whether S"</span>) </span>
<span id="cb23-64"><a href="#cb23-64" aria-hidden="true" tabindex="-1"></a>    }, </span>
<span id="cb23-65"><a href="#cb23-65" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP Ved'</span>: {</span>
<span id="cb23-66"><a href="#cb23-66" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>,)</span>
<span id="cb23-67"><a href="#cb23-67" aria-hidden="true" tabindex="-1"></a>    }, </span>
<span id="cb23-68"><a href="#cb23-68" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP Ved NP to VP[-eventive]'</span>: {</span>
<span id="cb23-69"><a href="#cb23-69" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP to VP[-eventive]"</span>), </span>
<span id="cb23-70"><a href="#cb23-70" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP_obj"</span>, <span class="st">"to VP[-eventive]"</span>),</span>
<span id="cb23-71"><a href="#cb23-71" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP to VP[-eventive]"</span>)</span>
<span id="cb23-72"><a href="#cb23-72" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb23-73"><a href="#cb23-73" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP was Ved so'</span>: {</span>
<span id="cb23-74"><a href="#cb23-74" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_obj"</span>, <span class="st">"so"</span>), </span>
<span id="cb23-75"><a href="#cb23-75" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP_obj"</span>, <span class="st">"so"</span>)</span>
<span id="cb23-76"><a href="#cb23-76" aria-hidden="true" tabindex="-1"></a>    }, </span>
<span id="cb23-77"><a href="#cb23-77" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP Ved so'</span>: {</span>
<span id="cb23-78"><a href="#cb23-78" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"so"</span>)</span>
<span id="cb23-79"><a href="#cb23-79" aria-hidden="true" tabindex="-1"></a>    }, </span>
<span id="cb23-80"><a href="#cb23-80" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP Ved NP that S[+future]'</span>: {</span>
<span id="cb23-81"><a href="#cb23-81" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP_obj"</span>, <span class="st">"that S[+future]"</span>)</span>
<span id="cb23-82"><a href="#cb23-82" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb23-83"><a href="#cb23-83" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP Ved NP whether S[+future]'</span>: {</span>
<span id="cb23-84"><a href="#cb23-84" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP_obj"</span>, <span class="st">"whether S[+future]"</span>)</span>
<span id="cb23-85"><a href="#cb23-85" aria-hidden="true" tabindex="-1"></a>    }, </span>
<span id="cb23-86"><a href="#cb23-86" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP Ved to NP whether S[+future]'</span>: {</span>
<span id="cb23-87"><a href="#cb23-87" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP_iobj"</span>, <span class="st">"whether S[+future]"</span>)</span>
<span id="cb23-88"><a href="#cb23-88" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb23-89"><a href="#cb23-89" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP was Ved that S'</span>: {</span>
<span id="cb23-90"><a href="#cb23-90" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_obj"</span>, <span class="st">"that S"</span>), </span>
<span id="cb23-91"><a href="#cb23-91" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP_obj"</span>, <span class="st">"that S"</span>)</span>
<span id="cb23-92"><a href="#cb23-92" aria-hidden="true" tabindex="-1"></a>    }, </span>
<span id="cb23-93"><a href="#cb23-93" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP Ved NP whether S'</span>: {</span>
<span id="cb23-94"><a href="#cb23-94" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP_obj"</span>, <span class="st">"whether S"</span>)</span>
<span id="cb23-95"><a href="#cb23-95" aria-hidden="true" tabindex="-1"></a>    }, </span>
<span id="cb23-96"><a href="#cb23-96" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP was Ved whether S'</span>: {</span>
<span id="cb23-97"><a href="#cb23-97" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_obj"</span>, <span class="st">"whether S"</span>), </span>
<span id="cb23-98"><a href="#cb23-98" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP_obj"</span>, <span class="st">"whether S"</span>)</span>
<span id="cb23-99"><a href="#cb23-99" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb23-100"><a href="#cb23-100" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP was Ved to VP[-eventive]'</span>: {</span>
<span id="cb23-101"><a href="#cb23-101" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_obj"</span>, <span class="st">"to VP[-eventive]"</span>), </span>
<span id="cb23-102"><a href="#cb23-102" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP_obj"</span>, <span class="st">"to VP[-eventive]"</span>),</span>
<span id="cb23-103"><a href="#cb23-103" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP to VP[-eventive]"</span>)</span>
<span id="cb23-104"><a href="#cb23-104" aria-hidden="true" tabindex="-1"></a>    }, </span>
<span id="cb23-105"><a href="#cb23-105" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP Ved NP VP'</span>: {</span>
<span id="cb23-106"><a href="#cb23-106" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP_obj"</span>, <span class="st">"VP"</span>),</span>
<span id="cb23-107"><a href="#cb23-107" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP VP"</span>)</span>
<span id="cb23-108"><a href="#cb23-108" aria-hidden="true" tabindex="-1"></a>    }, </span>
<span id="cb23-109"><a href="#cb23-109" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP Ved VPing'</span>: {</span>
<span id="cb23-110"><a href="#cb23-110" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"VPing"</span>)</span>
<span id="cb23-111"><a href="#cb23-111" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb23-112"><a href="#cb23-112" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP was Ved to VP[+eventive]'</span>: {</span>
<span id="cb23-113"><a href="#cb23-113" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_obj"</span>, <span class="st">"to VP[+eventive]"</span>), </span>
<span id="cb23-114"><a href="#cb23-114" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP_obj"</span>, <span class="st">"to VP[+eventive]"</span>),</span>
<span id="cb23-115"><a href="#cb23-115" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP to VP[+eventive]"</span>)</span>
<span id="cb23-116"><a href="#cb23-116" aria-hidden="true" tabindex="-1"></a>    }, </span>
<span id="cb23-117"><a href="#cb23-117" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP Ved NP that S[-tense]'</span>: {</span>
<span id="cb23-118"><a href="#cb23-118" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP_obj"</span>, <span class="st">"that S[-tense]"</span>)</span>
<span id="cb23-119"><a href="#cb23-119" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb23-120"><a href="#cb23-120" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP Ved that S'</span>: {</span>
<span id="cb23-121"><a href="#cb23-121" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"that S"</span>)</span>
<span id="cb23-122"><a href="#cb23-122" aria-hidden="true" tabindex="-1"></a>    }, </span>
<span id="cb23-123"><a href="#cb23-123" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP was Ved'</span>: {</span>
<span id="cb23-124"><a href="#cb23-124" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_obj"</span>,), </span>
<span id="cb23-125"><a href="#cb23-125" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP_obj"</span>)</span>
<span id="cb23-126"><a href="#cb23-126" aria-hidden="true" tabindex="-1"></a>    }, </span>
<span id="cb23-127"><a href="#cb23-127" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP Ved S'</span>: {</span>
<span id="cb23-128"><a href="#cb23-128" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"S"</span>)</span>
<span id="cb23-129"><a href="#cb23-129" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb23-130"><a href="#cb23-130" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP Ved that S[+future]'</span>: {</span>
<span id="cb23-131"><a href="#cb23-131" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"that S[+future]"</span>)</span>
<span id="cb23-132"><a href="#cb23-132" aria-hidden="true" tabindex="-1"></a>    }, </span>
<span id="cb23-133"><a href="#cb23-133" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP was Ved about whether S'</span>: {</span>
<span id="cb23-134"><a href="#cb23-134" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP_obj"</span>, <span class="st">"about whether S"</span>) ,</span>
<span id="cb23-135"><a href="#cb23-135" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_obj"</span>, <span class="st">"about whether S"</span>) </span>
<span id="cb23-136"><a href="#cb23-136" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb23-137"><a href="#cb23-137" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP Ved NP'</span>: {</span>
<span id="cb23-138"><a href="#cb23-138" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP_obj"</span>) </span>
<span id="cb23-139"><a href="#cb23-139" aria-hidden="true" tabindex="-1"></a>    }, </span>
<span id="cb23-140"><a href="#cb23-140" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP Ved NP VPing'</span>: {</span>
<span id="cb23-141"><a href="#cb23-141" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP_obj"</span>, <span class="st">"VPing"</span>),</span>
<span id="cb23-142"><a href="#cb23-142" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP VPing"</span>)</span>
<span id="cb23-143"><a href="#cb23-143" aria-hidden="true" tabindex="-1"></a>    }, </span>
<span id="cb23-144"><a href="#cb23-144" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP Ved NP whichNP S'</span>: {</span>
<span id="cb23-145"><a href="#cb23-145" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP_obj"</span>, <span class="st">"whichNP S"</span>)</span>
<span id="cb23-146"><a href="#cb23-146" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb23-147"><a href="#cb23-147" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP Ved about NP'</span>: {</span>
<span id="cb23-148"><a href="#cb23-148" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"about NP"</span>) </span>
<span id="cb23-149"><a href="#cb23-149" aria-hidden="true" tabindex="-1"></a>    }, </span>
<span id="cb23-150"><a href="#cb23-150" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP was Ved S'</span>: {</span>
<span id="cb23-151"><a href="#cb23-151" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP_obj"</span>, <span class="st">"S"</span>) ,</span>
<span id="cb23-152"><a href="#cb23-152" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_obj"</span>, <span class="st">"S"</span>) </span>
<span id="cb23-153"><a href="#cb23-153" aria-hidden="true" tabindex="-1"></a>    }, </span>
<span id="cb23-154"><a href="#cb23-154" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP Ved to NP that S'</span>: {</span>
<span id="cb23-155"><a href="#cb23-155" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP_iobj"</span>, <span class="st">"that S"</span>),</span>
<span id="cb23-156"><a href="#cb23-156" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb23-157"><a href="#cb23-157" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP was Ved whether S[+future]'</span>: {</span>
<span id="cb23-158"><a href="#cb23-158" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP_obj"</span>, <span class="st">"whether S[+future]"</span>) ,</span>
<span id="cb23-159"><a href="#cb23-159" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_obj"</span>, <span class="st">"whether S[+future]"</span>) </span>
<span id="cb23-160"><a href="#cb23-160" aria-hidden="true" tabindex="-1"></a>    }, </span>
<span id="cb23-161"><a href="#cb23-161" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP Ved whether S'</span>: {</span>
<span id="cb23-162"><a href="#cb23-162" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"whether S"</span>) </span>
<span id="cb23-163"><a href="#cb23-163" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb23-164"><a href="#cb23-164" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP was Ved whichNP S'</span>: {</span>
<span id="cb23-165"><a href="#cb23-165" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP_obj"</span>, <span class="st">"whichNP S"</span>) ,</span>
<span id="cb23-166"><a href="#cb23-166" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_obj"</span>, <span class="st">"whichNP S"</span>) </span>
<span id="cb23-167"><a href="#cb23-167" aria-hidden="true" tabindex="-1"></a>    }, </span>
<span id="cb23-168"><a href="#cb23-168" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP Ved to NP that S[-tense]'</span>: {</span>
<span id="cb23-169"><a href="#cb23-169" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP_iobj"</span>, <span class="st">"that S[-tense]"</span>)</span>
<span id="cb23-170"><a href="#cb23-170" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb23-171"><a href="#cb23-171" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP Ved to VP[-eventive]'</span>: {</span>
<span id="cb23-172"><a href="#cb23-172" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"to VP[-eventive]"</span>)</span>
<span id="cb23-173"><a href="#cb23-173" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb23-174"><a href="#cb23-174" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb23-175"><a href="#cb23-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-176"><a href="#cb23-176" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> data[data.frame.isin(frame_to_constituents)]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>The thing to notice about these frame decompositions is that different frames have different possible <em>parses</em>. <span id="exm-tell-passive"></span> <span id="exm-annoy-passive"></span> <span id="exm-annoy-active"></span> <span id="exm-happy"></span> For instance, (6) should have the same parse as (1), but (7) might have the same parse as (8) or it might have a parse analogous to the clearly adjectival (9).</p>
<ol start="6" class="example" type="1">
<li>Someone was told that something happened.</li>
<li>Someone was annoyed that something happened.</li>
<li>It annoyed someone that something happened.</li>
<li>Someone was happy that something happened.</li>
</ol>
<p>So we need to represent that a particular syntactic type may map onto any of these parses and still be good. We’ll discuss how to do this shortly in terms of the following mapping from frames to parses to an indicator for whether that constituent is contained in that parse (expand to see). We’ll call this mapping <span class="math inline">\(\mathbf{C} \in \mathbb{B}^{F \times K_\text{parse} \times K_\text{const}}\)</span>, where <span class="math inline">\(F\)</span> is the number of frames, <span class="math inline">\(K_\text{parse}\)</span> is the maximum number of parses, and <span class="math inline">\(K_\text{const}\)</span> is the numberof constituent types.</p>
<div class="cell" data-tags="[]" data-execution_count="101">
<details>
<summary>Constituent-to-feature vector mapping</summary>
<div class="sourceCode cell-code" id="cb24" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> numpy <span class="im">import</span> array, zeros, where, isin</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> xarray <span class="im">import</span> DataArray</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>constituents <span class="op">=</span> array(<span class="bu">sorted</span>({</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>    c </span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> tups <span class="kw">in</span> frame_to_constituents.values() </span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> t <span class="kw">in</span> tups </span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> c <span class="kw">in</span> t</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>}))</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>max_parses <span class="op">=</span> <span class="bu">max</span>(</span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>    <span class="bu">len</span>(t) </span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> tups <span class="kw">in</span> frame_to_constituents.values() </span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> t <span class="kw">in</span> tups </span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a>frame_to_parse_constituent_indicators <span class="op">=</span> zeros([</span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a>    <span class="bu">len</span>(frame_to_constituents), max_parses, <span class="bu">len</span>(constituents)</span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, (f, parses) <span class="kw">in</span> <span class="bu">enumerate</span>(frame_to_constituents.items()):</span>
<span id="cb24-22"><a href="#cb24-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j, parse <span class="kw">in</span> <span class="bu">enumerate</span>(parses):</span>
<span id="cb24-23"><a href="#cb24-23" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> k, const <span class="kw">in</span> <span class="bu">enumerate</span>(parse):</span>
<span id="cb24-24"><a href="#cb24-24" aria-hidden="true" tabindex="-1"></a>            const_idx <span class="op">=</span> where(constituents <span class="op">==</span> const)[<span class="dv">0</span>][<span class="dv">0</span>]</span>
<span id="cb24-25"><a href="#cb24-25" aria-hidden="true" tabindex="-1"></a>            frame_to_parse_constituent_indicators[i,j,const_idx] <span class="op">=</span> <span class="fl">1.</span></span>
<span id="cb24-26"><a href="#cb24-26" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb24-27"><a href="#cb24-27" aria-hidden="true" tabindex="-1"></a>frame_to_parse_constituent_indicators <span class="op">=</span> DataArray(</span>
<span id="cb24-28"><a href="#cb24-28" aria-hidden="true" tabindex="-1"></a>    frame_to_parse_constituent_indicators, </span>
<span id="cb24-29"><a href="#cb24-29" aria-hidden="true" tabindex="-1"></a>    dims<span class="op">=</span>[<span class="st">"frame"</span>, <span class="st">"parse"</span>, <span class="st">"constituent"</span>],</span>
<span id="cb24-30"><a href="#cb24-30" aria-hidden="true" tabindex="-1"></a>    coords<span class="op">=</span>{</span>
<span id="cb24-31"><a href="#cb24-31" aria-hidden="true" tabindex="-1"></a>        <span class="st">"frame"</span>: <span class="bu">list</span>(frame_to_constituents),</span>
<span id="cb24-32"><a href="#cb24-32" aria-hidden="true" tabindex="-1"></a>        <span class="st">"parse"</span>: <span class="bu">list</span>(<span class="bu">range</span>(max_parses)),</span>
<span id="cb24-33"><a href="#cb24-33" aria-hidden="true" tabindex="-1"></a>        <span class="st">"constituent"</span>: constituents,</span>
<span id="cb24-34"><a href="#cb24-34" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb24-35"><a href="#cb24-35" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="complex-type-relationships" class="level4">
<h4 class="anchored" data-anchor-id="complex-type-relationships">Complex type relationships</h4>
<p>We’ll assume that the relationship between semantic and syntactic primitive types determines the relationship between complex semantic and syntactic types. Specifically, we’ll assume that for complex semantic type <span class="math inline">\(\mathbf{t}^\text{sem}\)</span> and complex syntactic type <span class="math inline">\(\mathbf{t}^\text{syn}\)</span>, the probability that these types are related is a product of the probabilities that each of there corresponding primitive types (in order) are related:</p>
<p><span class="math display">\[\psi^\text{synsem}_{\mathbf{t}_\text{sem}\mathbf{t}_\text{syn}} \equiv \prod_i \phi^\text{synsem}_{t_i^\text{sem}t_i^\text{syn}}\]</span></p>
<p>One thing to note about <span class="math inline">\(\boldsymbol\Psi^\text{synsem}\)</span> in particular is that it has <span class="math inline">\(2L\)</span> dimensions, where <span class="math inline">\(L\)</span> is the maximum complexity (i.e.&nbsp;length) of the complex types, which we’ll set to <span class="math inline">\(3\)</span> based on the maximum number of constituents in the frame decompositions above.</p>
<p>Similarly, we’ll assume that the relationship between syntactic primitive types and constituents that can realize them determines the relationship between complex syntactic types and frames. If we knew the correct parse of the frame <span class="math inline">\(p\)</span>, we could look at each constituent type <span class="math inline">\(j\)</span>, and if the parse contains it, we look at the probability that any primitive semantic type in <span class="math inline">\(\mathbf{t}\)</span> can map onto it <span class="math inline">\(1 - \prod_i 1 - c_{fpj}^\text{const}\phi^\text{syn}_{t_i^\text{syn}j}\)</span>; otherwise, we ignore it <span class="math inline">\(1-c_{fpj}\)</span>.</p>
<p><span class="math display">\[\bar{\psi}^\text{syn}_{\mathbf{t}^\text{syn}fp} \equiv \prod_j (1-c_{fpj}) + 1 - \prod_i 1 - c_{fpj}^\text{const}\phi^\text{syn}_{t_i^\text{syn}j}\]</span></p>
<p>But since we also need to consider alternative parses for a particular frame <span class="math inline">\(f\)</span>, we additionally need to take the above expression and embed it in a disjunction over parses:</p>
<p><span class="math display">\[\psi^\text{syn}_{\mathbf{t}^\text{syn}f} \equiv 1 - \prod_p 1 - \bar{\psi}^\text{syn}_{\mathbf{t}^\text{syn}fp}\]</span></p>
<p>Effectively, what we are computing here is the probability that, if we look across parses, there is a constituent that could be mapped onto by at least one of the types.</p>
<p>One potential issue with this particular form is that it doesn’t not enforce a one-to-one relationship between syntactic types and constituents. We do enforce that every constituent must be mapped onto by some primitive syntactic type contained in the complex type–but not that each such primitive syntactic type maps onto a single constituent. This is a potential problem, since we don’t want a single syntactic type to map to no or multiple constituents (assuming we’ve correctly laid out all possible parses). We could do this by adding an extra condition to the expression, but we won’t for now. We’ll return to this problem in Module 4, when we consider mappings from thematic roles to syntactic positions.</p>
</section>
<section id="relationship-between-verbs-frames-and-complex-types" class="level4">
<h4 class="anchored" data-anchor-id="relationship-between-verbs-frames-and-complex-types">Relationship between verbs, frames, and complex types</h4>
<p>Finally, we need some way of representing the relationship between a verb and a complex semantic type and the relationship between a frame and a complex syntactic type. We’ll do this by extending <span class="math inline">\(\boldsymbol\lambda_v\)</span> and <span class="math inline">\(\boldsymbol\pi_f\)</span> from White and Rawlins’ model such that <span class="math inline">\(\lambda_{v\mathbf{t}}\)</span> tracks the probability of verb <span class="math inline">\(v\)</span> having complex semantic type <span class="math inline">\(\mathbf{t}\)</span>, and <span class="math inline">\(\pi_{f\mathbf{t}}\)</span> tracks the probability of frame <span class="math inline">\(f\)</span> having complex syntactic type <span class="math inline">\(\mathbf{t}\)</span>. <span class="math inline">\(\boldsymbol\Lambda\)</span> and <span class="math inline">\(\boldsymbol\Pi\)</span> will thus be represented as <em>tensors</em>, with the first dimension corresponding to verb and frame, respectively, and each subsequent dimension <span class="math inline">\(d\)</span> representing a primitive type <span class="math inline">\(t_d\)</span> in position <span class="math inline">\(d\)</span> of complex type <span class="math inline">\(\mathbf{t}\)</span>.</p>
</section>
<section id="definition-of-acceptability" class="level4">
<h4 class="anchored" data-anchor-id="definition-of-acceptability">Definition of acceptability</h4>
<p>Finally, we define the acceptability of a verb <span class="math inline">\(v\)</span> in a frame <span class="math inline">\(f\)</span> in terms of all of these relationships:</p>
<p><span class="math display">\[\alpha_{vf} \equiv 1 - \prod_{\mathbf{t}_\text{sem},\mathbf{t}_\text{syn}} 1 - \lambda_{v\mathbf{t}_\text{sem}}\phi^\text{synsem}_{\mathbf{t}_\text{sem}\mathbf{t}_\text{syn}}\phi^\text{syn}_{\mathbf{t}_\text{syn}f}\pi_{f\mathbf{t}_\text{syn}}\]</span></p>
</section>
</section>
<section id="implementing-the-unconstrained-model" class="level3">
<h3 class="anchored" data-anchor-id="implementing-the-unconstrained-model">Implementing the unconstrained model</h3>
<p>To implement the unconstrained variant of our structured type models, we need to specify some additional parameters: our single <code>n_components</code> parameter gets replaced with a specification for the number of semantic (<code>n_primitive_semantic_types</code>) and syntactic (<code>n_primitive_syntactic_types</code>) primitive types, the <code>max_complex_type_size</code> (which we already said would be 3), and the <code>frame_to_parse_constituent_indicators</code> we constructed earlier.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb25" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="at">@dataclass</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> StructuredSelectionModelParameters(BaseSelectionModelParameters):</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>    frame_to_parse_constituent_indicators: DataArray</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>    n_primitive_semantic_types: <span class="bu">int</span></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>    n_primitive_syntactic_types: <span class="bu">int</span></span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>    max_complex_type_size: <span class="bu">int</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb26" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> numpy <span class="im">import</span> prod</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch <span class="im">import</span> Tensor</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> StructuredSelectionModel(Module):</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>    parameter_class <span class="op">=</span> StructuredSelectionModelParameters</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>    data_class <span class="op">=</span> SelectionData</span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, parameters: StructuredSelectionModelParameters):</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model_parameters <span class="op">=</span> parameters</span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a>        <span class="co"># initialize the verb-complex semantic type probabilities</span></span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true" tabindex="-1"></a>        verb_shape <span class="op">=</span> (parameters.n_verb,) <span class="op">+</span> <span class="va">self</span>.complex_semantic_type_shape</span>
<span id="cb26-15"><a href="#cb26-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.verb_complex_semantic_type_aux <span class="op">=</span> torch.nn.Parameter(</span>
<span id="cb26-16"><a href="#cb26-16" aria-hidden="true" tabindex="-1"></a>            torch.randn(verb_shape), </span>
<span id="cb26-17"><a href="#cb26-17" aria-hidden="true" tabindex="-1"></a>            requires_grad<span class="op">=</span><span class="va">True</span></span>
<span id="cb26-18"><a href="#cb26-18" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb26-19"><a href="#cb26-19" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb26-20"><a href="#cb26-20" aria-hidden="true" tabindex="-1"></a>        <span class="co"># initialize the frame-complex syntactic type probabilities</span></span>
<span id="cb26-21"><a href="#cb26-21" aria-hidden="true" tabindex="-1"></a>        frame_shape <span class="op">=</span> (parameters.n_frame,) <span class="op">+</span> <span class="va">self</span>.complex_syntactic_type_shape</span>
<span id="cb26-22"><a href="#cb26-22" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.frame_complex_syntactic_type_aux <span class="op">=</span> torch.nn.Parameter(</span>
<span id="cb26-23"><a href="#cb26-23" aria-hidden="true" tabindex="-1"></a>            torch.randn(frame_shape), </span>
<span id="cb26-24"><a href="#cb26-24" aria-hidden="true" tabindex="-1"></a>            requires_grad<span class="op">=</span><span class="va">True</span></span>
<span id="cb26-25"><a href="#cb26-25" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb26-26"><a href="#cb26-26" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb26-27"><a href="#cb26-27" aria-hidden="true" tabindex="-1"></a>        <span class="co"># initialize the semantic-syntactic primitive type map</span></span>
<span id="cb26-28"><a href="#cb26-28" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._initialize_primitive_type_map()</span>
<span id="cb26-29"><a href="#cb26-29" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb26-30"><a href="#cb26-30" aria-hidden="true" tabindex="-1"></a>        <span class="co"># initialize the syntactic primitive type-constituent map</span></span>
<span id="cb26-31"><a href="#cb26-31" aria-hidden="true" tabindex="-1"></a>        syntactic_primitive_type_constituent_map_aux <span class="op">=</span> torch.zeros([</span>
<span id="cb26-32"><a href="#cb26-32" aria-hidden="true" tabindex="-1"></a>             parameters.n_primitive_syntactic_types <span class="op">+</span> <span class="dv">1</span>,</span>
<span id="cb26-33"><a href="#cb26-33" aria-hidden="true" tabindex="-1"></a>             parameters.frame_to_parse_constituent_indicators.shape[<span class="dv">2</span>]</span>
<span id="cb26-34"><a href="#cb26-34" aria-hidden="true" tabindex="-1"></a>        ])</span>
<span id="cb26-35"><a href="#cb26-35" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.syntactic_primitive_type_constituent_map_aux <span class="op">=</span> torch.nn.Parameter(</span>
<span id="cb26-36"><a href="#cb26-36" aria-hidden="true" tabindex="-1"></a>            syntactic_primitive_type_constituent_map_aux, </span>
<span id="cb26-37"><a href="#cb26-37" aria-hidden="true" tabindex="-1"></a>            requires_grad<span class="op">=</span><span class="va">True</span></span>
<span id="cb26-38"><a href="#cb26-38" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb26-39"><a href="#cb26-39" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb26-40"><a href="#cb26-40" aria-hidden="true" tabindex="-1"></a>        <span class="co"># initialize the cutpoint distances</span></span>
<span id="cb26-41"><a href="#cb26-41" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.log_jumps <span class="op">=</span> torch.nn.Parameter(</span>
<span id="cb26-42"><a href="#cb26-42" aria-hidden="true" tabindex="-1"></a>            torch.ones([</span>
<span id="cb26-43"><a href="#cb26-43" aria-hidden="true" tabindex="-1"></a>                parameters.n_subj, parameters.n_resp_levels<span class="op">-</span><span class="dv">1</span></span>
<span id="cb26-44"><a href="#cb26-44" aria-hidden="true" tabindex="-1"></a>            ]), </span>
<span id="cb26-45"><a href="#cb26-45" aria-hidden="true" tabindex="-1"></a>            requires_grad<span class="op">=</span><span class="va">True</span></span>
<span id="cb26-46"><a href="#cb26-46" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb26-47"><a href="#cb26-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-48"><a href="#cb26-48" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _initialize_primitive_type_map(<span class="va">self</span>):</span>
<span id="cb26-49"><a href="#cb26-49" aria-hidden="true" tabindex="-1"></a>        primitive_type_map_aux <span class="op">=</span> torch.zeros([</span>
<span id="cb26-50"><a href="#cb26-50" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.model_parameters.n_primitive_semantic_types <span class="op">+</span> <span class="dv">1</span>, </span>
<span id="cb26-51"><a href="#cb26-51" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.model_parameters.n_primitive_syntactic_types <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb26-52"><a href="#cb26-52" aria-hidden="true" tabindex="-1"></a>        ])</span>
<span id="cb26-53"><a href="#cb26-53" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.primitive_type_map_aux <span class="op">=</span> torch.nn.Parameter(</span>
<span id="cb26-54"><a href="#cb26-54" aria-hidden="true" tabindex="-1"></a>            primitive_type_map_aux, </span>
<span id="cb26-55"><a href="#cb26-55" aria-hidden="true" tabindex="-1"></a>            requires_grad<span class="op">=</span><span class="va">True</span></span>
<span id="cb26-56"><a href="#cb26-56" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb26-57"><a href="#cb26-57" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb26-58"><a href="#cb26-58" aria-hidden="true" tabindex="-1"></a>    <span class="at">@property</span></span>
<span id="cb26-59"><a href="#cb26-59" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> complex_semantic_type_shape(<span class="va">self</span>):</span>
<span id="cb26-60"><a href="#cb26-60" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> (<span class="va">self</span>.model_parameters.n_primitive_semantic_types<span class="op">+</span><span class="dv">1</span>,) <span class="op">*\</span></span>
<span id="cb26-61"><a href="#cb26-61" aria-hidden="true" tabindex="-1"></a>               <span class="va">self</span>.model_parameters.max_complex_type_size</span>
<span id="cb26-62"><a href="#cb26-62" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb26-63"><a href="#cb26-63" aria-hidden="true" tabindex="-1"></a>    <span class="at">@property</span></span>
<span id="cb26-64"><a href="#cb26-64" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> complex_syntactic_type_shape(<span class="va">self</span>):</span>
<span id="cb26-65"><a href="#cb26-65" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> (<span class="va">self</span>.model_parameters.n_primitive_syntactic_types<span class="op">+</span><span class="dv">1</span>,)<span class="op">*\</span></span>
<span id="cb26-66"><a href="#cb26-66" aria-hidden="true" tabindex="-1"></a>               <span class="va">self</span>.model_parameters.max_complex_type_size</span>
<span id="cb26-67"><a href="#cb26-67" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb26-68"><a href="#cb26-68" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, data: SelectionData):</span>
<span id="cb26-69"><a href="#cb26-69" aria-hidden="true" tabindex="-1"></a>        verb_frame_prob <span class="op">=</span> <span class="va">self</span>.verb_frame_prob(data.verb, data.frame)</span>
<span id="cb26-70"><a href="#cb26-70" aria-hidden="true" tabindex="-1"></a>        verb_frame_logodds <span class="op">=</span> torch.log(verb_frame_prob) <span class="op">-</span> torch.log(<span class="fl">1.</span> <span class="op">-</span> verb_frame_prob)</span>
<span id="cb26-71"><a href="#cb26-71" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb26-72"><a href="#cb26-72" aria-hidden="true" tabindex="-1"></a>        jumps <span class="op">=</span> <span class="va">self</span>.jumps[data.subj]</span>
<span id="cb26-73"><a href="#cb26-73" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb26-74"><a href="#cb26-74" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> ordered_logistic_likelihood(</span>
<span id="cb26-75"><a href="#cb26-75" aria-hidden="true" tabindex="-1"></a>            verb_frame_logodds, jumps</span>
<span id="cb26-76"><a href="#cb26-76" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb26-77"><a href="#cb26-77" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb26-78"><a href="#cb26-78" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> verb_frame_prob(<span class="va">self</span>, verb_idx: ndarray, frame_idx: ndarray) <span class="op">-&gt;</span> Tensor:</span>
<span id="cb26-79"><a href="#cb26-79" aria-hidden="true" tabindex="-1"></a>        n_verb <span class="op">=</span> <span class="va">self</span>.model_parameters.n_verb</span>
<span id="cb26-80"><a href="#cb26-80" aria-hidden="true" tabindex="-1"></a>        n_frame <span class="op">=</span> <span class="va">self</span>.model_parameters.n_frame</span>
<span id="cb26-81"><a href="#cb26-81" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb26-82"><a href="#cb26-82" aria-hidden="true" tabindex="-1"></a>        verb_shape <span class="op">=</span> <span class="va">self</span>.complex_semantic_type_shape <span class="op">+\</span></span>
<span id="cb26-83"><a href="#cb26-83" aria-hidden="true" tabindex="-1"></a>                     (<span class="dv">1</span>,) <span class="op">*</span> <span class="bu">len</span>(<span class="va">self</span>.complex_syntactic_type_shape)</span>
<span id="cb26-84"><a href="#cb26-84" aria-hidden="true" tabindex="-1"></a>        frame_shape <span class="op">=</span> (<span class="dv">1</span>,) <span class="op">*</span> <span class="bu">len</span>(<span class="va">self</span>.complex_semantic_type_shape) <span class="op">+\</span></span>
<span id="cb26-85"><a href="#cb26-85" aria-hidden="true" tabindex="-1"></a>                      <span class="va">self</span>.complex_syntactic_type_shape</span>
<span id="cb26-86"><a href="#cb26-86" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb26-87"><a href="#cb26-87" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> verb_idx.shape <span class="op">!=</span> frame_idx.shape:</span>
<span id="cb26-88"><a href="#cb26-88" aria-hidden="true" tabindex="-1"></a>            <span class="cf">raise</span> <span class="pp">ValueError</span></span>
<span id="cb26-89"><a href="#cb26-89" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb26-90"><a href="#cb26-90" aria-hidden="true" tabindex="-1"></a>            resp_shape <span class="op">=</span> verb_idx.shape[<span class="dv">0</span>]</span>
<span id="cb26-91"><a href="#cb26-91" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb26-92"><a href="#cb26-92" aria-hidden="true" tabindex="-1"></a>        <span class="co"># shape for verbs and frames to complex type signatures</span></span>
<span id="cb26-93"><a href="#cb26-93" aria-hidden="true" tabindex="-1"></a>        verb_shape <span class="op">=</span> (resp_shape,) <span class="op">+</span> verb_shape</span>
<span id="cb26-94"><a href="#cb26-94" aria-hidden="true" tabindex="-1"></a>        frame_shape <span class="op">=</span> (resp_shape,) <span class="op">+</span> frame_shape</span>
<span id="cb26-95"><a href="#cb26-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-96"><a href="#cb26-96" aria-hidden="true" tabindex="-1"></a>        <span class="co"># shape with response dimension inserted into map</span></span>
<span id="cb26-97"><a href="#cb26-97" aria-hidden="true" tabindex="-1"></a>        map_shape <span class="op">=</span> (<span class="dv">1</span>,) <span class="op">+</span> <span class="va">self</span>.complex_type_map.shape</span>
<span id="cb26-98"><a href="#cb26-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-99"><a href="#cb26-99" aria-hidden="true" tabindex="-1"></a>        <span class="co"># shape for computing prod on all but the reponse dimension</span></span>
<span id="cb26-100"><a href="#cb26-100" aria-hidden="true" tabindex="-1"></a>        flat_shape <span class="op">=</span> (resp_shape, prod(map_shape))</span>
<span id="cb26-101"><a href="#cb26-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-102"><a href="#cb26-102" aria-hidden="true" tabindex="-1"></a>        p <span class="op">=</span> <span class="va">self</span>.verb_complex_semantic_type[verb_idx].view(verb_shape) <span class="op">*\</span></span>
<span id="cb26-103"><a href="#cb26-103" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.frame_complex_syntactic_type[frame_idx].view(frame_shape) <span class="op">*\</span></span>
<span id="cb26-104"><a href="#cb26-104" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.complex_synsem_type_map.view(map_shape) <span class="op">*\</span></span>
<span id="cb26-105"><a href="#cb26-105" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.complex_syn_type_map(frame_idx).view(map_shape)</span>
<span id="cb26-106"><a href="#cb26-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-107"><a href="#cb26-107" aria-hidden="true" tabindex="-1"></a>        acc <span class="op">=</span> <span class="fl">1.</span> <span class="op">-</span> (<span class="fl">1.</span> <span class="op">-</span> p.view(flat_shape)).prod(axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb26-108"><a href="#cb26-108" aria-hidden="true" tabindex="-1"></a>        acc <span class="op">=</span> acc.clamp(<span class="bu">min</span><span class="op">=</span>ZERO, <span class="bu">max</span><span class="op">=</span>ONE)</span>
<span id="cb26-109"><a href="#cb26-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-110"><a href="#cb26-110" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> acc</span>
<span id="cb26-111"><a href="#cb26-111" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb26-112"><a href="#cb26-112" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb26-113"><a href="#cb26-113" aria-hidden="true" tabindex="-1"></a>    <span class="at">@property</span></span>
<span id="cb26-114"><a href="#cb26-114" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> verb_complex_semantic_type(<span class="va">self</span>) <span class="op">-&gt;</span> Tensor:</span>
<span id="cb26-115"><a href="#cb26-115" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.sigmoid(<span class="va">self</span>.verb_complex_semantic_type_aux)</span>
<span id="cb26-116"><a href="#cb26-116" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb26-117"><a href="#cb26-117" aria-hidden="true" tabindex="-1"></a>    <span class="at">@property</span></span>
<span id="cb26-118"><a href="#cb26-118" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> frame_complex_syntactic_type(<span class="va">self</span>) <span class="op">-&gt;</span> Tensor:</span>
<span id="cb26-119"><a href="#cb26-119" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.sigmoid(<span class="va">self</span>.frame_complex_syntactic_type_aux)</span>
<span id="cb26-120"><a href="#cb26-120" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb26-121"><a href="#cb26-121" aria-hidden="true" tabindex="-1"></a>    <span class="at">@property</span></span>
<span id="cb26-122"><a href="#cb26-122" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> primitive_type_map(<span class="va">self</span>) <span class="op">-&gt;</span> Tensor:</span>
<span id="cb26-123"><a href="#cb26-123" aria-hidden="true" tabindex="-1"></a>        prob <span class="op">=</span> torch.sigmoid(<span class="va">self</span>.primitive_type_map_aux)</span>
<span id="cb26-124"><a href="#cb26-124" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb26-125"><a href="#cb26-125" aria-hidden="true" tabindex="-1"></a>        <span class="co"># the 0th primitive type is the null primitive type and null </span></span>
<span id="cb26-126"><a href="#cb26-126" aria-hidden="true" tabindex="-1"></a>        <span class="co"># primitive types should only map onto each other, we do this</span></span>
<span id="cb26-127"><a href="#cb26-127" aria-hidden="true" tabindex="-1"></a>        <span class="co"># by multiplying by a special mask</span></span>
<span id="cb26-128"><a href="#cb26-128" aria-hidden="true" tabindex="-1"></a>        mask <span class="op">=</span> torch.ones_like(prob)</span>
<span id="cb26-129"><a href="#cb26-129" aria-hidden="true" tabindex="-1"></a>        mask[<span class="dv">0</span>,<span class="dv">0</span>] <span class="op">=</span> <span class="dv">1</span><span class="op">/</span>prob[<span class="dv">0</span>,<span class="dv">0</span>]</span>
<span id="cb26-130"><a href="#cb26-130" aria-hidden="true" tabindex="-1"></a>        mask[<span class="dv">0</span>,<span class="dv">1</span>:] <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb26-131"><a href="#cb26-131" aria-hidden="true" tabindex="-1"></a>        mask[<span class="dv">1</span>:,<span class="dv">0</span>] <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb26-132"><a href="#cb26-132" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb26-133"><a href="#cb26-133" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> mask <span class="op">*</span> prob</span>
<span id="cb26-134"><a href="#cb26-134" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb26-135"><a href="#cb26-135" aria-hidden="true" tabindex="-1"></a>    <span class="at">@property</span></span>
<span id="cb26-136"><a href="#cb26-136" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> complex_synsem_type_map(<span class="va">self</span>):</span>
<span id="cb26-137"><a href="#cb26-137" aria-hidden="true" tabindex="-1"></a>        <span class="co"># only want to compute the transformation implicit in the</span></span>
<span id="cb26-138"><a href="#cb26-138" aria-hidden="true" tabindex="-1"></a>        <span class="co"># property once</span></span>
<span id="cb26-139"><a href="#cb26-139" aria-hidden="true" tabindex="-1"></a>        primitive_type_map <span class="op">=</span> <span class="va">self</span>.primitive_type_map</span>
<span id="cb26-140"><a href="#cb26-140" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb26-141"><a href="#cb26-141" aria-hidden="true" tabindex="-1"></a>        <span class="co"># the final shape of the complex type map</span></span>
<span id="cb26-142"><a href="#cb26-142" aria-hidden="true" tabindex="-1"></a>        final_shape <span class="op">=</span> primitive_type_map.shape <span class="op">*\</span></span>
<span id="cb26-143"><a href="#cb26-143" aria-hidden="true" tabindex="-1"></a>                      <span class="va">self</span>.model_parameters.max_complex_type_size</span>
<span id="cb26-144"><a href="#cb26-144" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb26-145"><a href="#cb26-145" aria-hidden="true" tabindex="-1"></a>        shape <span class="op">=</span> (primitive_type_map.shape[<span class="dv">0</span>],) <span class="op">+\</span></span>
<span id="cb26-146"><a href="#cb26-146" aria-hidden="true" tabindex="-1"></a>                (<span class="dv">1</span>,) <span class="op">*</span> (<span class="va">self</span>.model_parameters.max_complex_type_size <span class="op">-</span> <span class="dv">1</span>) <span class="op">+\</span></span>
<span id="cb26-147"><a href="#cb26-147" aria-hidden="true" tabindex="-1"></a>                (primitive_type_map.shape[<span class="dv">1</span>],) <span class="op">+\</span></span>
<span id="cb26-148"><a href="#cb26-148" aria-hidden="true" tabindex="-1"></a>                (<span class="dv">1</span>,) <span class="op">*</span> (<span class="va">self</span>.model_parameters.max_complex_type_size <span class="op">-</span> <span class="dv">1</span>)</span>
<span id="cb26-149"><a href="#cb26-149" aria-hidden="true" tabindex="-1"></a>        m <span class="op">=</span> primitive_type_map.view(shape)</span>
<span id="cb26-150"><a href="#cb26-150" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb26-151"><a href="#cb26-151" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="va">self</span>.model_parameters.max_complex_type_size):</span>
<span id="cb26-152"><a href="#cb26-152" aria-hidden="true" tabindex="-1"></a>            shape <span class="op">=</span> (<span class="dv">1</span>,) <span class="op">*</span> i <span class="op">+\</span></span>
<span id="cb26-153"><a href="#cb26-153" aria-hidden="true" tabindex="-1"></a>                    (primitive_type_map.shape[<span class="dv">0</span>],) <span class="op">+\</span></span>
<span id="cb26-154"><a href="#cb26-154" aria-hidden="true" tabindex="-1"></a>                    (<span class="dv">1</span>,) <span class="op">*</span> (<span class="va">self</span>.model_parameters.max_complex_type_size <span class="op">-</span> (i <span class="op">+</span> <span class="dv">1</span>)) <span class="op">+\</span></span>
<span id="cb26-155"><a href="#cb26-155" aria-hidden="true" tabindex="-1"></a>                    (<span class="dv">1</span>,) <span class="op">*</span> i <span class="op">+\</span></span>
<span id="cb26-156"><a href="#cb26-156" aria-hidden="true" tabindex="-1"></a>                    (primitive_type_map.shape[<span class="dv">1</span>],) <span class="op">+\</span></span>
<span id="cb26-157"><a href="#cb26-157" aria-hidden="true" tabindex="-1"></a>                    (<span class="dv">1</span>,) <span class="op">*</span> (<span class="va">self</span>.model_parameters.max_complex_type_size <span class="op">-</span> (i <span class="op">+</span> <span class="dv">1</span>))</span>
<span id="cb26-158"><a href="#cb26-158" aria-hidden="true" tabindex="-1"></a>            m <span class="op">=</span> m <span class="op">*</span> primitive_type_map.view(shape)</span>
<span id="cb26-159"><a href="#cb26-159" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb26-160"><a href="#cb26-160" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> m</span>
<span id="cb26-161"><a href="#cb26-161" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb26-162"><a href="#cb26-162" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> complex_syn_type_map(<span class="va">self</span>, frame_idx: ndarray):</span>
<span id="cb26-163"><a href="#cb26-163" aria-hidden="true" tabindex="-1"></a>        parse_constituent_indicators <span class="op">=</span> <span class="va">self</span>.model_parameters.frame_to_parse_constituent_indicators[frame_idx]</span>
<span id="cb26-164"><a href="#cb26-164" aria-hidden="true" tabindex="-1"></a>        primitive_type_map <span class="op">=</span> <span class="va">self</span>.syntactic_primitive_type_constituent_map</span>
<span id="cb26-165"><a href="#cb26-165" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb26-166"><a href="#cb26-166" aria-hidden="true" tabindex="-1"></a>        final_shape <span class="op">=</span> frame_idx.shape <span class="op">+\</span></span>
<span id="cb26-167"><a href="#cb26-167" aria-hidden="true" tabindex="-1"></a>                      (<span class="va">self</span>.model_parameters.n_primitive_syntactic_types,) <span class="op">*\</span></span>
<span id="cb26-168"><a href="#cb26-168" aria-hidden="true" tabindex="-1"></a>                      <span class="va">self</span>.model_parameters.max_complex_type_size</span>
<span id="cb26-169"><a href="#cb26-169" aria-hidden="true" tabindex="-1"></a>        m <span class="op">=</span> torch.zeros(final_shape)</span>
<span id="cb26-170"><a href="#cb26-170" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb26-171"><a href="#cb26-171" aria-hidden="true" tabindex="-1"></a>        <span class="co"># frame x primitive type x parse x constituent type  </span></span>
<span id="cb26-172"><a href="#cb26-172" aria-hidden="true" tabindex="-1"></a>        map_shape <span class="op">=</span> (<span class="dv">1</span>,) <span class="op">+</span> primitive_type_map.shape[:<span class="dv">1</span>] <span class="op">+</span> (<span class="dv">1</span>,) <span class="op">+</span> primitive_type_map.shape[<span class="dv">1</span>:]</span>
<span id="cb26-173"><a href="#cb26-173" aria-hidden="true" tabindex="-1"></a>        indicators_shape <span class="op">=</span> indicators_shape.shape[:<span class="dv">1</span>] <span class="op">+</span> (<span class="dv">1</span>,) <span class="op">+</span> indicators_shape.shape[<span class="dv">1</span>:]</span>
<span id="cb26-174"><a href="#cb26-174" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb26-175"><a href="#cb26-175" aria-hidden="true" tabindex="-1"></a>        prob <span class="op">=</span> <span class="fl">1.</span> <span class="op">-</span> torch.prod(</span>
<span id="cb26-176"><a href="#cb26-176" aria-hidden="true" tabindex="-1"></a>            <span class="fl">1.</span> <span class="op">-</span> torch.prod(</span>
<span id="cb26-177"><a href="#cb26-177" aria-hidden="true" tabindex="-1"></a>                (<span class="fl">1.</span><span class="op">-</span>parse_constituent_indicators.view(indicators_shape)) <span class="op">+</span> </span>
<span id="cb26-178"><a href="#cb26-178" aria-hidden="true" tabindex="-1"></a>                <span class="fl">1.</span> <span class="op">-</span> torch.prod(</span>
<span id="cb26-179"><a href="#cb26-179" aria-hidden="true" tabindex="-1"></a>                    <span class="fl">1.</span> <span class="op">-</span> </span>
<span id="cb26-180"><a href="#cb26-180" aria-hidden="true" tabindex="-1"></a>                    primitive_type_map.view(map_shape) <span class="op">*</span> </span>
<span id="cb26-181"><a href="#cb26-181" aria-hidden="true" tabindex="-1"></a>                    parse_constituent_indicators.view(indicators_shape), </span>
<span id="cb26-182"><a href="#cb26-182" aria-hidden="true" tabindex="-1"></a>                    axis<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb26-183"><a href="#cb26-183" aria-hidden="true" tabindex="-1"></a>                axis<span class="op">=</span><span class="dv">2</span></span>
<span id="cb26-184"><a href="#cb26-184" aria-hidden="true" tabindex="-1"></a>            ), axis<span class="op">=</span><span class="dv">2</span></span>
<span id="cb26-185"><a href="#cb26-185" aria-hidden="true" tabindex="-1"></a>        ).view(final_shape)</span>
<span id="cb26-186"><a href="#cb26-186" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb26-187"><a href="#cb26-187" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> m <span class="op">+</span> prob</span>
<span id="cb26-188"><a href="#cb26-188" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb26-189"><a href="#cb26-189" aria-hidden="true" tabindex="-1"></a>    <span class="at">@property</span></span>
<span id="cb26-190"><a href="#cb26-190" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> syntactic_primitive_type_constituent_map(<span class="va">self</span>):</span>
<span id="cb26-191"><a href="#cb26-191" aria-hidden="true" tabindex="-1"></a>        prob <span class="op">=</span> torch.sigmoid(</span>
<span id="cb26-192"><a href="#cb26-192" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.syntactic_primitive_type_constituent_map_aux</span>
<span id="cb26-193"><a href="#cb26-193" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb26-194"><a href="#cb26-194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-195"><a href="#cb26-195" aria-hidden="true" tabindex="-1"></a>        <span class="co"># the 0th primitive type is the null primitive type and null </span></span>
<span id="cb26-196"><a href="#cb26-196" aria-hidden="true" tabindex="-1"></a>        <span class="co"># primitive types should not map onto any constitutent, we do </span></span>
<span id="cb26-197"><a href="#cb26-197" aria-hidden="true" tabindex="-1"></a>        <span class="co"># this by multiplying by a special mask</span></span>
<span id="cb26-198"><a href="#cb26-198" aria-hidden="true" tabindex="-1"></a>        mask <span class="op">=</span> torch.ones_like(prob)</span>
<span id="cb26-199"><a href="#cb26-199" aria-hidden="true" tabindex="-1"></a>        mask[<span class="dv">0</span>,:] <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb26-200"><a href="#cb26-200" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb26-201"><a href="#cb26-201" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> mask <span class="op">*</span> prob</span>
<span id="cb26-202"><a href="#cb26-202" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb26-203"><a href="#cb26-203" aria-hidden="true" tabindex="-1"></a>    <span class="at">@property</span></span>
<span id="cb26-204"><a href="#cb26-204" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> jumps(<span class="va">self</span>):</span>
<span id="cb26-205"><a href="#cb26-205" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.exp(<span class="va">self</span>.log_jumps)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="implementing-the-constrained-model" class="level3">
<h3 class="anchored" data-anchor-id="implementing-the-constrained-model">Implementing the constrained model</h3>
<p>To implement the constrained variant of the above model, we simply need to alter how the mapping from primitive semantic types to primitive semantic types operates.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb27" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ConstrainedStructuredSelectionModel(StructuredSelectionModel):</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _initialize_primitive_type_map(<span class="va">self</span>):</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>        primitive_type_rank_sem_aux <span class="op">=</span> torch.zeros([</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.model_parameters.n_primitive_semantic_types</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>        ])</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.primitive_type_rank_sem_aux <span class="op">=</span> torch.nn.Parameter(</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>            primitive_type_rank_sem_aux, </span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>            requires_grad<span class="op">=</span><span class="va">True</span></span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a>        primitive_type_rank_syn_aux <span class="op">=</span> torch.zeros([</span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.model_parameters.n_primitive_syntactic_types</span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a>        ])</span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.primitive_type_rank_syn_aux <span class="op">=</span> torch.nn.Parameter(</span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a>            primitive_type_rank_syn_aux, </span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a>            requires_grad<span class="op">=</span><span class="va">True</span></span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.type_rank_log_jumps <span class="op">=</span> torch.nn.Parameter(</span>
<span id="cb27-21"><a href="#cb27-21" aria-hidden="true" tabindex="-1"></a>            primitive_type_rank_syn_aux, </span>
<span id="cb27-22"><a href="#cb27-22" aria-hidden="true" tabindex="-1"></a>            requires_grad<span class="op">=</span><span class="va">True</span></span>
<span id="cb27-23"><a href="#cb27-23" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb27-24"><a href="#cb27-24" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb27-25"><a href="#cb27-25" aria-hidden="true" tabindex="-1"></a>    <span class="at">@property</span></span>
<span id="cb27-26"><a href="#cb27-26" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> primitive_type_map(<span class="va">self</span>) <span class="op">-&gt;</span> Tensor:</span>
<span id="cb27-27"><a href="#cb27-27" aria-hidden="true" tabindex="-1"></a>        rank_jumps <span class="op">=</span> torch.exp(<span class="va">self</span>.type_rank_log_jumps)</span>
<span id="cb27-28"><a href="#cb27-28" aria-hidden="true" tabindex="-1"></a>        rank_cuts <span class="op">=</span> torch.cumsum(rank_jumps, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb27-29"><a href="#cb27-29" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb27-30"><a href="#cb27-30" aria-hidden="true" tabindex="-1"></a>        prob_sem <span class="op">=</span> ordered_logistic(</span>
<span id="cb27-31"><a href="#cb27-31" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.primitive_type_rank_sem_aux[<span class="va">None</span>,:], </span>
<span id="cb27-32"><a href="#cb27-32" aria-hidden="true" tabindex="-1"></a>            rank_cuts[<span class="va">None</span>,:]</span>
<span id="cb27-33"><a href="#cb27-33" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb27-34"><a href="#cb27-34" aria-hidden="true" tabindex="-1"></a>        prob_syn <span class="op">=</span> ordered_logistic(</span>
<span id="cb27-35"><a href="#cb27-35" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.primitive_type_rank_syn_aux[<span class="va">None</span>,:], </span>
<span id="cb27-36"><a href="#cb27-36" aria-hidden="true" tabindex="-1"></a>            rank_cuts[<span class="va">None</span>,:]</span>
<span id="cb27-37"><a href="#cb27-37" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb27-38"><a href="#cb27-38" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb27-39"><a href="#cb27-39" aria-hidden="true" tabindex="-1"></a>        prob_prim <span class="op">=</span> prob_syn.transpose(<span class="dv">1</span>, <span class="dv">0</span>) <span class="op">*</span> prob_sem</span>
<span id="cb27-40"><a href="#cb27-40" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb27-41"><a href="#cb27-41" aria-hidden="true" tabindex="-1"></a>        <span class="co"># the 0th primitive type is the null primitive type and null </span></span>
<span id="cb27-42"><a href="#cb27-42" aria-hidden="true" tabindex="-1"></a>        <span class="co"># primitive types should only map onto each other, we do this</span></span>
<span id="cb27-43"><a href="#cb27-43" aria-hidden="true" tabindex="-1"></a>        <span class="co"># by multiplying by a special mask</span></span>
<span id="cb27-44"><a href="#cb27-44" aria-hidden="true" tabindex="-1"></a>        prob <span class="op">=</span> torch.zeros((prob_prim.shape[<span class="dv">0</span>] <span class="op">+</span> <span class="dv">1</span>, prob_prim.shape[<span class="dv">1</span>] <span class="op">+</span> <span class="dv">1</span>))</span>
<span id="cb27-45"><a href="#cb27-45" aria-hidden="true" tabindex="-1"></a>        prob[<span class="dv">0</span>,<span class="dv">0</span>] <span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb27-46"><a href="#cb27-46" aria-hidden="true" tabindex="-1"></a>        prob[<span class="dv">1</span>:,<span class="dv">1</span>:] <span class="op">=</span> prob_prim</span>
<span id="cb27-47"><a href="#cb27-47" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb27-48"><a href="#cb27-48" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> prob</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="summing-up" class="level2">
<h2 class="anchored" data-anchor-id="summing-up">Summing up</h2>
<p>We started with a relatively straightforward variant of matrix factorization as our model for inducing selection and augmented that out to a model that recognizes structured semantic and syntactic types. In the next section, we’ll fit these models and probe the representations they learn.</p>



</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" role="list">
<div id="ref-cristofaro_subordination_2005" class="csl-entry" role="listitem">
Cristofaro, Sonia, and Sonia Cristofaro. 2005. <em>Subordination</em>. Oxford <span>Studies</span> in <span>Typology</span> and <span>Linguistic</span> <span>Theory</span>. Oxford, New York: Oxford University Press.
</div>
<div id="ref-dixon_basic_2009" class="csl-entry" role="listitem">
Dixon, R. M. W. 2009. <em>Basic <span>Linguistic</span> <span>Theory</span> <span>Volume</span> 2: <span>Grammatical</span> <span>Topics</span></em>. Oxford, New York: Oxford University Press.
</div>
<div id="ref-givon_binding_1980" class="csl-entry" role="listitem">
Givón, T. 1980. <span>“The <span>Binding</span> <span>Hierarchy</span> and the <span>Typology</span> of <span>Complements</span>:”</span> <em>Studies in Language</em> 4 (3): 333–77. <a href="https://doi.org/10.1075/sl.4.3.03giv">https://doi.org/10.1075/sl.4.3.03giv</a>.
</div>
<div id="ref-grimshaw_complement_1979" class="csl-entry" role="listitem">
Grimshaw, Jane. 1979. <span>“Complement Selection and the Lexicon.”</span> <em>Linguistic Inquiry</em> 10 (2): 279–326.
</div>
<div id="ref-lohninger_typology_2020" class="csl-entry" role="listitem">
Lohninger, Magdalena, and Susanne Wurmbrand. to appear. <span>“Typology of Complement Clauses.”</span> Edited by Anton Benz, Werner Frey, Manfred Krifka, Thomas McFadden, and Marzena Żygis. <em>Handbook of Clausal Embedding</em>, to appear, 1–53.
</div>
<div id="ref-miettinen_recent_2020" class="csl-entry" role="listitem">
Miettinen, Pauli, and Stefan Neumann. 2020. <span>“Recent Developments in Boolean Matrix Factorization.”</span> <a href="https://arxiv.org/abs/2012.03127">https://arxiv.org/abs/2012.03127</a>.
</div>
<div id="ref-montague_proper_1973" class="csl-entry" role="listitem">
Montague, Richard. 1973. <span>“The Proper Treatment of Quantification in Ordinary <span>English</span>.”</span> In <em>Approaches to <span>Natural</span> <span>Language</span></em>, 221–42. Springer.
</div>
<div id="ref-noonan_complementation_2007" class="csl-entry" role="listitem">
Noonan, Michael. 2007. <span>“Complementation.”</span> In <em>Language Typology and Syntactic Description: <span>Volume</span> 2, <span>Complex</span> Constructions</em>, edited by Timothy Shopen, 2nd ed., 52–150. Cambridge: Cambridge University Press.
</div>
<div id="ref-paatero_positive_1994" class="csl-entry" role="listitem">
Paatero, Pentti, and Unto Tapper. 1994. <span>“Positive Matrix Factorization: <span>A</span> Non-Negative Factor Model with Optimal Utilization of Error Estimates of Data Values.”</span> <em>Environmetrics</em> 5 (2): 111–26. <a href="https://doi.org/10.1002/env.3170050203">https://doi.org/10.1002/env.3170050203</a>.
</div>
<div id="ref-pearson_lines_1901" class="csl-entry" role="listitem">
Pearson, Karl. 1901. <span>“On Lines and Planes of Closest Fit to Systems of Points in Space.”</span> <em>The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science</em> 2 (11): 559–72. <a href="https://doi.org/10.1080/14786440109462720">https://doi.org/10.1080/14786440109462720</a>.
</div>
<div id="ref-pesetsky_zero_1991" class="csl-entry" role="listitem">
Pesetsky, David. 1991. <span>“Zero Syntax: Vol. 2: <span>Infinitives</span>.”</span>
</div>
<div id="ref-ramchand_deriving_2014" class="csl-entry" role="listitem">
Ramchand, Gillian, and Peter Svenonius. 2014. <span>“Deriving the Functional Hierarchy.”</span> <em>Language Sciences</em>, New <span>Directions</span> in <span>Universal</span> <span>Grammar</span>, 46 (November): 152–74. <a href="https://doi.org/10.1016/j.langsci.2014.06.013">https://doi.org/10.1016/j.langsci.2014.06.013</a>.
</div>
<div id="ref-steedman_combinatory_2011" class="csl-entry" role="listitem">
Steedman, Mark, and Jason Baldridge. 2011. <span>“Combinatory <span>Categorial</span> <span>Grammar</span>.”</span> In <em>Non-<span>Transformational</span> <span>Syntax</span></em>, 181–224. John Wiley &amp; Sons, Ltd. <a href="https://doi.org/10.1002/9781444395037.ch5">https://doi.org/10.1002/9781444395037.ch5</a>.
</div>
<div id="ref-teh_stick-breaking_2007" class="csl-entry" role="listitem">
Teh, Yee Whye, Dilan Grür, and Zoubin Ghahramani. 2007. <span>“Stick-Breaking Construction for the Indian Buffet Process.”</span> In <em>Proceedings of the Eleventh International Conference on Artificial Intelligence and Statistics</em>, edited by Marina Meila and Xiaotong Shen, 2:556–63. Proceedings of Machine Learning Research. San Juan, Puerto Rico: PMLR. <a href="https://proceedings.mlr.press/v2/teh07a.html">https://proceedings.mlr.press/v2/teh07a.html</a>.
</div>
<div id="ref-white_computational_2016" class="csl-entry" role="listitem">
White, Aaron Steven, and Kyle Rawlins. 2016. <span>“A Computational Model of <span>S</span>-Selection.”</span> Edited by Mary Moroney, Carol-Rose Little, Jacob Collard, and Dan Burgdorf. <em>Semantics and Linguistic Theory</em> 26 (October): 641–63. <a href="https://doi.org/10.3765/salt.v26i0.3819">https://doi.org/10.3765/salt.v26i0.3819</a>.
</div>
<div id="ref-white_frequency_2020" class="csl-entry" role="listitem">
———. 2020. <span>“Frequency, Acceptability, and Selection: <span>A</span> Case Study of Clause-Embedding.”</span> <em>Glossa: A Journal of General Linguistics</em> 5 (1): 105. <a href="https://doi.org/10.5334/gjgl.1001">https://doi.org/10.5334/gjgl.1001</a>.
</div>
<div id="ref-wurmbrand_implicational_2023" class="csl-entry" role="listitem">
Wurmbrand, Susanne, and Magdalena Lohninger. 2023. <span>“An Implicational Universal in Complementation–Theogrohretical Insights and Empirical Progress.”</span> In <em>Propositional <span>Arguments</span> in <span>Cross</span>-<span>Linguistic</span> <span>Research</span>: <span>Theoretical</span> and <span>Empirical</span> <span>Issues</span></em>, edited by Hartmann, Jutta M. and Wöllstein, Angelika, 84:183–231. Studien Zur Deutschen <span>Sprache</span>. Tübingen: Gunter Narr Verlag.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>In fact, not all predicates found in their sentences are necessarily verbs. Some–e.g.&nbsp;<em>annoy</em>–are likely to be (deverbal) adjectives in some frames. We’ll continue to just refer to these predicates as verbs.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>In fact, when <span class="math inline">\(\mathbf{U}\)</span> and <span class="math inline">\(\mathbf{V}\)</span> are boolean matrices and we do this swap, the problem is often referred to as boolean matrix factorization <span class="citation" data-cites="miettinen_recent_2020">(see <a href="#ref-miettinen_recent_2020" role="doc-biblioref">Miettinen and Neumann 2020</a> and references therein)</span>.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>As <span class="citation" data-cites="teh_stick-breaking_2007">Teh, Grür, and Ghahramani (<a href="#ref-teh_stick-breaking_2007" role="doc-biblioref">2007</a>)</span> note, this process is very closely related to the stick-breaking process associated with the <a href="https://en.wikipedia.org/wiki/Dirichlet_process#The_stick-breaking_process">Dirichlet process</a>, which is commonly used in the context of infinite mixture models. See, for instance, the <a href="https://scikit-learn.org/stable/modules/generated/sklearn.mixture.BayesianGaussianMixture.html"><code>BayesianGaussianMixture</code></a> class from <a href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.mixture"><code>sklearn.mixture</code></a>.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>STAN does use <a href="https://mc-stan.org/docs/reference-manual/stochastic-gradient-ascent.html">stochastic gradient ascent</a> in its implementation of automatic differentiation <a href="https://en.wikipedia.org/wiki/Variational_Bayesian_methods">variational inference</a> (ADVI). But since I want to demonstrate MAP estimation and how to implement it in the popular <code>torch</code> framework here, I’m not going to use STAN’s implementation of variational inference.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>There are other ways to set things up in <code>torch</code>, but this general approach is relatively common.<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>We could alternatively learn a positive scaling term <span class="math inline">\(\beta\)</span> for <span class="math inline">\(\alpha_{vf}\)</span> that would expand it to be on <span class="math inline">\([0, \beta]\)</span>, but then we introduce an additional parameter that we need to worry about futzing with.<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://giscus.app/client.js" data-repo="aaronstevenwhite/representation-learning-course" data-repo-id="R_kgDOJsrvfQ" data-category="General" data-category-id="DIC_kwDOJsrvfc4CXIDs" data-mapping="title" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="top" data-theme="light" data-lang="en" crossorigin="anonymous" async="">
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../selection/a-brief-primer-on-gradient-based-optimization.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">A brief primer on gradient-based optimization</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../selection/model-fitting-and-comparison.html" class="pagination-link">
        <span class="nav-page-text">Model fitting and comparison</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



<script src="../site_libs/quarto-contrib/line-highlight-1.0.0/line-highlight.js" defer="true"></script>
</body></html>