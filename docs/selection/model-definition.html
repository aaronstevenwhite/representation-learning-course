<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.321">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Representation Learning for Syntactic and Semantic Theory - Model definition</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../selection/model-fitting-and-comparison.html" rel="next">
<link href="../selection/a-brief-primer-on-gradient-based-optimization.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/quarto-contrib/line-highlight-1.0.0/line-highlight.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../selection/index.html">Module 3: Selection</a></li><li class="breadcrumb-item"><a href="../selection/model-definition.html">Model definition</a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Representation Learning for Syntactic and Semantic Theory</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">About</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../installation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Installation</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../motivations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Motivations</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../methodological-approach.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Methodological Approach</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../course-structure-and-content.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Course Structure and Content</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Foundational Concepts in Probability and Statistics</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../foundational-concepts-in-probability-and-statistics/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">What is a probability?</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../foundational-concepts-in-probability-and-statistics/random-variables-and-probability-distributions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Random variables and probability distributions</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../foundational-concepts-in-probability-and-statistics/statistical-inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Statistical Inference</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
 <span class="menu-text">Module 1: Island Effects</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../island-effects/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../island-effects/model-definition.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Model definition</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../island-effects/model-fitting-and-comparison.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Model Fitting and Comparison</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
 <span class="menu-text">Module 2: Projective Content</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../projective-content/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../projective-content/inferentially-defined-classes-of-predicates.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Inferentially defined classes of predicates</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../projective-content/model-definition.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Model definition</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../projective-content/model-fitting-and-comparison.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Model fitting and comparison</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
 <span class="menu-text">Module 3: Selection</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../selection/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../selection/a-brief-primer-on-gradient-based-optimization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">A brief primer on gradient-based optimization</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../selection/model-definition.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Model definition</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../selection/model-fitting-and-comparison.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Model fitting and comparison</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">
 <span class="menu-text">Module 4: Thematic Roles</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../thematic-roles/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Module 4: Thematic Roles</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../thematic-roles/learning-distributional-representations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Distributional representations from language models</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../thematic-roles/model-definition.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Model definition</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../thematic-roles/model-fitting-and-comparison.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Model fitting and comparison</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#the-megaacceptability-dataset" id="toc-the-megaacceptability-dataset" class="nav-link active" data-scroll-target="#the-megaacceptability-dataset">The MegaAcceptability dataset</a></li>
  <li><a href="#inducing-semantic-types-by-matrix-factorization" id="toc-inducing-semantic-types-by-matrix-factorization" class="nav-link" data-scroll-target="#inducing-semantic-types-by-matrix-factorization">Inducing semantic types by matrix factorization</a>
  <ul class="collapse">
  <li><a href="#matrix-factorization" id="toc-matrix-factorization" class="nav-link" data-scroll-target="#matrix-factorization">Matrix factorization</a></li>
  <li><a href="#linking-model" id="toc-linking-model" class="nav-link" data-scroll-target="#linking-model">Linking model</a></li>
  <li><a href="#implementation-in-stan" id="toc-implementation-in-stan" class="nav-link" data-scroll-target="#implementation-in-stan">Implementation in STAN</a></li>
  <li><a href="#implementation-in-pytorch" id="toc-implementation-in-pytorch" class="nav-link" data-scroll-target="#implementation-in-pytorch">Implementation in PyTorch</a></li>
  </ul></li>
  <li><a href="#complex-syntactic-and-semantic-types" id="toc-complex-syntactic-and-semantic-types" class="nav-link" data-scroll-target="#complex-syntactic-and-semantic-types">Complex syntactic and semantic types</a>
  <ul class="collapse">
  <li><a href="#relationships-among-representations" id="toc-relationships-among-representations" class="nav-link" data-scroll-target="#relationships-among-representations">Relationships among representations</a></li>
  <li><a href="#implementing-the-unconstrained-model" id="toc-implementing-the-unconstrained-model" class="nav-link" data-scroll-target="#implementing-the-unconstrained-model">Implementing the unconstrained model</a></li>
  <li><a href="#implementing-the-constrained-model" id="toc-implementing-the-constrained-model" class="nav-link" data-scroll-target="#implementing-the-constrained-model">Implementing the constrained model</a></li>
  </ul></li>
  <li><a href="#evaluating-the-models" id="toc-evaluating-the-models" class="nav-link" data-scroll-target="#evaluating-the-models">Evaluating the models</a></li>
  <li><a href="#summing-up" id="toc-summing-up" class="nav-link" data-scroll-target="#summing-up">Summing up</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Model definition</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p><span class="citation" data-cites="lohninger_typology_2020">Lohninger and Wurmbrand (<a href="#ref-lohninger_typology_2020" role="doc-biblioref">to appear</a>)</span> review evidence from a variety of both “functional-typological and structural-grammatical approaches to complementation” <span class="citation" data-cites="givon_binding_1980 cristofaro_subordination_2005 noonan_complementation_2007 dixon_basic_2009 wurmbrand_implicational_2023">(<a href="#ref-givon_binding_1980" role="doc-biblioref">Givón 1980</a>; <a href="#ref-cristofaro_subordination_2005" role="doc-biblioref">Cristofaro and Cristofaro 2005</a>; <a href="#ref-noonan_complementation_2007" role="doc-biblioref">Noonan 2007</a>; <a href="#ref-dixon_basic_2009" role="doc-biblioref">Dixon 2009</a>; <a href="#ref-wurmbrand_implicational_2023" role="doc-biblioref">Wurmbrand and Lohninger 2023</a>)</span> that “…there is a possibly universal implicational complementation hierarchy which is defined semantically and detectable through a diverse set of grammatical properties” and that “[w]hile the distribution of morphosyntactic properties varies significantly across languages, the semantic grouping of complement types shows a (more) stable distribution” (<em>ibid</em>, p.&nbsp;33). The argue specifically that, while “different classification systems arise” in different works “[d]epending on the scope, focus and terminology of an approach”, “a common property found in all approaches, in one form or another, is that complementation configurations are ranked along some kind of hierarchy” (<em>ibid</em>, p.&nbsp;2).</p>
<p>In this module, we’ll consider how we might develop a model that encodes this notion of hierarchy as a means of testing this idea at the scale of an entire lexicon. We of course won’t be able to assess the idea cross-linguistically; but since all of these approaches make predictions of hierarchy language-internally, we will be able to probe it’s ability to cover English.</p>
<section id="the-megaacceptability-dataset" class="level2">
<h2 class="anchored" data-anchor-id="the-megaacceptability-dataset">The MegaAcceptability dataset</h2>
<p>We’ll use the <a href="http://megaattitude.io/projects/mega-acceptability/">MegaAcceptability dataset</a>–collected by <span class="citation" data-cites="white_computational_2016">White and Rawlins (<a href="#ref-white_computational_2016" role="doc-biblioref">2016</a>)</span> and reported on in detail by <span class="citation" data-cites="white_frequency_2020">White and Rawlins (<a href="#ref-white_frequency_2020" role="doc-biblioref">2020</a>)</span>.</p>
<div class="cell" data-tags="[]" data-execution_count="1">
<details>
<summary>Download the data</summary>
<div class="sourceCode cell-code" id="cb1" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>wget http:<span class="op">//</span>megaattitude.io<span class="op">/</span>projects<span class="op">/</span>mega<span class="op">-</span>acceptability<span class="op">/</span>mega<span class="op">-</span>acceptability<span class="op">-</span>v1.<span class="bu">zip</span> <span class="op">-</span>P data<span class="op">/</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>unzip data<span class="op">/</span>mega<span class="op">-</span>acceptability<span class="op">-</span>v1.<span class="bu">zip</span> <span class="op">-</span>d data<span class="op">/</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>data_dir <span class="op">=</span> <span class="st">"./data/mega-acceptability-v1/"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-tags="[]" data-execution_count="34">
<div class="sourceCode cell-code" id="cb2" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pandas <span class="im">import</span> DataFrame, read_csv</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> load_data(fname: <span class="bu">str</span>, verbose: <span class="bu">bool</span> <span class="op">=</span> <span class="va">True</span>) <span class="op">-&gt;</span> DataFrame:</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># read the raw data skipping comment rows at the beginning</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>    data <span class="op">=</span> read_csv(fname, sep<span class="op">=</span><span class="st">"</span><span class="ch">\t</span><span class="st">"</span>)</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> verbose:</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>        n_datapoints <span class="op">=</span> data.shape[<span class="dv">0</span>]</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"The full dataset has </span><span class="sc">{</span>n_datapoints<span class="sc">}</span><span class="ss"> datapoints."</span>)</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># remove non-native speakers</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="st">"nativeenglish"</span> <span class="kw">in</span> data.columns:</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>        data <span class="op">=</span> data.query(<span class="st">"nativeenglish"</span>)</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> verbose:</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>        n_datapoints_native <span class="op">=</span> data.shape[<span class="dv">0</span>]</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Removing </span><span class="sc">{</span>n_datapoints <span class="op">-</span> n_datapoints_native<span class="sc">}</span><span class="ss"> "</span></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>              <span class="st">"responses from nonnative speakers."</span>)</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># remove NaN judgments</span></span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>    data <span class="op">=</span> data.query(<span class="st">"~response.isnull()"</span>)</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> verbose:</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>        n_datapoints_nonnull <span class="op">=</span> data.shape[<span class="dv">0</span>]</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Removing </span><span class="sc">{</span>n_datapoints_native <span class="op">-</span> n_datapoints_nonnull<span class="sc">}</span><span class="ss"> NA responses."</span>)</span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> data</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Most importantly for our purposes, the dataset contains the <code>verb</code> and <code>frame</code> instantiated in the <code>sentence</code> that each <code>participant</code> rated on a 1-7 Likert <code>response</code> scale.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<div class="cell" data-tags="[]" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> load_data(os.path.join(data_dir, <span class="st">"mega-acceptability-v1.tsv"</span>))</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>data[[<span class="st">"participant"</span>, <span class="st">"verb"</span>, <span class="st">"frame"</span>, <span class="st">"sentence"</span>, <span class="st">"response"</span>]].head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre data-code-line-numbers=""><code>The full dataset has 250000 datapoints.
Removing 600 responses from nonnative speakers.
Removing 10 NA responses.</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="3">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">participant</th>
<th data-quarto-table-cell-role="th">verb</th>
<th data-quarto-table-cell-role="th">frame</th>
<th data-quarto-table-cell-role="th">sentence</th>
<th data-quarto-table-cell-role="th">response</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>4</td>
<td>turn_out</td>
<td>NP was Ved whichNP to VP</td>
<td>Someone was turned out which thing to do.</td>
<td>2.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>381</td>
<td>turn_out</td>
<td>NP was Ved whichNP to VP</td>
<td>Someone was turned out which thing to do.</td>
<td>1.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>395</td>
<td>turn_out</td>
<td>NP was Ved whichNP to VP</td>
<td>Someone was turned out which thing to do.</td>
<td>2.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>621</td>
<td>turn_out</td>
<td>NP was Ved whichNP to VP</td>
<td>Someone was turned out which thing to do.</td>
<td>1.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>527</td>
<td>turn_out</td>
<td>NP was Ved whichNP to VP</td>
<td>Someone was turned out which thing to do.</td>
<td>1.0</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>The full distribution of ratings is similar to the one we saw for Sprouse et al.’s Experiments 1 and 3 in the sense that it shows that, in general, subjects prefer the ends of the scale. It differs mainly in the fact that there is a substantial bias toward 1 responses.</p>
<div class="cell" data-tags="[]" data-execution_count="28">
<details>
<summary>Plotting code</summary>
<div class="sourceCode cell-code" id="cb5" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> numpy <span class="im">import</span> arange</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib.pyplot <span class="im">import</span> subplot</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> subplot()</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>ax.hist(data.response, bins<span class="op">=</span>arange(<span class="dv">1</span>, <span class="dv">9</span>), rwidth<span class="op">=</span><span class="fl">0.5</span>, align<span class="op">=</span><span class="st">"left"</span>)</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">"Likert scale acceptability judgments (MegaAcceptability)"</span>)</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">"Judgment"</span>)</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> ax.set_ylabel(<span class="st">"Count"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="model-definition_files/figure-html/cell-5-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>This bias is perhaps unsurprising in light of the way that the dataset was constructed: many of the verb-frame combinations are bound to be bad together; and it gives a sense for how “sparse” the verb-frame acceptability matrix we attempt to estimate using our models is likely to be. On average, the mean <code>response</code> for each verb-frame pair is below 4.</p>
<div class="cell" data-tags="[]" data-execution_count="5">
<details>
<summary>Plotting code</summary>
<div class="sourceCode cell-code" id="cb6" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>warnings.filterwarnings(<span class="st">"ignore"</span>)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> numpy <span class="im">import</span> <span class="bu">round</span>, corrcoef</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pandas <span class="im">import</span> Series</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> seaborn <span class="im">import</span> clustermap</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>verb_frame_means <span class="op">=</span> data.pivot_table(</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>    index<span class="op">=</span><span class="st">"verb"</span>, columns<span class="op">=</span><span class="st">"frame"</span>, values<span class="op">=</span><span class="st">"response"</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> clustermap(</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>    verb_frame_means, cmap<span class="op">=</span><span class="st">"vlag"</span>, figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">10</span>), </span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>    center<span class="op">=</span><span class="dv">4</span>, xticklabels<span class="op">=</span><span class="va">True</span>, yticklabels<span class="op">=</span><span class="va">False</span></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="model-definition_files/figure-html/cell-6-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>For reasons discussed in Module 1, we need to be careful in interpreting this sparsity–not least because there were many distinct lists and the distribution of true acceptability in the list almost certainly affected how subjects calibrated to the response scale. And so, following <span class="citation" data-cites="white_computational_2016">White and Rawlins (<a href="#ref-white_computational_2016" role="doc-biblioref">2016</a>)</span>, we’ll integrate an ordered logistic likelihood into all of our models. We’ll first reimplement the model proposed by <span class="citation" data-cites="white_computational_2016">White and Rawlins (<a href="#ref-white_computational_2016" role="doc-biblioref">2016</a>)</span>, then incrementally extend it to model the idea of homomorphic hierarchies of semantic and syntactic types discussed by <span class="citation" data-cites="lohninger_typology_2020">Lohninger and Wurmbrand (<a href="#ref-lohninger_typology_2020" role="doc-biblioref">to appear</a>)</span>.</p>
</section>
<section id="inducing-semantic-types-by-matrix-factorization" class="level2">
<h2 class="anchored" data-anchor-id="inducing-semantic-types-by-matrix-factorization">Inducing semantic types by matrix factorization</h2>
<p><span class="citation" data-cites="white_computational_2016">White and Rawlins (<a href="#ref-white_computational_2016" role="doc-biblioref">2016</a>)</span> model the ordinal acceptability judgments <span class="math inline">\(r_n\)</span> associated with a sentence <span class="math inline">\(\text{sent}(n)\)</span> to be a function of the probability <span class="math inline">\(\alpha_{vf}\)</span> that the main clause verb <span class="math inline">\(v = \text{verb}(n)\)</span> in <span class="math inline">\(\text{sent}(n)\)</span> is acceptable in the syntactic frame <span class="math inline">\(f = \text{frame}(i)\)</span> instantiated in <span class="math inline">\(\text{sent}(n)\)</span>. They model this probability as a function of two other kinds of probability: (i) the probability <span class="math inline">\(\lambda_{vs}\)</span> that a particular verb <span class="math inline">\(v\)</span> can have a particular semantic type <span class="math inline">\(s\)</span>; and (ii) the probability <span class="math inline">\(\pi_{fs}\)</span> that a particular semantic type <span class="math inline">\(s\)</span> can be mapped onto a particular syntactic frame <span class="math inline">\(f\)</span>. We’ll refer to the collection of these <span class="math inline">\(\lambda_{vs}\)</span>s and <span class="math inline">\(\pi_{fs}\)</span>s as matrices <span class="math inline">\(\boldsymbol\Lambda \in [0, 1]^{V \times K_\text{semtype}}\)</span> and <span class="math inline">\(\boldsymbol\Pi \in [0, 1]^{F \times K_\text{semtype}}\)</span>, where <span class="math inline">\(V\)</span> and <span class="math inline">\(F\)</span> are the numbers of verbs and frames, respectively.</p>
<p>The basic idea is that we should predict a verb to be good–modulo other factors <span class="citation" data-cites="grimshaw_complement_1979">(<a href="#ref-grimshaw_complement_1979" role="doc-biblioref">Grimshaw 1979</a>)</span>, such as its case assignment properties <span class="citation" data-cites="pesetsky_zero_1991">(<a href="#ref-pesetsky_zero_1991" role="doc-biblioref">Pesetsky 1991</a>)</span>–in a particular syntactic frame insofar as it can have at least one semantic type signature that maps onto that frame. That is, they define the probability <span class="math inline">\(\alpha_{vf}\)</span> that a main clause verb <span class="math inline">\(v\)</span> is acceptable in a syntactic frame <span class="math inline">\(f\)</span> to be <span class="math inline">\(p\left(\bigvee_s l_{vs} \land b_{fs}\right)\)</span>, where:</p>
<p><span class="math display">\[\begin{align*}
l_{vs} &amp;= \begin{cases}
\top &amp; \text{if } v \text{ can have semantic type signature } s\\
\bot &amp; \text{otherwise}
\end{cases}\\
b_{fs} &amp;= \begin{cases}
\top &amp; \text{if } s \text{ can map onto syntactic frame } f\\
\bot &amp; \text{otherwise}
\end{cases}
\end{align*}\]</span></p>
<p>As with <span class="math inline">\(\boldsymbol\Lambda\)</span> and <span class="math inline">\(\boldsymbol\Pi\)</span>, we can view the collection of <span class="math inline">\(l_{vs}\)</span>s and <span class="math inline">\(b_{fs}\)</span>s as boolean matrices <span class="math inline">\(\mathbf{L} \in \mathbb{B}^{V \times K_\text{semtype}}\)</span> <span class="math inline">\(\mathbf{B} \in \mathbb{B}^{F \times K_\text{semtype}}\)</span>.</p>
<p>Insofar as a verb’s having a particular type signature is independent of that type signature mapping onto a particular syntactic frame, this probability can be rewritten into an expression in terms of <span class="math inline">\(\lambda_{vs}\)</span> and <span class="math inline">\(\pi_{fs}\)</span>:</p>
<p><span class="math display">\[\begin{align*}
p\left(\bigvee_s l_{vs} \land b_{fs}\right) &amp;= p\left(\lnot\lnot\bigvee_s l_{vs} \land b_{fs}\right)\\
&amp;= 1 - p\left(\lnot\bigvee_s l_{vs} \land b_{fs}\right)\\
&amp;= 1 - p\left(\bigwedge_s \lnot\left[ l_{vs} \land b_{fs}\right]\right)\\
&amp;= 1 - \prod_s p\left(\lnot\left[ l_{vs} \land b_{fs}\right]\right)\\
&amp;= 1 - \prod_s 1 - p\left(l_{vs} \land b_{fs}\right)\\
&amp;= 1 - \prod_s 1 - p\left(l_{vs}\right)p\left(b_{fs}\right)\\
&amp;= 1 - \prod_s 1 - \lambda_{vs}\pi_{fs}\\
\end{align*}\]</span></p>
<p>As we saw in Module 2, this form coresponds to a probabilistic fuzzy logic disjunction over the semantic types. That is, if we interpret <span class="math inline">\(\lor\)</span> and <span class="math inline">\(\land\)</span> as probabilistic fuzzy logic disjunction, we can write:</p>
<p><span class="math display">\[\alpha_{vf} = \bigvee_s \lambda_{vs} \land \pi_{fs} = 1 - \prod_s 1 - \lambda_{vs}\pi_{fs}\]</span></p>
<p>Importantly, they assume: (a) that verbs can be compatible with multiple semantic type signatures; (b) that multiple semantic type signatures can map onto the same frame; and (c) that multiple frames can be mapped onto by the same semantic type signature. So <span class="math inline">\(\sum_s \lambda_{vs}\)</span> and <span class="math inline">\(\sum_s \pi_{fs}\)</span> can be anywhere between <span class="math inline">\(0\)</span> and the number of type signatures, and <span class="math inline">\(\sum_f \pi_{fs}\)</span> can be anywhere between <span class="math inline">\(0\)</span> and the number of syntactic frames. None of the three need to be <span class="math inline">\(1\)</span>.</p>
<section id="matrix-factorization" class="level3">
<h3 class="anchored" data-anchor-id="matrix-factorization">Matrix factorization</h3>
<p>Solving for <span class="math inline">\(\boldsymbol\Lambda\)</span> and <span class="math inline">\(\boldsymbol\Pi\)</span>, from which <span class="math inline">\(\alpha_{vf}\)</span> can be computed deterministically, is an instance of a <a href="https://en.wikipedia.org/wiki/Matrix_decomposition">matrix factorization</a> problem–of which <a href="https://en.wikipedia.org/wiki/Principal_component_analysis">principal component analysis</a> [PCA; <span class="citation" data-cites="pearson_lines_1901">Pearson (<a href="#ref-pearson_lines_1901" role="doc-biblioref">1901</a>)</span>], <a href="https://en.wikipedia.org/wiki/Factor_analysis">factor analysis</a>, and <a href="https://en.wikipedia.org/wiki/Non-negative_matrix_factorization">postive/non-negative matrix factorization</a> <span class="citation" data-cites="paatero_positive_1994">(<a href="#ref-paatero_positive_1994" role="doc-biblioref">Paatero and Tapper 1994</a>)</span> are common forms.</p>
<p>In matrix factorization, we assume some matrix <span class="math inline">\(\mathbf{Y} \in \mathbb{R}^{N \times M}\)</span> whose elements <span class="math inline">\(y_{nm} \sim f(x_{nm}, \boldsymbol\theta)\)</span> for some distribution <span class="math inline">\(f\)</span>. The matrix <span class="math inline">\(\mathbf{X}\)</span> is itself <em>factorized</em> (or <em>decomposed</em>) into two matrices <span class="math inline">\(\mathbf{U} \in \mathbb{R}^{N \times K}\)</span> and <span class="math inline">\(\mathbf{V} \in \mathbb{R}^{K \times M}\)</span> such that <span class="math inline">\(\mathbf{X} \equiv \mathbf{UV}\)</span>. For instance, in factor analysis (FA), <span class="math inline">\(f \equiv \mathcal{N}\)</span> and <span class="math inline">\(\boldsymbol\theta \equiv \sigma^2\)</span>; and in postive/non-negative matrix factorization, all the matrices are constrained to contain positive/non-negative reals, with <span class="math inline">\(f \equiv \text{HalfNormal}\)</span> and <span class="math inline">\(\boldsymbol\theta \equiv \sigma^2\)</span>.</p>
<p>To see why we can think of the model presented by <span class="citation" data-cites="white_computational_2016">White and Rawlins (<a href="#ref-white_computational_2016" role="doc-biblioref">2016</a>)</span> as a form of matrix factorization, remember that, to say that <span class="math inline">\(\mathbf{X} \equiv \mathbf{UV}\)</span> is just to say that <span class="math inline">\(x_{ij} = \sum_k u_{ik} \cdot v_{kj}\)</span> for all <span class="math inline">\(i, j\)</span>. If we simply replace <span class="math inline">\(\sum\)</span> with <span class="math inline">\(\bigvee\)</span> and <span class="math inline">\(\cdot\)</span> with <span class="math inline">\(\land\)</span>, we get exactly the form used by White and Rawlins.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> The distribution <span class="math inline">\(f\)</span> is then defined as an ordered logistic, whose auxiliary parameters are the by-subject cutpoints.</p>
</section>
<section id="linking-model" class="level3">
<h3 class="anchored" data-anchor-id="linking-model">Linking model</h3>
<p>As in Module 1 and White and Rawlins’ model, we’ll us an ordered logistic likelihood to model how participants make responses on the basis of <span class="math inline">\(\alpha_{vf}\)</span>. In contrast to the model in Module 1, however, we will implement all cutpoints as subject-specific, and we’ll place an exponential prior on their distances.</p>
<p><span class="math display">\[C_{sr} - C_{s(r-1)} \sim \text{Gamma}\left(a^\text{jump}_r, b^\text{jump}_r\right)\]</span></p>
<p>We’ll furthermore learn an offset for each subjects’ cutpoints <span class="math inline">\(o_s \sim \text{Gamma}\left(a^\text{center}_r, b^\text{center}_r\right)\)</span> so that <span class="math inline">\(C_{s1} = -o_s\)</span>. This assumption is important because, following <span class="citation" data-cites="white_computational_2016">White and Rawlins (<a href="#ref-white_computational_2016" role="doc-biblioref">2016</a>)</span>, we assume that the value getting binned is <span class="math inline">\(\text{logit}(\alpha_{vf})\)</span>, rather than <span class="math inline">\(\alpha_{vf}\)</span> itself. The reasoning behind this assumption has to do with the fact that we can’t simply bin directly on <span class="math inline">\([0, 1]\)</span> due to the assumption that the noise term implicit in an ordered logistic is assumed to be distributed standard logistic and therefore most of the middle categories would get very little probability.<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></p>
</section>
<section id="implementation-in-stan" class="level3">
<h3 class="anchored" data-anchor-id="implementation-in-stan">Implementation in STAN</h3>
<p>We can implement this model in STAN fairly straightforwardly.</p>
<div class="sourceCode" id="cb7" data-startfrom="1" data-code-line-numbers=""><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="kw">data</span> {</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; N_verb;                           <span class="co">// number of verbs</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; N_frame;                          <span class="co">// number of frames</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; N_component;                      <span class="co">// number of components</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; N_subj;                           <span class="co">// number of subjects</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; N_resp;                           <span class="co">// number of responses</span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; N_resp_levels;                    <span class="co">// number of ordinal response levels</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">1</span>,<span class="kw">upper</span>=N_verb&gt; verb[N_resp];        <span class="co">// the verb associated with respone n</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">1</span>,<span class="kw">upper</span>=N_frame&gt; frame[N_resp];      <span class="co">// the frame associated with respone n</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">1</span>,<span class="kw">upper</span>=N_subj&gt; subj[N_resp];        <span class="co">// the subject associated with respone n</span></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">1</span>,<span class="kw">upper</span>=N_resp_levels&gt; resp[N_resp]; <span class="co">// the response</span></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb8" data-startfrom="14" data-code-line-numbers=""><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan" style="counter-reset: source-line 13;"><span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a><span class="kw">parameters</span> {</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>  <span class="co">// the relationship between a {verb, frame} and a component</span></span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>  <span class="dt">matrix</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>,<span class="kw">upper</span>=<span class="dv">1</span>&gt;[N_verb,N_component] verb_component;</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>  <span class="dt">matrix</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>,<span class="kw">upper</span>=<span class="dv">1</span>&gt;[N_frame,N_component] frame_component;</span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>  <span class="co">// the subjects cutpoint center</span></span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt;[N_subj] subj_center;</span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>  <span class="co">// the alpha and beta parameter for the jump distribution                        </span></span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt;[N_resp_levels<span class="dv">-1</span>] subj_alpha;                      </span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt;[N_resp_levels<span class="dv">-1</span>] subj_beta;</span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a>  <span class="co">// cutpoint distances for each subject</span></span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a>  <span class="dt">matrix</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt;[N_subj,N_resp_levels<span class="dv">-2</span>] jumps;</span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb9" data-startfrom="30" data-code-line-numbers=""><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan" style="counter-reset: source-line 29;"><span id="cb9-30"><a href="#cb9-30" aria-hidden="true" tabindex="-1"></a><span class="kw">transformed parameters</span> {</span>
<span id="cb9-31"><a href="#cb9-31" aria-hidden="true" tabindex="-1"></a>  <span class="co">// compute the cutpoints by taking a cumulative sum</span></span>
<span id="cb9-32"><a href="#cb9-32" aria-hidden="true" tabindex="-1"></a>  <span class="dt">matrix</span>[N_resp_levels<span class="dv">-1</span>,N_subj] cutpoints;</span>
<span id="cb9-33"><a href="#cb9-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-34"><a href="#cb9-34" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (s <span class="cf">in</span> <span class="dv">1</span>:N_subj) {</span>
<span id="cb9-35"><a href="#cb9-35" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (c <span class="cf">in</span> <span class="dv">1</span>:(N_resp_levels<span class="dv">-1</span>)) {</span>
<span id="cb9-36"><a href="#cb9-36" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span> (c == <span class="dv">1</span>) {</span>
<span id="cb9-37"><a href="#cb9-37" aria-hidden="true" tabindex="-1"></a>        cutpoints[c,s] = <span class="fl">0.0</span> - subj_center[s];</span>
<span id="cb9-38"><a href="#cb9-38" aria-hidden="true" tabindex="-1"></a>      } <span class="cf">else</span> {</span>
<span id="cb9-39"><a href="#cb9-39" aria-hidden="true" tabindex="-1"></a>        cutpoints[c,s] = cutpoints[c<span class="dv">-1</span>,s] + jumps[s,c<span class="dv">-1</span>] - subj_center[s];</span>
<span id="cb9-40"><a href="#cb9-40" aria-hidden="true" tabindex="-1"></a>      }</span>
<span id="cb9-41"><a href="#cb9-41" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb9-42"><a href="#cb9-42" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb9-43"><a href="#cb9-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-44"><a href="#cb9-44" aria-hidden="true" tabindex="-1"></a>  <span class="co">// component the verb-frame acceptability</span></span>
<span id="cb9-45"><a href="#cb9-45" aria-hidden="true" tabindex="-1"></a>  <span class="dt">matrix</span>[N_verb,N_frame] verb_frame;</span>
<span id="cb9-46"><a href="#cb9-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-47"><a href="#cb9-47" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (v <span class="cf">in</span> <span class="dv">1</span>:N_verb) {</span>
<span id="cb9-48"><a href="#cb9-48" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (f <span class="cf">in</span> <span class="dv">1</span>:N_frame) {</span>
<span id="cb9-49"><a href="#cb9-49" aria-hidden="true" tabindex="-1"></a>      verb_frame[v,f] = <span class="fl">1.0</span>;</span>
<span id="cb9-50"><a href="#cb9-50" aria-hidden="true" tabindex="-1"></a>      <span class="cf">for</span> (c <span class="cf">in</span> <span class="dv">1</span>:N_component) {</span>
<span id="cb9-51"><a href="#cb9-51" aria-hidden="true" tabindex="-1"></a>        verb_frame[v,f] *= <span class="fl">1.0</span> - verb_component[v,c] * frame_component[f,c];</span>
<span id="cb9-52"><a href="#cb9-52" aria-hidden="true" tabindex="-1"></a>      }</span>
<span id="cb9-53"><a href="#cb9-53" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb9-54"><a href="#cb9-54" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb9-55"><a href="#cb9-55" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb9-56"><a href="#cb9-56" aria-hidden="true" tabindex="-1"></a>  verb_frame = <span class="fl">1.0</span> - verb_frame;</span>
<span id="cb9-57"><a href="#cb9-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-58"><a href="#cb9-58" aria-hidden="true" tabindex="-1"></a>  <span class="co">// compute the log-odds</span></span>
<span id="cb9-59"><a href="#cb9-59" aria-hidden="true" tabindex="-1"></a>  <span class="co">// used as a parameter of the ordered logistic</span></span>
<span id="cb9-60"><a href="#cb9-60" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>[N_resp] mu;</span>
<span id="cb9-61"><a href="#cb9-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-62"><a href="#cb9-62" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (n <span class="cf">in</span> <span class="dv">1</span>:N_resp) {</span>
<span id="cb9-63"><a href="#cb9-63" aria-hidden="true" tabindex="-1"></a>    mu[n] = logit(verb_frame[verb[n],frame[n]]);</span>
<span id="cb9-64"><a href="#cb9-64" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb9-65"><a href="#cb9-65" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb10" data-startfrom="67" data-code-line-numbers=""><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan" style="counter-reset: source-line 66;"><span id="cb10-67"><a href="#cb10-67" aria-hidden="true" tabindex="-1"></a><span class="kw">model</span> {</span>
<span id="cb10-68"><a href="#cb10-68" aria-hidden="true" tabindex="-1"></a>  <span class="co">// sample the centers</span></span>
<span id="cb10-69"><a href="#cb10-69" aria-hidden="true" tabindex="-1"></a>  subj_center ~ gamma(subj_alpha[<span class="dv">1</span>], subj_beta[<span class="dv">1</span>]);</span>
<span id="cb10-70"><a href="#cb10-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-71"><a href="#cb10-71" aria-hidden="true" tabindex="-1"></a>  <span class="co">// sample the cutpoint distances</span></span>
<span id="cb10-72"><a href="#cb10-72" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">1</span>:(N_resp_levels<span class="dv">-2</span>))</span>
<span id="cb10-73"><a href="#cb10-73" aria-hidden="true" tabindex="-1"></a>    jumps[,j] ~ gamma(subj_alpha[j+<span class="dv">1</span>], subj_beta[j+<span class="dv">1</span>]);</span>
<span id="cb10-74"><a href="#cb10-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-75"><a href="#cb10-75" aria-hidden="true" tabindex="-1"></a>  <span class="co">// sample the responses</span></span>
<span id="cb10-76"><a href="#cb10-76" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (n <span class="cf">in</span> <span class="dv">1</span>:N_resp) {</span>
<span id="cb10-77"><a href="#cb10-77" aria-hidden="true" tabindex="-1"></a>    resp[n] ~ ordered_logistic(mu[n], cutpoints);</span>
<span id="cb10-78"><a href="#cb10-78" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb10-79"><a href="#cb10-79" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>One issue with the implementation in STAN is that sampling under this parameterization turns out to be infeasible, so we need to turn to the sort of optimization discussed in the last section. STAN <a href="https://mc-stan.org/docs/reference-manual/optimization.html#optimization.chapter">supports</a> this sort of optimization, but (as far I know) it does not support stochastic gradient ascent/descent.<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a></p>
</section>
<section id="implementation-in-pytorch" class="level3">
<h3 class="anchored" data-anchor-id="implementation-in-pytorch">Implementation in PyTorch</h3>
<p>Using <code>torch</code> will give us the ability to implement MAP estimation with stochastic gradient descent. We basically need to design two components: (i) a <code>torch.nn.Module</code>, which is effectively used as a container for our models parameters that also specifies the analogue of STAN’s <code>transformed parameters</code> block; and (ii) a trainer class that computes the posterior of those parameters against some data and runs stochastic gradient descent.<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a> We’ll specify the first here and the second in the next section.</p>
<p>We’ll first specify a <code>dataclass</code> representing the data.</p>
<div class="cell" data-tags="[]" data-execution_count="10">
<div class="sourceCode cell-code" id="cb11" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dataclasses <span class="im">import</span> dataclass</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="at">@dataclass</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> SelectionData:</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>    verb: ndarray</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>    frame: ndarray</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>    subj: ndarray</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>    resp: ndarray</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We’ll also specify <code>dataclass</code>es that declare the paremeters that the model needs to have access to. We’ll use <code>SelectionModelParametersABC</code> across all of our models.</p>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb12" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="at">@dataclass</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> SelectionModelParametersABC:</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>    n_verb: <span class="bu">int</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>    n_frame: <span class="bu">int</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>    n_subj: <span class="bu">int</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>    n_resp_levels: <span class="bu">int</span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a><span class="at">@dataclass</span></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> SelectionModelParameters(SelectionModelParametersABC):</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>    n_component: <span class="bu">int</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Finally, we’ll implement the module.</p>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb13" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> typing <span class="im">import</span> Optional</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch <span class="im">import</span> manual_seed</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch <span class="im">import</span> randn</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.nn <span class="im">import</span> Module</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>ZERO <span class="op">=</span> <span class="fl">1e-3</span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>ONE <span class="op">=</span> <span class="fl">1.</span> <span class="op">-</span> ZERO</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> SelectionModel(Module):</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>    parameter_class <span class="op">=</span> SelectionModelParameters</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>    data_class <span class="op">=</span> SelectionData</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, parameters: SelectionModelParameters):</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model_parameters <span class="op">=</span> parameters</span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>        <span class="co"># prior parameters</span></span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.verb_component_prior_mean_aux <span class="op">=</span> torch.nn.Parameter(</span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>            randn(parameters.n_component), </span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a>            requires_grad<span class="op">=</span><span class="va">True</span></span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.frame_component_prior_mean_aux <span class="op">=</span> torch.nn.Parameter(</span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a>            randn(parameters.n_component), </span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a>            requires_grad<span class="op">=</span><span class="va">True</span></span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.verb_component_prior_precision_aux <span class="op">=</span> torch.nn.Parameter(</span>
<span id="cb13-29"><a href="#cb13-29" aria-hidden="true" tabindex="-1"></a>            randn(parameters.n_component), </span>
<span id="cb13-30"><a href="#cb13-30" aria-hidden="true" tabindex="-1"></a>            requires_grad<span class="op">=</span><span class="va">True</span></span>
<span id="cb13-31"><a href="#cb13-31" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb13-32"><a href="#cb13-32" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.frame_component_prior_precision_aux <span class="op">=</span> torch.nn.Parameter(</span>
<span id="cb13-33"><a href="#cb13-33" aria-hidden="true" tabindex="-1"></a>            randn(parameters.n_component), </span>
<span id="cb13-34"><a href="#cb13-34" aria-hidden="true" tabindex="-1"></a>            requires_grad<span class="op">=</span><span class="va">True</span></span>
<span id="cb13-35"><a href="#cb13-35" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb13-36"><a href="#cb13-36" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb13-37"><a href="#cb13-37" aria-hidden="true" tabindex="-1"></a>        <span class="co"># latent matrices</span></span>
<span id="cb13-38"><a href="#cb13-38" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.verb_component_aux <span class="op">=</span> torch.nn.Parameter(</span>
<span id="cb13-39"><a href="#cb13-39" aria-hidden="true" tabindex="-1"></a>            randn([</span>
<span id="cb13-40"><a href="#cb13-40" aria-hidden="true" tabindex="-1"></a>                parameters.n_verb, parameters.n_component</span>
<span id="cb13-41"><a href="#cb13-41" aria-hidden="true" tabindex="-1"></a>            ]), </span>
<span id="cb13-42"><a href="#cb13-42" aria-hidden="true" tabindex="-1"></a>            requires_grad<span class="op">=</span><span class="va">True</span></span>
<span id="cb13-43"><a href="#cb13-43" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb13-44"><a href="#cb13-44" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.frame_component_aux <span class="op">=</span> torch.nn.Parameter(</span>
<span id="cb13-45"><a href="#cb13-45" aria-hidden="true" tabindex="-1"></a>            randn([</span>
<span id="cb13-46"><a href="#cb13-46" aria-hidden="true" tabindex="-1"></a>                parameters.n_frame, parameters.n_component</span>
<span id="cb13-47"><a href="#cb13-47" aria-hidden="true" tabindex="-1"></a>            ]), </span>
<span id="cb13-48"><a href="#cb13-48" aria-hidden="true" tabindex="-1"></a>            requires_grad<span class="op">=</span><span class="va">True</span></span>
<span id="cb13-49"><a href="#cb13-49" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb13-50"><a href="#cb13-50" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb13-51"><a href="#cb13-51" aria-hidden="true" tabindex="-1"></a>        <span class="co"># likelihood parameters</span></span>
<span id="cb13-52"><a href="#cb13-52" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.log_jumps <span class="op">=</span> torch.nn.Parameter(</span>
<span id="cb13-53"><a href="#cb13-53" aria-hidden="true" tabindex="-1"></a>            torch.ones([</span>
<span id="cb13-54"><a href="#cb13-54" aria-hidden="true" tabindex="-1"></a>                parameters.n_subj, parameters.n_resp_levels<span class="op">-</span><span class="dv">1</span></span>
<span id="cb13-55"><a href="#cb13-55" aria-hidden="true" tabindex="-1"></a>            ]), </span>
<span id="cb13-56"><a href="#cb13-56" aria-hidden="true" tabindex="-1"></a>            requires_grad<span class="op">=</span><span class="va">True</span></span>
<span id="cb13-57"><a href="#cb13-57" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb13-58"><a href="#cb13-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-59"><a href="#cb13-59" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, data: SelectionData):</span>
<span id="cb13-60"><a href="#cb13-60" aria-hidden="true" tabindex="-1"></a>        <span class="co"># compute the verb frame probabilities</span></span>
<span id="cb13-61"><a href="#cb13-61" aria-hidden="true" tabindex="-1"></a>        verb_frame_prob <span class="op">=</span> <span class="va">self</span>.verb_frame_prob(</span>
<span id="cb13-62"><a href="#cb13-62" aria-hidden="true" tabindex="-1"></a>            data.verb, data.frame,</span>
<span id="cb13-63"><a href="#cb13-63" aria-hidden="true" tabindex="-1"></a>            clamp<span class="op">=</span><span class="va">True</span></span>
<span id="cb13-64"><a href="#cb13-64" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb13-65"><a href="#cb13-65" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb13-66"><a href="#cb13-66" aria-hidden="true" tabindex="-1"></a>        <span class="co"># apply a logit to those probabilities</span></span>
<span id="cb13-67"><a href="#cb13-67" aria-hidden="true" tabindex="-1"></a>        verb_frame_logodds <span class="op">=</span> torch.log(verb_frame_prob) <span class="op">-\</span></span>
<span id="cb13-68"><a href="#cb13-68" aria-hidden="true" tabindex="-1"></a>                             torch.log(<span class="fl">1.</span> <span class="op">-</span> verb_frame_prob)</span>
<span id="cb13-69"><a href="#cb13-69" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb13-70"><a href="#cb13-70" aria-hidden="true" tabindex="-1"></a>        <span class="co"># compute the jumps for each subject</span></span>
<span id="cb13-71"><a href="#cb13-71" aria-hidden="true" tabindex="-1"></a>        jumps <span class="op">=</span> <span class="va">self</span>.jumps[data.subj]</span>
<span id="cb13-72"><a href="#cb13-72" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb13-73"><a href="#cb13-73" aria-hidden="true" tabindex="-1"></a>        <span class="co"># return the ordered logistic probabilities</span></span>
<span id="cb13-74"><a href="#cb13-74" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> ordered_logistic_likelihood(</span>
<span id="cb13-75"><a href="#cb13-75" aria-hidden="true" tabindex="-1"></a>            verb_frame_logodds, jumps</span>
<span id="cb13-76"><a href="#cb13-76" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb13-77"><a href="#cb13-77" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-78"><a href="#cb13-78" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> verb_frame_prob(</span>
<span id="cb13-79"><a href="#cb13-79" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>, </span>
<span id="cb13-80"><a href="#cb13-80" aria-hidden="true" tabindex="-1"></a>        verb_idx: Optional[ndarray] <span class="op">=</span> <span class="va">None</span>, </span>
<span id="cb13-81"><a href="#cb13-81" aria-hidden="true" tabindex="-1"></a>        frame_idx: Optional[ndarray] <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb13-82"><a href="#cb13-82" aria-hidden="true" tabindex="-1"></a>        clamp: <span class="bu">bool</span> <span class="op">=</span> <span class="va">False</span></span>
<span id="cb13-83"><a href="#cb13-83" aria-hidden="true" tabindex="-1"></a>    ) <span class="op">-&gt;</span> Tensor:</span>
<span id="cb13-84"><a href="#cb13-84" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> verb_idx <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="kw">or</span> frame_idx <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb13-85"><a href="#cb13-85" aria-hidden="true" tabindex="-1"></a>            acc <span class="op">=</span> <span class="fl">1.</span> <span class="op">-</span> torch.prod(</span>
<span id="cb13-86"><a href="#cb13-86" aria-hidden="true" tabindex="-1"></a>                <span class="fl">1.</span> <span class="op">-</span> <span class="va">self</span>.verb_component_prob[verb_idx,:] <span class="op">*</span> </span>
<span id="cb13-87"><a href="#cb13-87" aria-hidden="true" tabindex="-1"></a>                     <span class="va">self</span>.frame_component_prob[frame_idx,:],</span>
<span id="cb13-88"><a href="#cb13-88" aria-hidden="true" tabindex="-1"></a>                axis<span class="op">=</span><span class="dv">1</span></span>
<span id="cb13-89"><a href="#cb13-89" aria-hidden="true" tabindex="-1"></a>            ).clamp(ZERO, ONE)</span>
<span id="cb13-90"><a href="#cb13-90" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> verb_idx <span class="kw">is</span> <span class="va">None</span> <span class="kw">and</span> frame_idx <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb13-91"><a href="#cb13-91" aria-hidden="true" tabindex="-1"></a>            acc <span class="op">=</span> <span class="fl">1.</span> <span class="op">-</span> torch.prod(</span>
<span id="cb13-92"><a href="#cb13-92" aria-hidden="true" tabindex="-1"></a>                <span class="fl">1.</span> <span class="op">-</span> <span class="va">self</span>.verb_component_prob[:,<span class="va">None</span>,:] <span class="op">*</span> </span>
<span id="cb13-93"><a href="#cb13-93" aria-hidden="true" tabindex="-1"></a>                     <span class="va">self</span>.frame_component_prob[:,frame_idx,:],</span>
<span id="cb13-94"><a href="#cb13-94" aria-hidden="true" tabindex="-1"></a>                axis<span class="op">=</span><span class="dv">2</span></span>
<span id="cb13-95"><a href="#cb13-95" aria-hidden="true" tabindex="-1"></a>            ).clamp(ZERO, ONE)</span>
<span id="cb13-96"><a href="#cb13-96" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> verb_idx <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="kw">and</span> frame_idx <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb13-97"><a href="#cb13-97" aria-hidden="true" tabindex="-1"></a>            acc <span class="op">=</span> <span class="fl">1.</span> <span class="op">-</span> torch.prod(</span>
<span id="cb13-98"><a href="#cb13-98" aria-hidden="true" tabindex="-1"></a>                <span class="fl">1.</span> <span class="op">-</span> <span class="va">self</span>.verb_component_prob[verb_idx,<span class="va">None</span>,:] <span class="op">*</span> </span>
<span id="cb13-99"><a href="#cb13-99" aria-hidden="true" tabindex="-1"></a>                     <span class="va">self</span>.frame_component_prob[<span class="va">None</span>,:,:],</span>
<span id="cb13-100"><a href="#cb13-100" aria-hidden="true" tabindex="-1"></a>                axis<span class="op">=</span><span class="dv">2</span></span>
<span id="cb13-101"><a href="#cb13-101" aria-hidden="true" tabindex="-1"></a>            ).clamp(ZERO, ONE)</span>
<span id="cb13-102"><a href="#cb13-102" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb13-103"><a href="#cb13-103" aria-hidden="true" tabindex="-1"></a>            acc <span class="op">=</span> <span class="fl">1.</span> <span class="op">-</span> torch.prod(</span>
<span id="cb13-104"><a href="#cb13-104" aria-hidden="true" tabindex="-1"></a>                <span class="fl">1.</span> <span class="op">-</span> <span class="va">self</span>.verb_component_prob[:,<span class="va">None</span>,:] <span class="op">*</span> </span>
<span id="cb13-105"><a href="#cb13-105" aria-hidden="true" tabindex="-1"></a>                     <span class="va">self</span>.frame_component_prob[<span class="va">None</span>,:,:],</span>
<span id="cb13-106"><a href="#cb13-106" aria-hidden="true" tabindex="-1"></a>                axis<span class="op">=</span><span class="dv">2</span></span>
<span id="cb13-107"><a href="#cb13-107" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb13-108"><a href="#cb13-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-109"><a href="#cb13-109" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> clamp:</span>
<span id="cb13-110"><a href="#cb13-110" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> acc.clamp(ZERO, ONE)</span>
<span id="cb13-111"><a href="#cb13-111" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb13-112"><a href="#cb13-112" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> acc</span>
<span id="cb13-113"><a href="#cb13-113" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-114"><a href="#cb13-114" aria-hidden="true" tabindex="-1"></a>    <span class="at">@property</span></span>
<span id="cb13-115"><a href="#cb13-115" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> verb_component_prob(<span class="va">self</span>) <span class="op">-&gt;</span> Tensor:</span>
<span id="cb13-116"><a href="#cb13-116" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.sigmoid(<span class="va">self</span>.verb_component_aux)</span>
<span id="cb13-117"><a href="#cb13-117" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-118"><a href="#cb13-118" aria-hidden="true" tabindex="-1"></a>    <span class="at">@property</span></span>
<span id="cb13-119"><a href="#cb13-119" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> frame_component_prob(<span class="va">self</span>) <span class="op">-&gt;</span> Tensor:</span>
<span id="cb13-120"><a href="#cb13-120" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.sigmoid(<span class="va">self</span>.frame_component_aux)</span>
<span id="cb13-121"><a href="#cb13-121" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-122"><a href="#cb13-122" aria-hidden="true" tabindex="-1"></a>    <span class="at">@property</span></span>
<span id="cb13-123"><a href="#cb13-123" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> jumps(<span class="va">self</span>):</span>
<span id="cb13-124"><a href="#cb13-124" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.exp(<span class="va">self</span>.log_jumps)</span>
<span id="cb13-125"><a href="#cb13-125" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-126"><a href="#cb13-126" aria-hidden="true" tabindex="-1"></a>    <span class="at">@property</span></span>
<span id="cb13-127"><a href="#cb13-127" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> verb_component_prior_mean(<span class="va">self</span>):</span>
<span id="cb13-128"><a href="#cb13-128" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.sigmoid(<span class="va">self</span>.verb_component_prior_mean_aux)</span>
<span id="cb13-129"><a href="#cb13-129" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-130"><a href="#cb13-130" aria-hidden="true" tabindex="-1"></a>    <span class="at">@property</span></span>
<span id="cb13-131"><a href="#cb13-131" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> frame_component_prior_mean(<span class="va">self</span>):</span>
<span id="cb13-132"><a href="#cb13-132" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.sigmoid(<span class="va">self</span>.frame_component_prior_mean_aux)</span>
<span id="cb13-133"><a href="#cb13-133" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-134"><a href="#cb13-134" aria-hidden="true" tabindex="-1"></a>    <span class="at">@property</span></span>
<span id="cb13-135"><a href="#cb13-135" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> verb_component_prior_precision(<span class="va">self</span>):</span>
<span id="cb13-136"><a href="#cb13-136" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.exp(<span class="va">self</span>.verb_component_prior_precision_aux)</span>
<span id="cb13-137"><a href="#cb13-137" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-138"><a href="#cb13-138" aria-hidden="true" tabindex="-1"></a>    <span class="at">@property</span></span>
<span id="cb13-139"><a href="#cb13-139" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> frame_component_prior_precision(<span class="va">self</span>):</span>
<span id="cb13-140"><a href="#cb13-140" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.exp(<span class="va">self</span>.frame_component_prior_precision_aux)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="complex-syntactic-and-semantic-types" class="level2">
<h2 class="anchored" data-anchor-id="complex-syntactic-and-semantic-types">Complex syntactic and semantic types</h2>
<p>As mentioned by <span class="citation" data-cites="white_computational_2016">White and Rawlins (<a href="#ref-white_computational_2016" role="doc-biblioref">2016</a>)</span>, this model of selection is very coarse-grained in that it fails to capture that both semantic and syntactic types have structure. This structure is important in the current context because the hypotheses that <span class="citation" data-cites="lohninger_typology_2020">Lohninger and Wurmbrand (<a href="#ref-lohninger_typology_2020" role="doc-biblioref">to appear</a>)</span> present make important reference to the relationship between particular elements (or <em>primitive types</em>) that constitute a structured (or <em>complex</em>) type. For instance, <span class="citation" data-cites="wurmbrand_implicational_2023">Wurmbrand and Lohninger (<a href="#ref-wurmbrand_implicational_2023" role="doc-biblioref">2023</a>)</span> suggest that, while particular languages may make finer-grained distinctions, there are three coarse-grained semantic types that are mapped monotonically to three coarse-grained syntactic types, both ordered by some notion of containment <span class="citation" data-cites="ramchand_deriving_2014">(<a href="#ref-ramchand_deriving_2014" role="doc-biblioref">Ramchand and Svenonius 2014</a>)</span>.</p>
<p>To incorporate this idea of structure into our models, the first thing we need to figure out is how to represent the distinction between a primitive type and a complex type. As I mentioned in <a href="#selecting-a-number-of-types">introducing the non-parametric prior</a> we added to White and Rawlins’ model, in formal semantics following <span class="citation" data-cites="montague_proper_1973">Montague (<a href="#ref-montague_proper_1973" role="doc-biblioref">1973</a>)</span>, we tend to assume that complex semantic types <span class="math inline">\(\mathcal{T} \equiv \bigcup_{j=1}^\infty \mathcal{T}_j\)</span> are inductively defined in terms of some finite set of primitive types <span class="math inline">\(\mathcal{T}_0\)</span> and <span class="math inline">\(\mathcal{T}_i = \left[\bigcup_{j=1}^{i-1} \mathcal{T}_j\right]^2\)</span>.</p>
<div class="cell" data-tags="[]" data-execution_count="16">
<div class="sourceCode cell-code" id="cb14" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> typing <span class="im">import</span> Generator, Union, Tuple, Set</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> defaultdict</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> itertools <span class="im">import</span> product</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>PrimitiveType <span class="op">=</span> <span class="bu">str</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>ComplexType <span class="op">=</span> Union[PrimitiveType, Tuple[<span class="st">'ComplexType'</span>, <span class="st">'ComplexType'</span>]]</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> natural_numbers() <span class="op">-&gt;</span> Generator[<span class="bu">int</span>, <span class="va">None</span>, <span class="va">None</span>]:</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""The natural numbers excluding 0"""</span></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>    i <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> <span class="va">True</span>:</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>        i <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">yield</span> i</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> complex_types(</span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>    primitive_types: Set[PrimitiveType], max_size: Optional[<span class="bu">int</span>] <span class="op">=</span> <span class="va">None</span></span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>) <span class="op">-&gt;</span> Generator[ComplexType, <span class="va">None</span>, <span class="va">None</span>]:</span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>    types <span class="op">=</span> defaultdict(<span class="bu">list</span>)</span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> t <span class="kw">in</span> primitive_types:</span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a>        types[<span class="dv">0</span>].append(t)</span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a>        <span class="cf">yield</span> t</span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> natural_numbers():</span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> max_size <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="kw">and</span> i <span class="op">&gt;</span> max_size:</span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span></span>
<span id="cb14-28"><a href="#cb14-28" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb14-29"><a href="#cb14-29" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j1 <span class="kw">in</span> <span class="bu">range</span>(i):</span>
<span id="cb14-30"><a href="#cb14-30" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> j2 <span class="kw">in</span> <span class="bu">range</span>(i):</span>
<span id="cb14-31"><a href="#cb14-31" aria-hidden="true" tabindex="-1"></a>                <span class="cf">for</span> t <span class="kw">in</span> product(types[j1], types[j2]):</span>
<span id="cb14-32"><a href="#cb14-32" aria-hidden="true" tabindex="-1"></a>                    types[i].append(t)</span>
<span id="cb14-33"><a href="#cb14-33" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">yield</span> t</span>
<span id="cb14-34"><a href="#cb14-34" aria-hidden="true" tabindex="-1"></a>                    </span>
<span id="cb14-35"><a href="#cb14-35" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, t <span class="kw">in</span> <span class="bu">enumerate</span>(complex_types({<span class="st">"e"</span>, <span class="st">"t"</span>})):</span>
<span id="cb14-36"><a href="#cb14-36" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> i <span class="op">&lt;</span> <span class="dv">20</span>:</span>
<span id="cb14-37"><a href="#cb14-37" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(t)</span>
<span id="cb14-38"><a href="#cb14-38" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb14-39"><a href="#cb14-39" aria-hidden="true" tabindex="-1"></a>        <span class="cf">break</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre data-code-line-numbers=""><code>t
e
('t', 't')
('t', 'e')
('e', 't')
('e', 'e')
('t', 't')
('t', 'e')
('e', 't')
('e', 'e')
('t', ('t', 't'))
('t', ('t', 'e'))
('t', ('e', 't'))
('t', ('e', 'e'))
('e', ('t', 't'))
('e', ('t', 'e'))
('e', ('e', 't'))
('e', ('e', 'e'))
(('t', 't'), 't')
(('t', 't'), 'e')</code></pre>
</div>
</div>
<p>A similar approach is taken to syntactic structures in combinatory categorial grammar, where directed <em>type constructors</em> <code>\</code> and <code>/</code> are added <span class="citation" data-cites="steedman_combinatory_2011">(see <a href="#ref-steedman_combinatory_2011" role="doc-biblioref">Steedman and Baldridge 2011</a> and references therein)</span>.</p>
<div class="cell" data-tags="[]" data-execution_count="18">
<div class="sourceCode cell-code" id="cb16" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>TypeConstructor <span class="op">=</span> <span class="bu">str</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>ComplexType <span class="op">=</span> Union[PrimitiveType, Tuple[<span class="st">'ComplexType'</span>, TypeConstructor, <span class="st">'ComplexType'</span>]]</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> natural_numbers() <span class="op">-&gt;</span> Generator[<span class="bu">int</span>, <span class="va">None</span>, <span class="va">None</span>]:</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""The natural numbers excluding 0"""</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>    i <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> <span class="va">True</span>:</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>        i <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>        <span class="cf">yield</span> i</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> complex_types(</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>    primitive_types: Set[PrimitiveType], </span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>    type_constructors: Set[TypeConstructor], </span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>    max_size: Optional[<span class="bu">int</span>] <span class="op">=</span> <span class="va">None</span></span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>) <span class="op">-&gt;</span> Generator[ComplexType, <span class="va">None</span>, <span class="va">None</span>]:</span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>    types <span class="op">=</span> defaultdict(<span class="bu">list</span>)</span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> t <span class="kw">in</span> primitive_types:</span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a>        types[<span class="dv">0</span>].append(t)</span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>        <span class="cf">yield</span> t</span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> natural_numbers():</span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> max_size <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="kw">and</span> i <span class="op">&gt;</span> max_size:</span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span></span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j1 <span class="kw">in</span> <span class="bu">range</span>(i):</span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> j2 <span class="kw">in</span> <span class="bu">range</span>(i):</span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a>                <span class="cf">for</span> t <span class="kw">in</span> product(types[j1], type_constructors, types[j2]):</span>
<span id="cb16-30"><a href="#cb16-30" aria-hidden="true" tabindex="-1"></a>                    types[i].append(t)</span>
<span id="cb16-31"><a href="#cb16-31" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">yield</span> t</span>
<span id="cb16-32"><a href="#cb16-32" aria-hidden="true" tabindex="-1"></a>                    </span>
<span id="cb16-33"><a href="#cb16-33" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, t <span class="kw">in</span> <span class="bu">enumerate</span>(complex_types({<span class="st">"NP"</span>, <span class="st">"S"</span>}, {<span class="vs">r"\\"</span>, <span class="st">"/"</span>})):</span>
<span id="cb16-34"><a href="#cb16-34" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> i <span class="op">&lt;</span> <span class="dv">20</span>:</span>
<span id="cb16-35"><a href="#cb16-35" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(t)</span>
<span id="cb16-36"><a href="#cb16-36" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb16-37"><a href="#cb16-37" aria-hidden="true" tabindex="-1"></a>        <span class="cf">break</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre data-code-line-numbers=""><code>NP
S
('NP', '\\\\', 'NP')
('NP', '\\\\', 'S')
('NP', '/', 'NP')
('NP', '/', 'S')
('S', '\\\\', 'NP')
('S', '\\\\', 'S')
('S', '/', 'NP')
('S', '/', 'S')
('NP', '\\\\', 'NP')
('NP', '\\\\', 'S')
('NP', '/', 'NP')
('NP', '/', 'S')
('S', '\\\\', 'NP')
('S', '\\\\', 'S')
('S', '/', 'NP')
('S', '/', 'S')
('NP', '\\\\', ('NP', '\\\\', 'NP'))
('NP', '\\\\', ('NP', '\\\\', 'S'))</code></pre>
</div>
</div>
<p>So both complex semantic types and complex syntactic types can be viewed as binary trees with type constructors as the non-terminals and the primitive types as the terminals.</p>
<p>We could imagine stating the generalizations described by <span class="citation" data-cites="lohninger_typology_2020">Lohninger and Wurmbrand (<a href="#ref-lohninger_typology_2020" role="doc-biblioref">to appear</a>)</span> in terms of ordered equivalence classes on these sorts of types. What’s crucial in this case is that the types form an equivalence class–not which types are contained in each class. So really we just want to be able to represent the equivalence class, which we can do without recognizing its constituency. That is, we can simply view the equivalence classes as primitive (i.e.&nbsp;unstructured) types that potentially have an ordering relation on them (probably determined by their constituency). A simple way to do this is to represent primitive semantic and syntactic types as integers.</p>
<p>Can we get away from having to represent complex types at all then? No.&nbsp;The reason is that clauses are not the only constituents in many of these sentences. <span id="exm-tell-good"></span> <span id="exm-tell-bad"></span> For instance, to explain why (1) is more acceptable than (2), we want to be able to appeal to two things: (i) that <em>tell</em> is good with finite clauses–e.g.&nbsp;because its type lives in a semantic equivalence class that maps onto a syntactic equivalence class that can be realized as <em>that something happened</em>; but also (ii) that <em>tell</em> prefers to have a direct object.</p>
<ol class="example" type="1">
<li>Someone told someone that something happened.</li>
<li>Someone told that something happened.</li>
</ol>
<p>So basically, we can’t abstract away <em>all</em> of the structure in the semantic and syntactic types. We need to retain some sorts of structure–e.g.&nbsp;the distinction between direct objects and clausal complements–while abstracting away others–e.g.&nbsp;what exactly the semantic and syntactic type of the clausal complement is in a relatively fine-grained type system like Montague’s. We’ll do this by viewing complex semantic and syntactic types as strings of primitive types. We’ll consider two ways of doing this: one that constrains the explanation of acceptability by an inherent ordering on primitive types and another that is unconstrained by this ordering.</p>
<p>So complex types will be strings of integers. Adding this structure in turn requires us to handle types of different complexity–e.g.&nbsp;that the complex syntactic type associated with (1) contains two primitive types while the one associated with (2) contains two. We’ll do this by thinking of all types as having the same complexity but by introducing the notion of a special null primitive type that “pads out” types of lower complexity.</p>
<section id="relationships-among-representations" class="level3">
<h3 class="anchored" data-anchor-id="relationships-among-representations">Relationships among representations</h3>
<p>The second thing we must handle is how to represent some additional relationships that we didn’t have to before.</p>
<section id="primitive-type-relationships" class="level4">
<h4 class="anchored" data-anchor-id="primitive-type-relationships">Primitive type relationships</h4>
<p>We’ll need to represent the relationship between semantic and syntactic primitive types as well as the relationship between syntactic primitive types and the constituents that may realize them. We’ll do both using matrices of probabilities similar to the ones we used in implemented White and Rawlins’ model–i.e.&nbsp;that are interpreted representing the probability that a particular object <em>can</em> be associated with some other object.</p>
<p>We’ll represent the relationship between semantic and syntactic primitive types in a matrix of probabilities <span class="math inline">\(\boldsymbol\Phi^\text{synsem} \in [0, 1]^{(K_\text{sem} + 1) \times (K_\text{syn} + 1)}\)</span>, where <span class="math inline">\(K_\text{sem}\)</span> is the number of semantic primitive types, <span class="math inline">\(K_\text{syn}\)</span> is the number of syntactic primitive types, and the additional type handles a null type. We’ll assume that null primitive semantic types only map onto null primitive syntactic types–<span class="math inline">\(\phi^\text{synsem}_{00} = 1\)</span> and <span class="math inline">\(\phi^\text{synsem}_{0t} = 0\)</span> for all non-null types <span class="math inline">\(t\)</span>–but we want to allow that null primitive syntactic types can be mapped onto by non-null primitive semantic types.</p>
<p><span id="exm-nca-leadup"></span> <span id="exm-nca"></span> We need this latter assumption to handle null complement anaphora, as in (4).</p>
<ol start="3" class="example" type="1">
<li><strong>A:</strong> Bo left.</li>
<li><strong>B:</strong> I {know, remember, heard, …}.</li>
</ol>
<p><span id="exm-nca-equivalent"></span> Baically, we want to be able to capture that (4) is interpreted as (5).</p>
<ol start="5" class="example" type="1">
<li><strong>B’:</strong> I {know, remember, heard, …} that Bo left.</li>
</ol>
<p>When the model incorporates ordering on the primitive types, we will constrain the mapping by the ordering by assuming that each non-null primitive type <span class="math inline">\(t\)</span> is associated with some probability distribution over <span class="math inline">\(K_\text{rank}\)</span> ranks <span class="math inline">\(\chi^\text{synsem} \sim \text{OrderedLogistic}(\zeta_t^\text{sem}, \mathbf{\kappa})\)</span> and that <span class="math inline">\(\phi^\text{synsem}_{tt'} \equiv \mathbb{P}\left(\chi_{t} = \chi_{t'}\right) = \sum_i \mathbb{P}\left(\chi_{t} = i\right)\mathbb{P}\left(\chi_{t'} = i\right)\)</span>. For instance, for wurmbrand_implicational_2023, <span class="math inline">\(K_\text{rank} = 3\)</span>.</p>
<p>We’ll represent the relationship between syntactic primitive types and the constituents that may realize them in a similar way: a matrix of probabilities <span class="math inline">\(\boldsymbol\Phi^\text{syn} \in [0, 1]^{(K_\text{syn} + 1) \times K_\text{const}}\)</span>. We’ll assume that <span class="math inline">\(\phi^\text{syn}_{0i} = 0\)</span> for all constituents <span class="math inline">\(i\)</span>–i.e.&nbsp;that the null type doesn’t map to any constituent–and that frames are decomposed into constituents in the following way (expand to see the frame-to-constituent mapping).</p>
<div class="cell" data-tags="[]" data-execution_count="19">
<details>
<summary>Frame-to-constitutent mapping</summary>
<div class="sourceCode cell-code" id="cb18" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> OrderedDict</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>frame_to_constituents <span class="op">=</span> OrderedDict({</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP was Ved whichNP to VP'</span>: {</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP_obj"</span>, <span class="st">"whichNP to VP"</span>),</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_obj"</span>, <span class="st">"whichNP to VP"</span>)</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>    }, </span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP Ved for NP to VP'</span>: {</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"for NP to VP"</span>), </span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"PP_for"</span>, <span class="st">"to VP"</span>)</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP Ved NP to VP[+eventive]'</span>: {</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP to VP[+eventive]"</span>), </span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP_obj"</span>, <span class="st">"to VP[+eventive]"</span>)</span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>    }, </span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP was Ved whether to VP'</span>: {</span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP_obj"</span>, <span class="st">"whether to VP"</span>),</span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_obj"</span>, <span class="st">"whether to VP"</span>)</span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP Ved to VP[+eventive]'</span>: {</span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"to VP[+eventive]"</span>)</span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a>    }, </span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP Ved NP to NP'</span>: {</span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP_obj"</span>, <span class="st">"NP_iobj"</span>) </span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true" tabindex="-1"></a>    }, </span>
<span id="cb18-26"><a href="#cb18-26" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP Ved NP that S'</span>: {</span>
<span id="cb18-27"><a href="#cb18-27" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP_obj"</span>, <span class="st">"that S"</span>) </span>
<span id="cb18-28"><a href="#cb18-28" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb18-29"><a href="#cb18-29" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP was Ved about NP'</span>: {</span>
<span id="cb18-30"><a href="#cb18-30" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP_obj"</span>, <span class="st">"about NP"</span>) ,</span>
<span id="cb18-31"><a href="#cb18-31" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_obj"</span>, <span class="st">"about NP"</span>) </span>
<span id="cb18-32"><a href="#cb18-32" aria-hidden="true" tabindex="-1"></a>    }, </span>
<span id="cb18-33"><a href="#cb18-33" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP was Ved that S[-tense]'</span>: {</span>
<span id="cb18-34"><a href="#cb18-34" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP_obj"</span>, <span class="st">"S[-tense]"</span>) ,</span>
<span id="cb18-35"><a href="#cb18-35" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_obj"</span>, <span class="st">"S[-tense]"</span>) </span>
<span id="cb18-36"><a href="#cb18-36" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb18-37"><a href="#cb18-37" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP Ved to NP that S[+future]'</span>: {</span>
<span id="cb18-38"><a href="#cb18-38" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP_iobj"</span>, <span class="st">"that S[+future]"</span>) </span>
<span id="cb18-39"><a href="#cb18-39" aria-hidden="true" tabindex="-1"></a>    }, </span>
<span id="cb18-40"><a href="#cb18-40" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP Ved whether to VP'</span>: {</span>
<span id="cb18-41"><a href="#cb18-41" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"whether to VP"</span>)</span>
<span id="cb18-42"><a href="#cb18-42" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb18-43"><a href="#cb18-43" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP Ved whichNP to VP'</span>: {</span>
<span id="cb18-44"><a href="#cb18-44" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"whichNP to VP"</span>)</span>
<span id="cb18-45"><a href="#cb18-45" aria-hidden="true" tabindex="-1"></a>    }, </span>
<span id="cb18-46"><a href="#cb18-46" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP Ved about whether S'</span>: {</span>
<span id="cb18-47"><a href="#cb18-47" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"about whether S"</span>) </span>
<span id="cb18-48"><a href="#cb18-48" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb18-49"><a href="#cb18-49" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP Ved whichNP S'</span>: {</span>
<span id="cb18-50"><a href="#cb18-50" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"whichNP S"</span>)</span>
<span id="cb18-51"><a href="#cb18-51" aria-hidden="true" tabindex="-1"></a>    }, </span>
<span id="cb18-52"><a href="#cb18-52" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP Ved that S[-tense]'</span>: {</span>
<span id="cb18-53"><a href="#cb18-53" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"that S[-tense]"</span>) </span>
<span id="cb18-54"><a href="#cb18-54" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb18-55"><a href="#cb18-55" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP Ved whether S[+future]'</span>: {</span>
<span id="cb18-56"><a href="#cb18-56" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"whether S[+future]"</span>) </span>
<span id="cb18-57"><a href="#cb18-57" aria-hidden="true" tabindex="-1"></a>    }, </span>
<span id="cb18-58"><a href="#cb18-58" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP was Ved that S[+future]'</span>: {</span>
<span id="cb18-59"><a href="#cb18-59" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP_obj"</span>, <span class="st">"that S[+future]"</span>) ,</span>
<span id="cb18-60"><a href="#cb18-60" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_obj"</span>, <span class="st">"that S[+future]"</span>) </span>
<span id="cb18-61"><a href="#cb18-61" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb18-62"><a href="#cb18-62" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP Ved to NP whether S'</span>: {</span>
<span id="cb18-63"><a href="#cb18-63" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP_iobj"</span>, <span class="st">"whether S"</span>) </span>
<span id="cb18-64"><a href="#cb18-64" aria-hidden="true" tabindex="-1"></a>    }, </span>
<span id="cb18-65"><a href="#cb18-65" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP Ved'</span>: {</span>
<span id="cb18-66"><a href="#cb18-66" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>,)</span>
<span id="cb18-67"><a href="#cb18-67" aria-hidden="true" tabindex="-1"></a>    }, </span>
<span id="cb18-68"><a href="#cb18-68" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP Ved NP to VP[-eventive]'</span>: {</span>
<span id="cb18-69"><a href="#cb18-69" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP to VP[-eventive]"</span>), </span>
<span id="cb18-70"><a href="#cb18-70" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP_obj"</span>, <span class="st">"to VP[-eventive]"</span>),</span>
<span id="cb18-71"><a href="#cb18-71" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP to VP[-eventive]"</span>)</span>
<span id="cb18-72"><a href="#cb18-72" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb18-73"><a href="#cb18-73" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP was Ved so'</span>: {</span>
<span id="cb18-74"><a href="#cb18-74" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_obj"</span>, <span class="st">"so"</span>), </span>
<span id="cb18-75"><a href="#cb18-75" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP_obj"</span>, <span class="st">"so"</span>)</span>
<span id="cb18-76"><a href="#cb18-76" aria-hidden="true" tabindex="-1"></a>    }, </span>
<span id="cb18-77"><a href="#cb18-77" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP Ved so'</span>: {</span>
<span id="cb18-78"><a href="#cb18-78" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"so"</span>)</span>
<span id="cb18-79"><a href="#cb18-79" aria-hidden="true" tabindex="-1"></a>    }, </span>
<span id="cb18-80"><a href="#cb18-80" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP Ved NP that S[+future]'</span>: {</span>
<span id="cb18-81"><a href="#cb18-81" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP_obj"</span>, <span class="st">"that S[+future]"</span>)</span>
<span id="cb18-82"><a href="#cb18-82" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb18-83"><a href="#cb18-83" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP Ved NP whether S[+future]'</span>: {</span>
<span id="cb18-84"><a href="#cb18-84" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP_obj"</span>, <span class="st">"whether S[+future]"</span>)</span>
<span id="cb18-85"><a href="#cb18-85" aria-hidden="true" tabindex="-1"></a>    }, </span>
<span id="cb18-86"><a href="#cb18-86" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP Ved to NP whether S[+future]'</span>: {</span>
<span id="cb18-87"><a href="#cb18-87" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP_iobj"</span>, <span class="st">"whether S[+future]"</span>)</span>
<span id="cb18-88"><a href="#cb18-88" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb18-89"><a href="#cb18-89" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP was Ved that S'</span>: {</span>
<span id="cb18-90"><a href="#cb18-90" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_obj"</span>, <span class="st">"that S"</span>), </span>
<span id="cb18-91"><a href="#cb18-91" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP_obj"</span>, <span class="st">"that S"</span>)</span>
<span id="cb18-92"><a href="#cb18-92" aria-hidden="true" tabindex="-1"></a>    }, </span>
<span id="cb18-93"><a href="#cb18-93" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP Ved NP whether S'</span>: {</span>
<span id="cb18-94"><a href="#cb18-94" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP_obj"</span>, <span class="st">"whether S"</span>)</span>
<span id="cb18-95"><a href="#cb18-95" aria-hidden="true" tabindex="-1"></a>    }, </span>
<span id="cb18-96"><a href="#cb18-96" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP was Ved whether S'</span>: {</span>
<span id="cb18-97"><a href="#cb18-97" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_obj"</span>, <span class="st">"whether S"</span>), </span>
<span id="cb18-98"><a href="#cb18-98" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP_obj"</span>, <span class="st">"whether S"</span>)</span>
<span id="cb18-99"><a href="#cb18-99" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb18-100"><a href="#cb18-100" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP was Ved to VP[-eventive]'</span>: {</span>
<span id="cb18-101"><a href="#cb18-101" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_obj"</span>, <span class="st">"to VP[-eventive]"</span>), </span>
<span id="cb18-102"><a href="#cb18-102" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP_obj"</span>, <span class="st">"to VP[-eventive]"</span>),</span>
<span id="cb18-103"><a href="#cb18-103" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP to VP[-eventive]"</span>)</span>
<span id="cb18-104"><a href="#cb18-104" aria-hidden="true" tabindex="-1"></a>    }, </span>
<span id="cb18-105"><a href="#cb18-105" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP Ved NP VP'</span>: {</span>
<span id="cb18-106"><a href="#cb18-106" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP_obj"</span>, <span class="st">"VP"</span>),</span>
<span id="cb18-107"><a href="#cb18-107" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP VP"</span>)</span>
<span id="cb18-108"><a href="#cb18-108" aria-hidden="true" tabindex="-1"></a>    }, </span>
<span id="cb18-109"><a href="#cb18-109" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP Ved VPing'</span>: {</span>
<span id="cb18-110"><a href="#cb18-110" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"VPing"</span>)</span>
<span id="cb18-111"><a href="#cb18-111" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb18-112"><a href="#cb18-112" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP was Ved to VP[+eventive]'</span>: {</span>
<span id="cb18-113"><a href="#cb18-113" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_obj"</span>, <span class="st">"to VP[+eventive]"</span>), </span>
<span id="cb18-114"><a href="#cb18-114" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP_obj"</span>, <span class="st">"to VP[+eventive]"</span>),</span>
<span id="cb18-115"><a href="#cb18-115" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP to VP[+eventive]"</span>)</span>
<span id="cb18-116"><a href="#cb18-116" aria-hidden="true" tabindex="-1"></a>    }, </span>
<span id="cb18-117"><a href="#cb18-117" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP Ved NP that S[-tense]'</span>: {</span>
<span id="cb18-118"><a href="#cb18-118" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP_obj"</span>, <span class="st">"that S[-tense]"</span>)</span>
<span id="cb18-119"><a href="#cb18-119" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb18-120"><a href="#cb18-120" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP Ved that S'</span>: {</span>
<span id="cb18-121"><a href="#cb18-121" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"that S"</span>)</span>
<span id="cb18-122"><a href="#cb18-122" aria-hidden="true" tabindex="-1"></a>    }, </span>
<span id="cb18-123"><a href="#cb18-123" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP was Ved'</span>: {</span>
<span id="cb18-124"><a href="#cb18-124" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_obj"</span>,), </span>
<span id="cb18-125"><a href="#cb18-125" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP_obj"</span>)</span>
<span id="cb18-126"><a href="#cb18-126" aria-hidden="true" tabindex="-1"></a>    }, </span>
<span id="cb18-127"><a href="#cb18-127" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP Ved S'</span>: {</span>
<span id="cb18-128"><a href="#cb18-128" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"S"</span>)</span>
<span id="cb18-129"><a href="#cb18-129" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb18-130"><a href="#cb18-130" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP Ved that S[+future]'</span>: {</span>
<span id="cb18-131"><a href="#cb18-131" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"that S[+future]"</span>)</span>
<span id="cb18-132"><a href="#cb18-132" aria-hidden="true" tabindex="-1"></a>    }, </span>
<span id="cb18-133"><a href="#cb18-133" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP was Ved about whether S'</span>: {</span>
<span id="cb18-134"><a href="#cb18-134" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP_obj"</span>, <span class="st">"about whether S"</span>) ,</span>
<span id="cb18-135"><a href="#cb18-135" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_obj"</span>, <span class="st">"about whether S"</span>) </span>
<span id="cb18-136"><a href="#cb18-136" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb18-137"><a href="#cb18-137" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP Ved NP'</span>: {</span>
<span id="cb18-138"><a href="#cb18-138" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP_obj"</span>) </span>
<span id="cb18-139"><a href="#cb18-139" aria-hidden="true" tabindex="-1"></a>    }, </span>
<span id="cb18-140"><a href="#cb18-140" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP Ved NP VPing'</span>: {</span>
<span id="cb18-141"><a href="#cb18-141" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP_obj"</span>, <span class="st">"VPing"</span>),</span>
<span id="cb18-142"><a href="#cb18-142" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP VPing"</span>)</span>
<span id="cb18-143"><a href="#cb18-143" aria-hidden="true" tabindex="-1"></a>    }, </span>
<span id="cb18-144"><a href="#cb18-144" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP Ved NP whichNP S'</span>: {</span>
<span id="cb18-145"><a href="#cb18-145" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP_obj"</span>, <span class="st">"whichNP S"</span>)</span>
<span id="cb18-146"><a href="#cb18-146" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb18-147"><a href="#cb18-147" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP Ved about NP'</span>: {</span>
<span id="cb18-148"><a href="#cb18-148" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"about NP"</span>) </span>
<span id="cb18-149"><a href="#cb18-149" aria-hidden="true" tabindex="-1"></a>    }, </span>
<span id="cb18-150"><a href="#cb18-150" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP was Ved S'</span>: {</span>
<span id="cb18-151"><a href="#cb18-151" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP_obj"</span>, <span class="st">"S"</span>) ,</span>
<span id="cb18-152"><a href="#cb18-152" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_obj"</span>, <span class="st">"S"</span>) </span>
<span id="cb18-153"><a href="#cb18-153" aria-hidden="true" tabindex="-1"></a>    }, </span>
<span id="cb18-154"><a href="#cb18-154" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP Ved to NP that S'</span>: {</span>
<span id="cb18-155"><a href="#cb18-155" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP_iobj"</span>, <span class="st">"that S"</span>),</span>
<span id="cb18-156"><a href="#cb18-156" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb18-157"><a href="#cb18-157" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP was Ved whether S[+future]'</span>: {</span>
<span id="cb18-158"><a href="#cb18-158" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP_obj"</span>, <span class="st">"whether S[+future]"</span>) ,</span>
<span id="cb18-159"><a href="#cb18-159" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_obj"</span>, <span class="st">"whether S[+future]"</span>) </span>
<span id="cb18-160"><a href="#cb18-160" aria-hidden="true" tabindex="-1"></a>    }, </span>
<span id="cb18-161"><a href="#cb18-161" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP Ved whether S'</span>: {</span>
<span id="cb18-162"><a href="#cb18-162" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"whether S"</span>) </span>
<span id="cb18-163"><a href="#cb18-163" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb18-164"><a href="#cb18-164" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP was Ved whichNP S'</span>: {</span>
<span id="cb18-165"><a href="#cb18-165" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP_obj"</span>, <span class="st">"whichNP S"</span>) ,</span>
<span id="cb18-166"><a href="#cb18-166" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_obj"</span>, <span class="st">"whichNP S"</span>) </span>
<span id="cb18-167"><a href="#cb18-167" aria-hidden="true" tabindex="-1"></a>    }, </span>
<span id="cb18-168"><a href="#cb18-168" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP Ved to NP that S[-tense]'</span>: {</span>
<span id="cb18-169"><a href="#cb18-169" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"NP_iobj"</span>, <span class="st">"that S[-tense]"</span>)</span>
<span id="cb18-170"><a href="#cb18-170" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb18-171"><a href="#cb18-171" aria-hidden="true" tabindex="-1"></a>    <span class="st">'NP Ved to VP[-eventive]'</span>: {</span>
<span id="cb18-172"><a href="#cb18-172" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"NP_subj"</span>, <span class="st">"to VP[-eventive]"</span>)</span>
<span id="cb18-173"><a href="#cb18-173" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb18-174"><a href="#cb18-174" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb18-175"><a href="#cb18-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-176"><a href="#cb18-176" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> data[data.frame.isin(frame_to_constituents)]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>The thing to notice about these frame decompositions is that different frames have different possible <em>parses</em>. <span id="exm-tell-passive"></span> <span id="exm-annoy-passive"></span> <span id="exm-annoy-active"></span> <span id="exm-happy"></span> For instance, (6) should have the same parse as (1), but (7) might have the same parse as (8) or it might have a parse analogous to the clearly adjectival (9).</p>
<ol start="6" class="example" type="1">
<li>Someone was told that something happened.</li>
<li>Someone was annoyed that something happened.</li>
<li>It annoyed someone that something happened.</li>
<li>Someone was happy that something happened.</li>
</ol>
<p>So we need to represent that a particular syntactic type may map onto any of these parses and still be good. We’ll discuss how to do this shortly in terms of the following mapping from frames to parses to an indicator for whether that constituent is contained in that parse (expand to see). We’ll call this mapping <span class="math inline">\(\mathbf{C} \in \mathbb{B}^{F \times K_\text{parse} \times K_\text{const}}\)</span>, where <span class="math inline">\(F\)</span> is the number of frames, <span class="math inline">\(K_\text{parse}\)</span> is the maximum number of parses, and <span class="math inline">\(K_\text{const}\)</span> is the numberof constituent types.</p>
<div class="cell" data-tags="[]" data-execution_count="24">
<details>
<summary>Constituent-to-feature vector mapping</summary>
<div class="sourceCode cell-code" id="cb19" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> numpy <span class="im">import</span> array, zeros, where, isin</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> xarray <span class="im">import</span> DataArray</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>constituents <span class="op">=</span> array(<span class="bu">sorted</span>({</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>    c </span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> tups <span class="kw">in</span> frame_to_constituents.values() </span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> t <span class="kw">in</span> tups </span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> c <span class="kw">in</span> t</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>}))</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>max_parses <span class="op">=</span> <span class="bu">max</span>(</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>    <span class="bu">len</span>(t) </span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> tups <span class="kw">in</span> frame_to_constituents.values() </span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> t <span class="kw">in</span> tups </span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a>frame_to_parse_constituent_indicators <span class="op">=</span> zeros([</span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a>    <span class="bu">len</span>(frame_to_constituents), max_parses, <span class="bu">len</span>(constituents)</span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, (f, parses) <span class="kw">in</span> <span class="bu">enumerate</span>(frame_to_constituents.items()):</span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j, parse <span class="kw">in</span> <span class="bu">enumerate</span>(parses):</span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> k, const <span class="kw">in</span> <span class="bu">enumerate</span>(parse):</span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true" tabindex="-1"></a>            const_idx <span class="op">=</span> where(constituents <span class="op">==</span> const)[<span class="dv">0</span>][<span class="dv">0</span>]</span>
<span id="cb19-25"><a href="#cb19-25" aria-hidden="true" tabindex="-1"></a>            frame_to_parse_constituent_indicators[i,j,const_idx] <span class="op">=</span> <span class="fl">1.</span></span>
<span id="cb19-26"><a href="#cb19-26" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb19-27"><a href="#cb19-27" aria-hidden="true" tabindex="-1"></a>frame_to_parse_constituent_indicators <span class="op">=</span> DataArray(</span>
<span id="cb19-28"><a href="#cb19-28" aria-hidden="true" tabindex="-1"></a>    frame_to_parse_constituent_indicators, </span>
<span id="cb19-29"><a href="#cb19-29" aria-hidden="true" tabindex="-1"></a>    dims<span class="op">=</span>[<span class="st">"frame"</span>, <span class="st">"parse"</span>, <span class="st">"constituent"</span>],</span>
<span id="cb19-30"><a href="#cb19-30" aria-hidden="true" tabindex="-1"></a>    coords<span class="op">=</span>{</span>
<span id="cb19-31"><a href="#cb19-31" aria-hidden="true" tabindex="-1"></a>        <span class="st">"frame"</span>: <span class="bu">list</span>(frame_to_constituents),</span>
<span id="cb19-32"><a href="#cb19-32" aria-hidden="true" tabindex="-1"></a>        <span class="st">"parse"</span>: <span class="bu">list</span>(<span class="bu">range</span>(max_parses)),</span>
<span id="cb19-33"><a href="#cb19-33" aria-hidden="true" tabindex="-1"></a>        <span class="st">"constituent"</span>: constituents,</span>
<span id="cb19-34"><a href="#cb19-34" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb19-35"><a href="#cb19-35" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb19-36"><a href="#cb19-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-37"><a href="#cb19-37" aria-hidden="true" tabindex="-1"></a>frame_to_parse_constituent_indicators</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="24">

<div><svg style="position: absolute; width: 0; height: 0; overflow: hidden">
<defs>
<symbol id="icon-database" viewbox="0 0 32 32">
<path d="M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z"></path>
<path d="M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z"></path>
<path d="M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z"></path>
</symbol>
<symbol id="icon-file-text2" viewbox="0 0 32 32">
<path d="M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z"></path>
<path d="M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z"></path>
<path d="M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z"></path>
<path d="M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z"></path>
</symbol>
</defs>
</svg>
<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.
 *
 */

:root {
  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));
  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));
  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));
  --xr-border-color: var(--jp-border-color2, #e0e0e0);
  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);
  --xr-background-color: var(--jp-layout-color0, white);
  --xr-background-color-row-even: var(--jp-layout-color1, white);
  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);
}

html[theme=dark],
body[data-theme=dark],
body.vscode-dark {
  --xr-font-color0: rgba(255, 255, 255, 1);
  --xr-font-color2: rgba(255, 255, 255, 0.54);
  --xr-font-color3: rgba(255, 255, 255, 0.38);
  --xr-border-color: #1F1F1F;
  --xr-disabled-color: #515151;
  --xr-background-color: #111111;
  --xr-background-color-row-even: #111111;
  --xr-background-color-row-odd: #313131;
}

.xr-wrap {
  display: block !important;
  min-width: 300px;
  max-width: 700px;
}

.xr-text-repr-fallback {
  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */
  display: none;
}

.xr-header {
  padding-top: 6px;
  padding-bottom: 6px;
  margin-bottom: 4px;
  border-bottom: solid 1px var(--xr-border-color);
}

.xr-header > div,
.xr-header > ul {
  display: inline;
  margin-top: 0;
  margin-bottom: 0;
}

.xr-obj-type,
.xr-array-name {
  margin-left: 2px;
  margin-right: 10px;
}

.xr-obj-type {
  color: var(--xr-font-color2);
}

.xr-sections {
  padding-left: 0 !important;
  display: grid;
  grid-template-columns: 150px auto auto 1fr 20px 20px;
}

.xr-section-item {
  display: contents;
}

.xr-section-item input {
  display: none;
}

.xr-section-item input + label {
  color: var(--xr-disabled-color);
}

.xr-section-item input:enabled + label {
  cursor: pointer;
  color: var(--xr-font-color2);
}

.xr-section-item input:enabled + label:hover {
  color: var(--xr-font-color0);
}

.xr-section-summary {
  grid-column: 1;
  color: var(--xr-font-color2);
  font-weight: 500;
}

.xr-section-summary > span {
  display: inline-block;
  padding-left: 0.5em;
}

.xr-section-summary-in:disabled + label {
  color: var(--xr-font-color2);
}

.xr-section-summary-in + label:before {
  display: inline-block;
  content: '►';
  font-size: 11px;
  width: 15px;
  text-align: center;
}

.xr-section-summary-in:disabled + label:before {
  color: var(--xr-disabled-color);
}

.xr-section-summary-in:checked + label:before {
  content: '▼';
}

.xr-section-summary-in:checked + label > span {
  display: none;
}

.xr-section-summary,
.xr-section-inline-details {
  padding-top: 4px;
  padding-bottom: 4px;
}

.xr-section-inline-details {
  grid-column: 2 / -1;
}

.xr-section-details {
  display: none;
  grid-column: 1 / -1;
  margin-bottom: 5px;
}

.xr-section-summary-in:checked ~ .xr-section-details {
  display: contents;
}

.xr-array-wrap {
  grid-column: 1 / -1;
  display: grid;
  grid-template-columns: 20px auto;
}

.xr-array-wrap > label {
  grid-column: 1;
  vertical-align: top;
}

.xr-preview {
  color: var(--xr-font-color3);
}

.xr-array-preview,
.xr-array-data {
  padding: 0 5px !important;
  grid-column: 2;
}

.xr-array-data,
.xr-array-in:checked ~ .xr-array-preview {
  display: none;
}

.xr-array-in:checked ~ .xr-array-data,
.xr-array-preview {
  display: inline-block;
}

.xr-dim-list {
  display: inline-block !important;
  list-style: none;
  padding: 0 !important;
  margin: 0;
}

.xr-dim-list li {
  display: inline-block;
  padding: 0;
  margin: 0;
}

.xr-dim-list:before {
  content: '(';
}

.xr-dim-list:after {
  content: ')';
}

.xr-dim-list li:not(:last-child):after {
  content: ',';
  padding-right: 5px;
}

.xr-has-index {
  font-weight: bold;
}

.xr-var-list,
.xr-var-item {
  display: contents;
}

.xr-var-item > div,
.xr-var-item label,
.xr-var-item > .xr-var-name span {
  background-color: var(--xr-background-color-row-even);
  margin-bottom: 0;
}

.xr-var-item > .xr-var-name:hover span {
  padding-right: 5px;
}

.xr-var-list > li:nth-child(odd) > div,
.xr-var-list > li:nth-child(odd) > label,
.xr-var-list > li:nth-child(odd) > .xr-var-name span {
  background-color: var(--xr-background-color-row-odd);
}

.xr-var-name {
  grid-column: 1;
}

.xr-var-dims {
  grid-column: 2;
}

.xr-var-dtype {
  grid-column: 3;
  text-align: right;
  color: var(--xr-font-color2);
}

.xr-var-preview {
  grid-column: 4;
}

.xr-index-preview {
  grid-column: 2 / 5;
  color: var(--xr-font-color2);
}

.xr-var-name,
.xr-var-dims,
.xr-var-dtype,
.xr-preview,
.xr-attrs dt {
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  padding-right: 10px;
}

.xr-var-name:hover,
.xr-var-dims:hover,
.xr-var-dtype:hover,
.xr-attrs dt:hover {
  overflow: visible;
  width: auto;
  z-index: 1;
}

.xr-var-attrs,
.xr-var-data,
.xr-index-data {
  display: none;
  background-color: var(--xr-background-color) !important;
  padding-bottom: 5px !important;
}

.xr-var-attrs-in:checked ~ .xr-var-attrs,
.xr-var-data-in:checked ~ .xr-var-data,
.xr-index-data-in:checked ~ .xr-index-data {
  display: block;
}

.xr-var-data > table {
  float: right;
}

.xr-var-name span,
.xr-var-data,
.xr-index-name div,
.xr-index-data,
.xr-attrs {
  padding-left: 25px !important;
}

.xr-attrs,
.xr-var-attrs,
.xr-var-data,
.xr-index-data {
  grid-column: 1 / -1;
}

dl.xr-attrs {
  padding: 0;
  margin: 0;
  display: grid;
  grid-template-columns: 125px auto;
}

.xr-attrs dt,
.xr-attrs dd {
  padding: 0;
  margin: 0;
  float: left;
  padding-right: 10px;
  width: auto;
}

.xr-attrs dt {
  font-weight: normal;
  grid-column: 1;
}

.xr-attrs dt:hover span {
  display: inline-block;
  background: var(--xr-background-color);
  padding-right: 10px;
}

.xr-attrs dd {
  grid-column: 2;
  white-space: pre-wrap;
  word-break: break-all;
}

.xr-icon-database,
.xr-icon-file-text2,
.xr-no-icon {
  display: inline-block;
  vertical-align: middle;
  width: 1em;
  height: 1.5em !important;
  stroke-width: 0;
  stroke: currentColor;
  fill: currentColor;
}
</style><pre class="xr-text-repr-fallback">&lt;xarray.DataArray (frame: 49, parse: 3, constituent: 27)&gt;
array([[[0., 0., 0., ..., 0., 0., 1.],
        [0., 0., 0., ..., 0., 0., 1.],
        [0., 0., 0., ..., 0., 0., 0.]],

       [[0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]],

       [[0., 0., 1., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]],

       ...,

       [[0., 0., 0., ..., 0., 1., 0.],
        [0., 0., 0., ..., 0., 1., 0.],
        [0., 0., 0., ..., 0., 0., 0.]],

       [[0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]],

       [[0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]]])
Coordinates:
  * frame        (frame) &lt;U31 'NP was Ved whichNP to VP' ... 'NP Ved to VP[-e...
  * parse        (parse) int64 0 1 2
  * constituent  (constituent) &lt;U19 'NP VP' 'NP VPing' ... 'whichNP to VP'</pre><div class="xr-wrap" style="display:none"><div class="xr-header"><div class="xr-obj-type">xarray.DataArray</div><div class="xr-array-name"></div><ul class="xr-dim-list"><li><span class="xr-has-index">frame</span>: 49</li><li><span class="xr-has-index">parse</span>: 3</li><li><span class="xr-has-index">constituent</span>: 27</li></ul></div><ul class="xr-sections"><li class="xr-section-item"><div class="xr-array-wrap"><input id="section-89bebc9c-0760-44b7-9db7-b9f81e5c7d5a" class="xr-array-in" type="checkbox" checked=""><label for="section-89bebc9c-0760-44b7-9db7-b9f81e5c7d5a" title="Show/hide data repr"><svg class="icon xr-icon-database"><use href="#icon-database"></use></svg></label><div class="xr-array-preview xr-preview"><span>0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0</span></div><div class="xr-array-data"><pre>array([[[0., 0., 0., ..., 0., 0., 1.],
        [0., 0., 0., ..., 0., 0., 1.],
        [0., 0., 0., ..., 0., 0., 0.]],

       [[0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]],

       [[0., 0., 1., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]],

       ...,

       [[0., 0., 0., ..., 0., 1., 0.],
        [0., 0., 0., ..., 0., 1., 0.],
        [0., 0., 0., ..., 0., 0., 0.]],

       [[0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]],

       [[0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]]])</pre></div></div></li><li class="xr-section-item"><input id="section-083989f5-850b-4d8e-843c-5d33e7a42d0c" class="xr-section-summary-in" type="checkbox" checked=""><label for="section-083989f5-850b-4d8e-843c-5d33e7a42d0c" class="xr-section-summary">Coordinates: <span>(3)</span></label><div class="xr-section-inline-details"></div><div class="xr-section-details"><ul class="xr-var-list"><li class="xr-var-item"><div class="xr-var-name"><span class="xr-has-index">frame</span></div><div class="xr-var-dims">(frame)</div><div class="xr-var-dtype">&lt;U31</div><div class="xr-var-preview xr-preview">'NP was Ved whichNP to VP' ... '...</div><input id="attrs-e6c8f3d7-0c65-4036-98b2-0d2d80395cb1" class="xr-var-attrs-in" type="checkbox" disabled=""><label for="attrs-e6c8f3d7-0c65-4036-98b2-0d2d80395cb1" title="Show/Hide attributes"><svg class="icon xr-icon-file-text2"><use href="#icon-file-text2"></use></svg></label><input id="data-af184eb1-da47-4860-b723-37a06f4e12fe" class="xr-var-data-in" type="checkbox"><label for="data-af184eb1-da47-4860-b723-37a06f4e12fe" title="Show/Hide data repr"><svg class="icon xr-icon-database"><use href="#icon-database"></use></svg></label><div class="xr-var-attrs"><dl class="xr-attrs"></dl></div><div class="xr-var-data"><pre>array(['NP was Ved whichNP to VP', 'NP Ved for NP to VP',
       'NP Ved NP to VP[+eventive]', 'NP was Ved whether to VP',
       'NP Ved to VP[+eventive]', 'NP Ved NP to NP', 'NP Ved NP that S',
       'NP was Ved about NP', 'NP was Ved that S[-tense]',
       'NP Ved to NP that S[+future]', 'NP Ved whether to VP',
       'NP Ved whichNP to VP', 'NP Ved about whether S', 'NP Ved whichNP S',
       'NP Ved that S[-tense]', 'NP Ved whether S[+future]',
       'NP was Ved that S[+future]', 'NP Ved to NP whether S', 'NP Ved',
       'NP Ved NP to VP[-eventive]', 'NP was Ved so', 'NP Ved so',
       'NP Ved NP that S[+future]', 'NP Ved NP whether S[+future]',
       'NP Ved to NP whether S[+future]', 'NP was Ved that S',
       'NP Ved NP whether S', 'NP was Ved whether S',
       'NP was Ved to VP[-eventive]', 'NP Ved NP VP', 'NP Ved VPing',
       'NP was Ved to VP[+eventive]', 'NP Ved NP that S[-tense]',
       'NP Ved that S', 'NP was Ved', 'NP Ved S', 'NP Ved that S[+future]',
       'NP was Ved about whether S', 'NP Ved NP', 'NP Ved NP VPing',
       'NP Ved NP whichNP S', 'NP Ved about NP', 'NP was Ved S',
       'NP Ved to NP that S', 'NP was Ved whether S[+future]',
       'NP Ved whether S', 'NP was Ved whichNP S',
       'NP Ved to NP that S[-tense]', 'NP Ved to VP[-eventive]'], dtype='&lt;U31')</pre></div></li><li class="xr-var-item"><div class="xr-var-name"><span class="xr-has-index">parse</span></div><div class="xr-var-dims">(parse)</div><div class="xr-var-dtype">int64</div><div class="xr-var-preview xr-preview">0 1 2</div><input id="attrs-5cc49dae-b10a-466e-8c7e-7e972fff675a" class="xr-var-attrs-in" type="checkbox" disabled=""><label for="attrs-5cc49dae-b10a-466e-8c7e-7e972fff675a" title="Show/Hide attributes"><svg class="icon xr-icon-file-text2"><use href="#icon-file-text2"></use></svg></label><input id="data-d92144e2-a4a6-4fd8-b767-393ab17806df" class="xr-var-data-in" type="checkbox"><label for="data-d92144e2-a4a6-4fd8-b767-393ab17806df" title="Show/Hide data repr"><svg class="icon xr-icon-database"><use href="#icon-database"></use></svg></label><div class="xr-var-attrs"><dl class="xr-attrs"></dl></div><div class="xr-var-data"><pre>array([0, 1, 2])</pre></div></li><li class="xr-var-item"><div class="xr-var-name"><span class="xr-has-index">constituent</span></div><div class="xr-var-dims">(constituent)</div><div class="xr-var-dtype">&lt;U19</div><div class="xr-var-preview xr-preview">'NP VP' ... 'whichNP to VP'</div><input id="attrs-cd56c8c7-12c2-4d21-8cf5-e45c566c1ae3" class="xr-var-attrs-in" type="checkbox" disabled=""><label for="attrs-cd56c8c7-12c2-4d21-8cf5-e45c566c1ae3" title="Show/Hide attributes"><svg class="icon xr-icon-file-text2"><use href="#icon-file-text2"></use></svg></label><input id="data-73c47b61-191f-4396-9fc4-f876542f508b" class="xr-var-data-in" type="checkbox"><label for="data-73c47b61-191f-4396-9fc4-f876542f508b" title="Show/Hide data repr"><svg class="icon xr-icon-database"><use href="#icon-database"></use></svg></label><div class="xr-var-attrs"><dl class="xr-attrs"></dl></div><div class="xr-var-data"><pre>array(['NP VP', 'NP VPing', 'NP to VP[+eventive]', 'NP to VP[-eventive]',
       'NP_iobj', 'NP_obj', 'NP_subj', 'PP_for', 'S', 'S[-tense]', 'VP',
       'VPing', 'about NP', 'about whether S', 'for NP to VP', 'so', 'that S',
       'that S[+future]', 'that S[-tense]', 'to VP', 'to VP[+eventive]',
       'to VP[-eventive]', 'whether S', 'whether S[+future]', 'whether to VP',
       'whichNP S', 'whichNP to VP'], dtype='&lt;U19')</pre></div></li></ul></div></li><li class="xr-section-item"><input id="section-91f6ec1c-2db6-482c-ad88-a60a2d597a38" class="xr-section-summary-in" type="checkbox"><label for="section-91f6ec1c-2db6-482c-ad88-a60a2d597a38" class="xr-section-summary">Indexes: <span>(3)</span></label><div class="xr-section-inline-details"></div><div class="xr-section-details"><ul class="xr-var-list"><li class="xr-var-item"><div class="xr-index-name"><div>frame</div></div><div class="xr-index-preview">PandasIndex</div><div></div><input id="index-4fd3bed6-26d5-4c27-b3d7-8f1d50a1288a" class="xr-index-data-in" type="checkbox"><label for="index-4fd3bed6-26d5-4c27-b3d7-8f1d50a1288a" title="Show/Hide index repr"><svg class="icon xr-icon-database"><use href="#icon-database"></use></svg></label><div class="xr-index-data"><pre>PandasIndex(Index(['NP was Ved whichNP to VP', 'NP Ved for NP to VP',
       'NP Ved NP to VP[+eventive]', 'NP was Ved whether to VP',
       'NP Ved to VP[+eventive]', 'NP Ved NP to NP', 'NP Ved NP that S',
       'NP was Ved about NP', 'NP was Ved that S[-tense]',
       'NP Ved to NP that S[+future]', 'NP Ved whether to VP',
       'NP Ved whichNP to VP', 'NP Ved about whether S', 'NP Ved whichNP S',
       'NP Ved that S[-tense]', 'NP Ved whether S[+future]',
       'NP was Ved that S[+future]', 'NP Ved to NP whether S', 'NP Ved',
       'NP Ved NP to VP[-eventive]', 'NP was Ved so', 'NP Ved so',
       'NP Ved NP that S[+future]', 'NP Ved NP whether S[+future]',
       'NP Ved to NP whether S[+future]', 'NP was Ved that S',
       'NP Ved NP whether S', 'NP was Ved whether S',
       'NP was Ved to VP[-eventive]', 'NP Ved NP VP', 'NP Ved VPing',
       'NP was Ved to VP[+eventive]', 'NP Ved NP that S[-tense]',
       'NP Ved that S', 'NP was Ved', 'NP Ved S', 'NP Ved that S[+future]',
       'NP was Ved about whether S', 'NP Ved NP', 'NP Ved NP VPing',
       'NP Ved NP whichNP S', 'NP Ved about NP', 'NP was Ved S',
       'NP Ved to NP that S', 'NP was Ved whether S[+future]',
       'NP Ved whether S', 'NP was Ved whichNP S',
       'NP Ved to NP that S[-tense]', 'NP Ved to VP[-eventive]'],
      dtype='object', name='frame'))</pre></div></li><li class="xr-var-item"><div class="xr-index-name"><div>parse</div></div><div class="xr-index-preview">PandasIndex</div><div></div><input id="index-0c814946-a32c-49fb-a2ce-8d86914e668e" class="xr-index-data-in" type="checkbox"><label for="index-0c814946-a32c-49fb-a2ce-8d86914e668e" title="Show/Hide index repr"><svg class="icon xr-icon-database"><use href="#icon-database"></use></svg></label><div class="xr-index-data"><pre>PandasIndex(Index([0, 1, 2], dtype='int64', name='parse'))</pre></div></li><li class="xr-var-item"><div class="xr-index-name"><div>constituent</div></div><div class="xr-index-preview">PandasIndex</div><div></div><input id="index-273d9569-03b6-47a9-9cfd-59644f401af3" class="xr-index-data-in" type="checkbox"><label for="index-273d9569-03b6-47a9-9cfd-59644f401af3" title="Show/Hide index repr"><svg class="icon xr-icon-database"><use href="#icon-database"></use></svg></label><div class="xr-index-data"><pre>PandasIndex(Index(['NP VP', 'NP VPing', 'NP to VP[+eventive]', 'NP to VP[-eventive]',
       'NP_iobj', 'NP_obj', 'NP_subj', 'PP_for', 'S', 'S[-tense]', 'VP',
       'VPing', 'about NP', 'about whether S', 'for NP to VP', 'so', 'that S',
       'that S[+future]', 'that S[-tense]', 'to VP', 'to VP[+eventive]',
       'to VP[-eventive]', 'whether S', 'whether S[+future]', 'whether to VP',
       'whichNP S', 'whichNP to VP'],
      dtype='object', name='constituent'))</pre></div></li></ul></div></li><li class="xr-section-item"><input id="section-380bcde3-9d77-4db6-8485-c10d3afab330" class="xr-section-summary-in" type="checkbox" disabled=""><label for="section-380bcde3-9d77-4db6-8485-c10d3afab330" class="xr-section-summary" title="Expand/collapse section">Attributes: <span>(0)</span></label><div class="xr-section-inline-details"></div><div class="xr-section-details"><dl class="xr-attrs"></dl></div></li></ul></div></div>
</div>
</div>
</section>
<section id="complex-type-relationships" class="level4">
<h4 class="anchored" data-anchor-id="complex-type-relationships">Complex type relationships</h4>
<p>We’ll assume that the relationship between semantic and syntactic primitive types determines the relationship between complex semantic and syntactic types. Specifically, we’ll assume that for complex semantic type <span class="math inline">\(\mathbf{t}^\text{sem}\)</span> and complex syntactic type <span class="math inline">\(\mathbf{t}^\text{syn}\)</span>, the probability that these types are related is a product of the probabilities that each of there corresponding primitive types (in order) are related:</p>
<p><span class="math display">\[\psi^\text{synsem}_{\mathbf{t}_\text{sem}\mathbf{t}_\text{syn}} \equiv \prod_i \phi^\text{synsem}_{t_i^\text{sem}t_i^\text{syn}}\]</span></p>
<p>One thing to note about <span class="math inline">\(\boldsymbol\Psi^\text{synsem}\)</span> in particular is that it has <span class="math inline">\(2L\)</span> dimensions, where <span class="math inline">\(L\)</span> is the maximum complexity (i.e.&nbsp;length) of the complex types, which we’ll set to <span class="math inline">\(3\)</span> based on the maximum number of constituents in the frame decompositions above.</p>
<p>Similarly, we’ll assume that the relationship between syntactic primitive types and constituents that can realize them determines the relationship between complex syntactic types and frames. If we knew the correct parse of the frame <span class="math inline">\(p\)</span>, we could look at each constituent type <span class="math inline">\(j\)</span>, and if the parse contains it, we look at the probability that any primitive semantic type in <span class="math inline">\(\mathbf{t}\)</span> can map onto it <span class="math inline">\(1 - \prod_i 1 - c_{fpj}^\text{const}\phi^\text{syn}_{t_i^\text{syn}j}\)</span>; otherwise, we ignore it <span class="math inline">\(1-c_{fpj}\)</span>.</p>
<p><span class="math display">\[\bar{\psi}^\text{syn}_{\mathbf{t}^\text{syn}fp} \equiv \prod_j (1-c_{fpj}) + 1 - \prod_i 1 - c_{fpj}^\text{const}\phi^\text{syn}_{t_i^\text{syn}j}\]</span></p>
<p>But since we also need to consider alternative parses for a particular frame <span class="math inline">\(f\)</span>, we additionally need to take the above expression and embed it in a disjunction over parses:</p>
<p><span class="math display">\[\psi^\text{syn}_{\mathbf{t}^\text{syn}f} \equiv 1 - \prod_p 1 - \bar{\psi}^\text{syn}_{\mathbf{t}^\text{syn}fp}\]</span></p>
<p>Effectively, what we are computing here is the probability that, if we look across parses, there is a constituent that could be mapped onto by at least one of the types.</p>
<p>One potential issue with this particular form is that it doesn’t not enforce a one-to-one relationship between syntactic types and constituents. We do enforce that every constituent must be mapped onto by some primitive syntactic type contained in the complex type–but not that each such primitive syntactic type maps onto a single constituent. This is a potential problem, since we don’t want a single syntactic type to map to no or multiple constituents (assuming we’ve correctly laid out all possible parses). We could do this by adding an extra condition to the expression, but we won’t for now. We’ll return to this problem in Module 4, when we consider mappings from thematic roles to syntactic positions.</p>
</section>
<section id="relationship-between-verbs-frames-and-complex-types" class="level4">
<h4 class="anchored" data-anchor-id="relationship-between-verbs-frames-and-complex-types">Relationship between verbs, frames, and complex types</h4>
<p>Finally, we need some way of representing the relationship between a verb and a complex semantic type and the relationship between a frame and a complex syntactic type. We’ll do this by extending <span class="math inline">\(\boldsymbol\lambda_v\)</span> and <span class="math inline">\(\boldsymbol\pi_f\)</span> from White and Rawlins’ model such that <span class="math inline">\(\lambda_{v\mathbf{t}}\)</span> tracks the probability of verb <span class="math inline">\(v\)</span> having complex semantic type <span class="math inline">\(\mathbf{t}\)</span>, and <span class="math inline">\(\pi_{f\mathbf{t}}\)</span> tracks the probability of frame <span class="math inline">\(f\)</span> having complex syntactic type <span class="math inline">\(\mathbf{t}\)</span>. <span class="math inline">\(\boldsymbol\Lambda\)</span> and <span class="math inline">\(\boldsymbol\Pi\)</span> will thus be represented as <em>tensors</em>, with the first dimension corresponding to verb and frame, respectively, and each subsequent dimension <span class="math inline">\(d\)</span> representing a primitive type <span class="math inline">\(t_d\)</span> in position <span class="math inline">\(d\)</span> of complex type <span class="math inline">\(\mathbf{t}\)</span>.</p>
</section>
<section id="definition-of-acceptability" class="level4">
<h4 class="anchored" data-anchor-id="definition-of-acceptability">Definition of acceptability</h4>
<p>Finally, we define the acceptability of a verb <span class="math inline">\(v\)</span> in a frame <span class="math inline">\(f\)</span> in terms of all of these relationships:</p>
<p><span class="math display">\[\alpha_{vf} \equiv 1 - \prod_{\mathbf{t}_\text{sem},\mathbf{t}_\text{syn}} 1 - \lambda_{v\mathbf{t}_\text{sem}}\phi^\text{synsem}_{\mathbf{t}_\text{sem}\mathbf{t}_\text{syn}}\phi^\text{syn}_{\mathbf{t}_\text{syn}f}\pi_{f\mathbf{t}_\text{syn}}\]</span></p>
</section>
</section>
<section id="implementing-the-unconstrained-model" class="level3">
<h3 class="anchored" data-anchor-id="implementing-the-unconstrained-model">Implementing the unconstrained model</h3>
<p>To implement the unconstrained variant of our structured type models, we need to specify some additional parameters: our single <code>n_components</code> parameter gets replaced with a specification for the number of semantic (<code>n_primitive_semantic_types</code>) and syntactic (<code>n_primitive_syntactic_types</code>) primitive types, the <code>max_complex_type_size</code> (which we already said would be 3), and the <code>frame_to_parse_constituent_indicators</code> we constructed earlier.</p>
<div class="cell" data-tags="[]" data-execution_count="21">
<div class="sourceCode cell-code" id="cb20" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="at">@dataclass</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> StructuredSelectionModelParameters(SelectionModelParametersABC):</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>    frame_to_parse_constituent_indicators: ndarray</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>    n_primitive_semantic_types: <span class="bu">int</span></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>    n_primitive_syntactic_types: <span class="bu">int</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>    max_complex_type_size: <span class="bu">int</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb21" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> numpy <span class="im">import</span> prod</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch <span class="im">import</span> Tensor</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> StructuredSelectionModel(Module):</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>    parameter_class <span class="op">=</span> StructuredSelectionModelParameters</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>    data_class <span class="op">=</span> SelectionData</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, parameters: StructuredSelectionModelParameters):</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model_parameters <span class="op">=</span> parameters</span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>        <span class="co"># initialize the verb-complex semantic type probabilities</span></span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._initialize_verb_complex_semantic_type()</span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>        <span class="co"># initialize the frame-complex syntactic type probabilities</span></span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._initialize_frame_complex_syntactic_type()</span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a>        <span class="co"># initialize the semantic-syntactic primitive type map</span></span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._initialize_primitive_type_map()</span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a>        <span class="co"># initialize the syntactic primitive type-constituent map</span></span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a>        syntactic_primitive_type_constituent_map_aux <span class="op">=</span> torch.zeros([</span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a>             parameters.n_primitive_syntactic_types,</span>
<span id="cb21-25"><a href="#cb21-25" aria-hidden="true" tabindex="-1"></a>             parameters.frame_to_parse_constituent_indicators.shape[<span class="dv">2</span>]</span>
<span id="cb21-26"><a href="#cb21-26" aria-hidden="true" tabindex="-1"></a>        ])</span>
<span id="cb21-27"><a href="#cb21-27" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.syntactic_primitive_type_constituent_map_aux <span class="op">=</span> torch.nn.Parameter(</span>
<span id="cb21-28"><a href="#cb21-28" aria-hidden="true" tabindex="-1"></a>            syntactic_primitive_type_constituent_map_aux, </span>
<span id="cb21-29"><a href="#cb21-29" aria-hidden="true" tabindex="-1"></a>            requires_grad<span class="op">=</span><span class="va">True</span></span>
<span id="cb21-30"><a href="#cb21-30" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb21-31"><a href="#cb21-31" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb21-32"><a href="#cb21-32" aria-hidden="true" tabindex="-1"></a>        <span class="co"># initialize the cutpoint distances</span></span>
<span id="cb21-33"><a href="#cb21-33" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.log_jumps <span class="op">=</span> torch.nn.Parameter(</span>
<span id="cb21-34"><a href="#cb21-34" aria-hidden="true" tabindex="-1"></a>            torch.ones([</span>
<span id="cb21-35"><a href="#cb21-35" aria-hidden="true" tabindex="-1"></a>                parameters.n_subj, parameters.n_resp_levels<span class="op">-</span><span class="dv">1</span></span>
<span id="cb21-36"><a href="#cb21-36" aria-hidden="true" tabindex="-1"></a>            ]), </span>
<span id="cb21-37"><a href="#cb21-37" aria-hidden="true" tabindex="-1"></a>            requires_grad<span class="op">=</span><span class="va">True</span></span>
<span id="cb21-38"><a href="#cb21-38" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb21-39"><a href="#cb21-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-40"><a href="#cb21-40" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _initialize_verb_complex_semantic_type(<span class="va">self</span>):</span>
<span id="cb21-41"><a href="#cb21-41" aria-hidden="true" tabindex="-1"></a>        verb_shape <span class="op">=</span> (<span class="va">self</span>.model_parameters.n_verb,) <span class="op">+\</span></span>
<span id="cb21-42"><a href="#cb21-42" aria-hidden="true" tabindex="-1"></a>                     <span class="va">self</span>.complex_semantic_type_shape</span>
<span id="cb21-43"><a href="#cb21-43" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.verb_complex_semantic_type_aux <span class="op">=</span> torch.nn.Parameter(</span>
<span id="cb21-44"><a href="#cb21-44" aria-hidden="true" tabindex="-1"></a>            torch.randn(verb_shape), </span>
<span id="cb21-45"><a href="#cb21-45" aria-hidden="true" tabindex="-1"></a>            requires_grad<span class="op">=</span><span class="va">True</span></span>
<span id="cb21-46"><a href="#cb21-46" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb21-47"><a href="#cb21-47" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb21-48"><a href="#cb21-48" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _initialize_frame_complex_syntactic_type(<span class="va">self</span>):</span>
<span id="cb21-49"><a href="#cb21-49" aria-hidden="true" tabindex="-1"></a>        frame_shape <span class="op">=</span> (<span class="va">self</span>.model_parameters.n_frame,) <span class="op">+\</span></span>
<span id="cb21-50"><a href="#cb21-50" aria-hidden="true" tabindex="-1"></a>                      <span class="va">self</span>.complex_syntactic_type_shape</span>
<span id="cb21-51"><a href="#cb21-51" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.frame_complex_syntactic_type_aux <span class="op">=</span> torch.nn.Parameter(</span>
<span id="cb21-52"><a href="#cb21-52" aria-hidden="true" tabindex="-1"></a>            torch.randn(frame_shape), </span>
<span id="cb21-53"><a href="#cb21-53" aria-hidden="true" tabindex="-1"></a>            requires_grad<span class="op">=</span><span class="va">True</span></span>
<span id="cb21-54"><a href="#cb21-54" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb21-55"><a href="#cb21-55" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb21-56"><a href="#cb21-56" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _initialize_primitive_type_map(<span class="va">self</span>):</span>
<span id="cb21-57"><a href="#cb21-57" aria-hidden="true" tabindex="-1"></a>        primitive_type_map_aux <span class="op">=</span> randn([</span>
<span id="cb21-58"><a href="#cb21-58" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.model_parameters.n_primitive_semantic_types, </span>
<span id="cb21-59"><a href="#cb21-59" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.model_parameters.n_primitive_syntactic_types <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb21-60"><a href="#cb21-60" aria-hidden="true" tabindex="-1"></a>        ])</span>
<span id="cb21-61"><a href="#cb21-61" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.primitive_type_map_aux <span class="op">=</span> torch.nn.Parameter(</span>
<span id="cb21-62"><a href="#cb21-62" aria-hidden="true" tabindex="-1"></a>            primitive_type_map_aux, </span>
<span id="cb21-63"><a href="#cb21-63" aria-hidden="true" tabindex="-1"></a>            requires_grad<span class="op">=</span><span class="va">True</span></span>
<span id="cb21-64"><a href="#cb21-64" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb21-65"><a href="#cb21-65" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb21-66"><a href="#cb21-66" aria-hidden="true" tabindex="-1"></a>    <span class="at">@property</span></span>
<span id="cb21-67"><a href="#cb21-67" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> complex_semantic_type_shape(<span class="va">self</span>):</span>
<span id="cb21-68"><a href="#cb21-68" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> (<span class="va">self</span>.model_parameters.n_primitive_semantic_types<span class="op">+</span><span class="dv">1</span>,) <span class="op">*\</span></span>
<span id="cb21-69"><a href="#cb21-69" aria-hidden="true" tabindex="-1"></a>               <span class="va">self</span>.model_parameters.max_complex_type_size</span>
<span id="cb21-70"><a href="#cb21-70" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-71"><a href="#cb21-71" aria-hidden="true" tabindex="-1"></a>    <span class="at">@property</span></span>
<span id="cb21-72"><a href="#cb21-72" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> complex_syntactic_type_shape(<span class="va">self</span>):</span>
<span id="cb21-73"><a href="#cb21-73" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> (<span class="va">self</span>.model_parameters.n_primitive_syntactic_types<span class="op">+</span><span class="dv">1</span>,)<span class="op">*\</span></span>
<span id="cb21-74"><a href="#cb21-74" aria-hidden="true" tabindex="-1"></a>               <span class="va">self</span>.model_parameters.max_complex_type_size</span>
<span id="cb21-75"><a href="#cb21-75" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb21-76"><a href="#cb21-76" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, data: SelectionData):</span>
<span id="cb21-77"><a href="#cb21-77" aria-hidden="true" tabindex="-1"></a>        verb_frame_prob <span class="op">=</span> <span class="va">self</span>.verb_frame_prob(data.verb, data.frame)</span>
<span id="cb21-78"><a href="#cb21-78" aria-hidden="true" tabindex="-1"></a>        verb_frame_logodds <span class="op">=</span> torch.log(verb_frame_prob) <span class="op">-</span> torch.log(<span class="fl">1.</span> <span class="op">-</span> verb_frame_prob)</span>
<span id="cb21-79"><a href="#cb21-79" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb21-80"><a href="#cb21-80" aria-hidden="true" tabindex="-1"></a>        jumps <span class="op">=</span> <span class="va">self</span>.jumps[data.subj]</span>
<span id="cb21-81"><a href="#cb21-81" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb21-82"><a href="#cb21-82" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> ordered_logistic_likelihood(</span>
<span id="cb21-83"><a href="#cb21-83" aria-hidden="true" tabindex="-1"></a>            verb_frame_logodds, jumps</span>
<span id="cb21-84"><a href="#cb21-84" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb21-85"><a href="#cb21-85" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-86"><a href="#cb21-86" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> verb_frame_prob(<span class="va">self</span>, verb_idx: ndarray, frame_idx: ndarray) <span class="op">-&gt;</span> Tensor:</span>
<span id="cb21-87"><a href="#cb21-87" aria-hidden="true" tabindex="-1"></a>        n_verb <span class="op">=</span> <span class="va">self</span>.model_parameters.n_verb</span>
<span id="cb21-88"><a href="#cb21-88" aria-hidden="true" tabindex="-1"></a>        n_frame <span class="op">=</span> <span class="va">self</span>.model_parameters.n_frame</span>
<span id="cb21-89"><a href="#cb21-89" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb21-90"><a href="#cb21-90" aria-hidden="true" tabindex="-1"></a>        verb_shape <span class="op">=</span> <span class="va">self</span>.complex_semantic_type_shape <span class="op">+\</span></span>
<span id="cb21-91"><a href="#cb21-91" aria-hidden="true" tabindex="-1"></a>                     (<span class="dv">1</span>,) <span class="op">*</span> <span class="bu">len</span>(<span class="va">self</span>.complex_syntactic_type_shape)</span>
<span id="cb21-92"><a href="#cb21-92" aria-hidden="true" tabindex="-1"></a>        frame_shape <span class="op">=</span> (<span class="dv">1</span>,) <span class="op">*</span> <span class="bu">len</span>(<span class="va">self</span>.complex_semantic_type_shape) <span class="op">+\</span></span>
<span id="cb21-93"><a href="#cb21-93" aria-hidden="true" tabindex="-1"></a>                      <span class="va">self</span>.complex_syntactic_type_shape</span>
<span id="cb21-94"><a href="#cb21-94" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb21-95"><a href="#cb21-95" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> verb_idx.shape <span class="op">!=</span> frame_idx.shape:</span>
<span id="cb21-96"><a href="#cb21-96" aria-hidden="true" tabindex="-1"></a>            <span class="cf">raise</span> <span class="pp">ValueError</span></span>
<span id="cb21-97"><a href="#cb21-97" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb21-98"><a href="#cb21-98" aria-hidden="true" tabindex="-1"></a>            resp_shape <span class="op">=</span> verb_idx.shape[<span class="dv">0</span>]</span>
<span id="cb21-99"><a href="#cb21-99" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb21-100"><a href="#cb21-100" aria-hidden="true" tabindex="-1"></a>        <span class="co"># shape for verbs and frames to complex type signatures</span></span>
<span id="cb21-101"><a href="#cb21-101" aria-hidden="true" tabindex="-1"></a>        verb_shape <span class="op">=</span> (resp_shape,) <span class="op">+</span> verb_shape</span>
<span id="cb21-102"><a href="#cb21-102" aria-hidden="true" tabindex="-1"></a>        frame_shape <span class="op">=</span> (resp_shape,) <span class="op">+</span> frame_shape</span>
<span id="cb21-103"><a href="#cb21-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-104"><a href="#cb21-104" aria-hidden="true" tabindex="-1"></a>        <span class="co"># shape with response dimension inserted into map</span></span>
<span id="cb21-105"><a href="#cb21-105" aria-hidden="true" tabindex="-1"></a>        synsem_map_shape <span class="op">=</span> (<span class="dv">1</span>,) <span class="op">+\</span></span>
<span id="cb21-106"><a href="#cb21-106" aria-hidden="true" tabindex="-1"></a>                           <span class="va">self</span>.complex_semantic_type_shape <span class="op">+\</span></span>
<span id="cb21-107"><a href="#cb21-107" aria-hidden="true" tabindex="-1"></a>                           <span class="va">self</span>.complex_syntactic_type_shape</span>
<span id="cb21-108"><a href="#cb21-108" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb21-109"><a href="#cb21-109" aria-hidden="true" tabindex="-1"></a>        <span class="co"># shape for broadcasting syn map</span></span>
<span id="cb21-110"><a href="#cb21-110" aria-hidden="true" tabindex="-1"></a>        syn_map_shape <span class="op">=</span> (resp_shape,) <span class="op">+\</span></span>
<span id="cb21-111"><a href="#cb21-111" aria-hidden="true" tabindex="-1"></a>                        (<span class="dv">1</span>,) <span class="op">*</span> <span class="va">self</span>.model_parameters.max_complex_type_size <span class="op">+\</span></span>
<span id="cb21-112"><a href="#cb21-112" aria-hidden="true" tabindex="-1"></a>                        <span class="va">self</span>.complex_syntactic_type_shape</span>
<span id="cb21-113"><a href="#cb21-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-114"><a href="#cb21-114" aria-hidden="true" tabindex="-1"></a>        <span class="co"># shape for computing prod on all but the reponse dimension</span></span>
<span id="cb21-115"><a href="#cb21-115" aria-hidden="true" tabindex="-1"></a>        flat_shape <span class="op">=</span> (resp_shape, prod(synsem_map_shape))</span>
<span id="cb21-116"><a href="#cb21-116" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb21-117"><a href="#cb21-117" aria-hidden="true" tabindex="-1"></a>        p <span class="op">=</span> <span class="va">self</span>.verb_complex_semantic_type[verb_idx].view(verb_shape) <span class="op">*\</span></span>
<span id="cb21-118"><a href="#cb21-118" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.frame_complex_syntactic_type[frame_idx].view(frame_shape) <span class="op">*\</span></span>
<span id="cb21-119"><a href="#cb21-119" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.complex_synsem_type_map.view(synsem_map_shape) <span class="op">*\</span></span>
<span id="cb21-120"><a href="#cb21-120" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.complex_syn_type_map[frame_idx].view(syn_map_shape)</span>
<span id="cb21-121"><a href="#cb21-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-122"><a href="#cb21-122" aria-hidden="true" tabindex="-1"></a>        acc <span class="op">=</span> <span class="fl">1.</span> <span class="op">-</span> (<span class="fl">1.</span> <span class="op">-</span> p.view(flat_shape)).prod(axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb21-123"><a href="#cb21-123" aria-hidden="true" tabindex="-1"></a>        acc <span class="op">=</span> acc.clamp(<span class="bu">min</span><span class="op">=</span>ZERO, <span class="bu">max</span><span class="op">=</span>ONE)</span>
<span id="cb21-124"><a href="#cb21-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-125"><a href="#cb21-125" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> acc</span>
<span id="cb21-126"><a href="#cb21-126" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb21-127"><a href="#cb21-127" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-128"><a href="#cb21-128" aria-hidden="true" tabindex="-1"></a>    <span class="at">@property</span></span>
<span id="cb21-129"><a href="#cb21-129" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> verb_complex_semantic_type(<span class="va">self</span>) <span class="op">-&gt;</span> Tensor:</span>
<span id="cb21-130"><a href="#cb21-130" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.sigmoid(<span class="va">self</span>.verb_complex_semantic_type_aux)</span>
<span id="cb21-131"><a href="#cb21-131" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-132"><a href="#cb21-132" aria-hidden="true" tabindex="-1"></a>    <span class="at">@property</span></span>
<span id="cb21-133"><a href="#cb21-133" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> frame_complex_syntactic_type(<span class="va">self</span>) <span class="op">-&gt;</span> Tensor:</span>
<span id="cb21-134"><a href="#cb21-134" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.sigmoid(<span class="va">self</span>.frame_complex_syntactic_type_aux)</span>
<span id="cb21-135"><a href="#cb21-135" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-136"><a href="#cb21-136" aria-hidden="true" tabindex="-1"></a>    <span class="at">@property</span></span>
<span id="cb21-137"><a href="#cb21-137" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> primitive_type_map(<span class="va">self</span>) <span class="op">-&gt;</span> Tensor:</span>
<span id="cb21-138"><a href="#cb21-138" aria-hidden="true" tabindex="-1"></a>        prob <span class="op">=</span> torch.sigmoid(</span>
<span id="cb21-139"><a href="#cb21-139" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.primitive_type_map_aux</span>
<span id="cb21-140"><a href="#cb21-140" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb21-141"><a href="#cb21-141" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb21-142"><a href="#cb21-142" aria-hidden="true" tabindex="-1"></a>        <span class="co"># the 0th primitive type is the null primitive type and null </span></span>
<span id="cb21-143"><a href="#cb21-143" aria-hidden="true" tabindex="-1"></a>        <span class="co"># primitive types should only map onto each other</span></span>
<span id="cb21-144"><a href="#cb21-144" aria-hidden="true" tabindex="-1"></a>        null_map <span class="op">=</span> torch.zeros([</span>
<span id="cb21-145"><a href="#cb21-145" aria-hidden="true" tabindex="-1"></a>            <span class="dv">1</span>,</span>
<span id="cb21-146"><a href="#cb21-146" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.model_parameters.n_primitive_syntactic_types <span class="op">+</span> <span class="dv">1</span>,</span>
<span id="cb21-147"><a href="#cb21-147" aria-hidden="true" tabindex="-1"></a>        ])</span>
<span id="cb21-148"><a href="#cb21-148" aria-hidden="true" tabindex="-1"></a>        null_map[<span class="dv">0</span>,<span class="dv">0</span>] <span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb21-149"><a href="#cb21-149" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb21-150"><a href="#cb21-150" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.cat([null_map, prob], axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb21-151"><a href="#cb21-151" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-152"><a href="#cb21-152" aria-hidden="true" tabindex="-1"></a>    <span class="at">@property</span></span>
<span id="cb21-153"><a href="#cb21-153" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> complex_synsem_type_map(<span class="va">self</span>):</span>
<span id="cb21-154"><a href="#cb21-154" aria-hidden="true" tabindex="-1"></a>        <span class="co"># only want to compute the transformation implicit in the</span></span>
<span id="cb21-155"><a href="#cb21-155" aria-hidden="true" tabindex="-1"></a>        <span class="co"># property once</span></span>
<span id="cb21-156"><a href="#cb21-156" aria-hidden="true" tabindex="-1"></a>        primitive_type_map <span class="op">=</span> <span class="va">self</span>.primitive_type_map</span>
<span id="cb21-157"><a href="#cb21-157" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb21-158"><a href="#cb21-158" aria-hidden="true" tabindex="-1"></a>        <span class="co"># the final shape of the complex type map</span></span>
<span id="cb21-159"><a href="#cb21-159" aria-hidden="true" tabindex="-1"></a>        final_shape <span class="op">=</span> primitive_type_map.shape <span class="op">*\</span></span>
<span id="cb21-160"><a href="#cb21-160" aria-hidden="true" tabindex="-1"></a>                      <span class="va">self</span>.model_parameters.max_complex_type_size</span>
<span id="cb21-161"><a href="#cb21-161" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb21-162"><a href="#cb21-162" aria-hidden="true" tabindex="-1"></a>        shape <span class="op">=</span> (primitive_type_map.shape[<span class="dv">0</span>],) <span class="op">+\</span></span>
<span id="cb21-163"><a href="#cb21-163" aria-hidden="true" tabindex="-1"></a>                (<span class="dv">1</span>,) <span class="op">*</span> (<span class="va">self</span>.model_parameters.max_complex_type_size <span class="op">-</span> <span class="dv">1</span>) <span class="op">+\</span></span>
<span id="cb21-164"><a href="#cb21-164" aria-hidden="true" tabindex="-1"></a>                (primitive_type_map.shape[<span class="dv">1</span>],) <span class="op">+\</span></span>
<span id="cb21-165"><a href="#cb21-165" aria-hidden="true" tabindex="-1"></a>                (<span class="dv">1</span>,) <span class="op">*</span> (<span class="va">self</span>.model_parameters.max_complex_type_size <span class="op">-</span> <span class="dv">1</span>)</span>
<span id="cb21-166"><a href="#cb21-166" aria-hidden="true" tabindex="-1"></a>        m <span class="op">=</span> primitive_type_map.view(shape)</span>
<span id="cb21-167"><a href="#cb21-167" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb21-168"><a href="#cb21-168" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="va">self</span>.model_parameters.max_complex_type_size):</span>
<span id="cb21-169"><a href="#cb21-169" aria-hidden="true" tabindex="-1"></a>            shape <span class="op">=</span> (<span class="dv">1</span>,) <span class="op">*</span> i <span class="op">+\</span></span>
<span id="cb21-170"><a href="#cb21-170" aria-hidden="true" tabindex="-1"></a>                    (primitive_type_map.shape[<span class="dv">0</span>],) <span class="op">+\</span></span>
<span id="cb21-171"><a href="#cb21-171" aria-hidden="true" tabindex="-1"></a>                    (<span class="dv">1</span>,) <span class="op">*</span> (<span class="va">self</span>.model_parameters.max_complex_type_size <span class="op">-</span> (i <span class="op">+</span> <span class="dv">1</span>)) <span class="op">+\</span></span>
<span id="cb21-172"><a href="#cb21-172" aria-hidden="true" tabindex="-1"></a>                    (<span class="dv">1</span>,) <span class="op">*</span> i <span class="op">+\</span></span>
<span id="cb21-173"><a href="#cb21-173" aria-hidden="true" tabindex="-1"></a>                    (primitive_type_map.shape[<span class="dv">1</span>],) <span class="op">+\</span></span>
<span id="cb21-174"><a href="#cb21-174" aria-hidden="true" tabindex="-1"></a>                    (<span class="dv">1</span>,) <span class="op">*</span> (<span class="va">self</span>.model_parameters.max_complex_type_size <span class="op">-</span> (i <span class="op">+</span> <span class="dv">1</span>))</span>
<span id="cb21-175"><a href="#cb21-175" aria-hidden="true" tabindex="-1"></a>            m <span class="op">=</span> m <span class="op">*</span> primitive_type_map.view(shape)</span>
<span id="cb21-176"><a href="#cb21-176" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb21-177"><a href="#cb21-177" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> m</span>
<span id="cb21-178"><a href="#cb21-178" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-179"><a href="#cb21-179" aria-hidden="true" tabindex="-1"></a>    <span class="at">@property</span></span>
<span id="cb21-180"><a href="#cb21-180" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> complex_syn_type_map(<span class="va">self</span>):</span>
<span id="cb21-181"><a href="#cb21-181" aria-hidden="true" tabindex="-1"></a>        parse_constituent_indicators <span class="op">=</span> tensor(</span>
<span id="cb21-182"><a href="#cb21-182" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.model_parameters.frame_to_parse_constituent_indicators</span>
<span id="cb21-183"><a href="#cb21-183" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb21-184"><a href="#cb21-184" aria-hidden="true" tabindex="-1"></a>        primitive_type_map <span class="op">=</span> <span class="va">self</span>.syntactic_primitive_type_constituent_map.transpose(<span class="dv">1</span>,<span class="dv">0</span>)</span>
<span id="cb21-185"><a href="#cb21-185" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb21-186"><a href="#cb21-186" aria-hidden="true" tabindex="-1"></a>        <span class="co"># frame x parse x constituent type x primitive type^max_size</span></span>
<span id="cb21-187"><a href="#cb21-187" aria-hidden="true" tabindex="-1"></a>        indicators_shape <span class="op">=</span> parse_constituent_indicators.shape <span class="op">+\</span></span>
<span id="cb21-188"><a href="#cb21-188" aria-hidden="true" tabindex="-1"></a>                           (<span class="dv">1</span>,) <span class="op">*</span> <span class="va">self</span>.model_parameters.max_complex_type_size</span>
<span id="cb21-189"><a href="#cb21-189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-190"><a href="#cb21-190" aria-hidden="true" tabindex="-1"></a>        map_shape <span class="op">=</span> (<span class="dv">1</span>,<span class="dv">1</span>,) <span class="op">+\</span></span>
<span id="cb21-191"><a href="#cb21-191" aria-hidden="true" tabindex="-1"></a>                    primitive_type_map.shape <span class="op">+\</span></span>
<span id="cb21-192"><a href="#cb21-192" aria-hidden="true" tabindex="-1"></a>                    (<span class="dv">1</span>,) <span class="op">*</span> (<span class="va">self</span>.model_parameters.max_complex_type_size <span class="op">-</span> <span class="dv">1</span>)</span>
<span id="cb21-193"><a href="#cb21-193" aria-hidden="true" tabindex="-1"></a>                    </span>
<span id="cb21-194"><a href="#cb21-194" aria-hidden="true" tabindex="-1"></a>        m <span class="op">=</span> <span class="fl">1.</span> <span class="op">-</span> primitive_type_map.view(map_shape) <span class="op">*\</span></span>
<span id="cb21-195"><a href="#cb21-195" aria-hidden="true" tabindex="-1"></a>                 parse_constituent_indicators.view(indicators_shape)</span>
<span id="cb21-196"><a href="#cb21-196" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb21-197"><a href="#cb21-197" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="va">self</span>.model_parameters.max_complex_type_size):</span>
<span id="cb21-198"><a href="#cb21-198" aria-hidden="true" tabindex="-1"></a>            map_shape <span class="op">=</span> (<span class="dv">1</span>,<span class="dv">1</span>,primitive_type_map.shape[<span class="dv">0</span>]) <span class="op">+\</span></span>
<span id="cb21-199"><a href="#cb21-199" aria-hidden="true" tabindex="-1"></a>                        (<span class="dv">1</span>,) <span class="op">*</span> i <span class="op">+\</span></span>
<span id="cb21-200"><a href="#cb21-200" aria-hidden="true" tabindex="-1"></a>                        primitive_type_map.shape[<span class="dv">1</span>:] <span class="op">+\</span></span>
<span id="cb21-201"><a href="#cb21-201" aria-hidden="true" tabindex="-1"></a>                        (<span class="dv">1</span>,) <span class="op">*</span> (<span class="va">self</span>.model_parameters.max_complex_type_size <span class="op">-</span> (i<span class="op">+</span><span class="dv">1</span>))</span>
<span id="cb21-202"><a href="#cb21-202" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb21-203"><a href="#cb21-203" aria-hidden="true" tabindex="-1"></a>            m <span class="op">=</span> m <span class="op">*</span> (<span class="fl">1.</span> <span class="op">-</span> primitive_type_map.view(map_shape) <span class="op">*\</span></span>
<span id="cb21-204"><a href="#cb21-204" aria-hidden="true" tabindex="-1"></a>                          parse_constituent_indicators.view(indicators_shape))</span>
<span id="cb21-205"><a href="#cb21-205" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb21-206"><a href="#cb21-206" aria-hidden="true" tabindex="-1"></a>        prob <span class="op">=</span> <span class="fl">1.</span> <span class="op">-</span> torch.prod(</span>
<span id="cb21-207"><a href="#cb21-207" aria-hidden="true" tabindex="-1"></a>            <span class="fl">1.</span> <span class="op">-</span> torch.prod(</span>
<span id="cb21-208"><a href="#cb21-208" aria-hidden="true" tabindex="-1"></a>                (<span class="fl">1.</span><span class="op">-</span>parse_constituent_indicators.view(indicators_shape)) <span class="op">+</span> </span>
<span id="cb21-209"><a href="#cb21-209" aria-hidden="true" tabindex="-1"></a>                <span class="fl">1.</span> <span class="op">-</span> m, </span>
<span id="cb21-210"><a href="#cb21-210" aria-hidden="true" tabindex="-1"></a>                axis<span class="op">=</span><span class="dv">2</span></span>
<span id="cb21-211"><a href="#cb21-211" aria-hidden="true" tabindex="-1"></a>            ), axis<span class="op">=</span><span class="dv">1</span></span>
<span id="cb21-212"><a href="#cb21-212" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb21-213"><a href="#cb21-213" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb21-214"><a href="#cb21-214" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> prob</span>
<span id="cb21-215"><a href="#cb21-215" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-216"><a href="#cb21-216" aria-hidden="true" tabindex="-1"></a>    <span class="at">@property</span></span>
<span id="cb21-217"><a href="#cb21-217" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> syntactic_primitive_type_constituent_map(<span class="va">self</span>):</span>
<span id="cb21-218"><a href="#cb21-218" aria-hidden="true" tabindex="-1"></a>        prob <span class="op">=</span> torch.sigmoid(</span>
<span id="cb21-219"><a href="#cb21-219" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.syntactic_primitive_type_constituent_map_aux</span>
<span id="cb21-220"><a href="#cb21-220" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb21-221"><a href="#cb21-221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-222"><a href="#cb21-222" aria-hidden="true" tabindex="-1"></a>        <span class="co"># the 0th primitive type is the null primitive type and null </span></span>
<span id="cb21-223"><a href="#cb21-223" aria-hidden="true" tabindex="-1"></a>        <span class="co"># primitive types should not map onto any constitutent, we do </span></span>
<span id="cb21-224"><a href="#cb21-224" aria-hidden="true" tabindex="-1"></a>        <span class="co"># this by multiplying by a special mask</span></span>
<span id="cb21-225"><a href="#cb21-225" aria-hidden="true" tabindex="-1"></a>        null_map <span class="op">=</span> torch.zeros([</span>
<span id="cb21-226"><a href="#cb21-226" aria-hidden="true" tabindex="-1"></a>            <span class="dv">1</span>,</span>
<span id="cb21-227"><a href="#cb21-227" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.model_parameters.frame_to_parse_constituent_indicators.shape[<span class="dv">2</span>]</span>
<span id="cb21-228"><a href="#cb21-228" aria-hidden="true" tabindex="-1"></a>        ])</span>
<span id="cb21-229"><a href="#cb21-229" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb21-230"><a href="#cb21-230" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.cat([null_map, prob], axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb21-231"><a href="#cb21-231" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-232"><a href="#cb21-232" aria-hidden="true" tabindex="-1"></a>    <span class="at">@property</span></span>
<span id="cb21-233"><a href="#cb21-233" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> jumps(<span class="va">self</span>):</span>
<span id="cb21-234"><a href="#cb21-234" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.exp(<span class="va">self</span>.log_jumps)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="implementing-the-constrained-model" class="level3">
<h3 class="anchored" data-anchor-id="implementing-the-constrained-model">Implementing the constrained model</h3>
<p>To implement the constrained variant of the above model, we simply need to alter how the mapping from primitive semantic types to primitive semantic types operates.</p>
<div class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb22" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ConstrainedStructuredSelectionModel(StructuredSelectionModel):</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _initialize_primitive_type_map(<span class="va">self</span>):</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>        primitive_type_rank_sem_aux <span class="op">=</span> randn([</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.model_parameters.n_primitive_semantic_types</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>        ])</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.primitive_type_rank_sem_aux <span class="op">=</span> torch.nn.Parameter(</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>            primitive_type_rank_sem_aux, </span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>            requires_grad<span class="op">=</span><span class="va">True</span></span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>        primitive_type_rank_syn_aux <span class="op">=</span> randn([</span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.model_parameters.n_primitive_syntactic_types</span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a>        ])</span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.primitive_type_rank_syn_aux <span class="op">=</span> torch.nn.Parameter(</span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a>            primitive_type_rank_syn_aux, </span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a>            requires_grad<span class="op">=</span><span class="va">True</span></span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb22-20"><a href="#cb22-20" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.nonnull_sem_to_null_syn_aux <span class="op">=</span> torch.nn.Parameter(</span>
<span id="cb22-21"><a href="#cb22-21" aria-hidden="true" tabindex="-1"></a>            randn(<span class="va">self</span>.model_parameters.n_primitive_semantic_types), </span>
<span id="cb22-22"><a href="#cb22-22" aria-hidden="true" tabindex="-1"></a>            requires_grad<span class="op">=</span><span class="va">True</span></span>
<span id="cb22-23"><a href="#cb22-23" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb22-24"><a href="#cb22-24" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb22-25"><a href="#cb22-25" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.type_rank_log_jumps <span class="op">=</span> torch.nn.Parameter(</span>
<span id="cb22-26"><a href="#cb22-26" aria-hidden="true" tabindex="-1"></a>            randn(</span>
<span id="cb22-27"><a href="#cb22-27" aria-hidden="true" tabindex="-1"></a>                <span class="bu">min</span>(</span>
<span id="cb22-28"><a href="#cb22-28" aria-hidden="true" tabindex="-1"></a>                    <span class="va">self</span>.model_parameters.n_primitive_syntactic_types <span class="op">-</span> <span class="dv">1</span>, </span>
<span id="cb22-29"><a href="#cb22-29" aria-hidden="true" tabindex="-1"></a>                    <span class="va">self</span>.model_parameters.n_primitive_syntactic_types <span class="op">-</span> <span class="dv">1</span></span>
<span id="cb22-30"><a href="#cb22-30" aria-hidden="true" tabindex="-1"></a>                )</span>
<span id="cb22-31"><a href="#cb22-31" aria-hidden="true" tabindex="-1"></a>            ), </span>
<span id="cb22-32"><a href="#cb22-32" aria-hidden="true" tabindex="-1"></a>            requires_grad<span class="op">=</span><span class="va">True</span></span>
<span id="cb22-33"><a href="#cb22-33" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb22-34"><a href="#cb22-34" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb22-35"><a href="#cb22-35" aria-hidden="true" tabindex="-1"></a>    <span class="at">@property</span></span>
<span id="cb22-36"><a href="#cb22-36" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> primitive_type_map(<span class="va">self</span>) <span class="op">-&gt;</span> Tensor:</span>
<span id="cb22-37"><a href="#cb22-37" aria-hidden="true" tabindex="-1"></a>        rank_jumps <span class="op">=</span> torch.exp(<span class="va">self</span>.type_rank_log_jumps)</span>
<span id="cb22-38"><a href="#cb22-38" aria-hidden="true" tabindex="-1"></a>        rank_cuts <span class="op">=</span> torch.cumsum(rank_jumps, axis<span class="op">=</span><span class="dv">0</span>) <span class="op">-</span> rank_jumps[<span class="dv">0</span>]</span>
<span id="cb22-39"><a href="#cb22-39" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb22-40"><a href="#cb22-40" aria-hidden="true" tabindex="-1"></a>        prob_sem <span class="op">=</span> ordered_logistic_likelihood(</span>
<span id="cb22-41"><a href="#cb22-41" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.primitive_type_rank_sem_aux, </span>
<span id="cb22-42"><a href="#cb22-42" aria-hidden="true" tabindex="-1"></a>            rank_cuts[<span class="va">None</span>,:]</span>
<span id="cb22-43"><a href="#cb22-43" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb22-44"><a href="#cb22-44" aria-hidden="true" tabindex="-1"></a>        prob_syn <span class="op">=</span> ordered_logistic_likelihood(</span>
<span id="cb22-45"><a href="#cb22-45" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.primitive_type_rank_syn_aux, </span>
<span id="cb22-46"><a href="#cb22-46" aria-hidden="true" tabindex="-1"></a>            rank_cuts[<span class="va">None</span>,:]</span>
<span id="cb22-47"><a href="#cb22-47" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb22-48"><a href="#cb22-48" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb22-49"><a href="#cb22-49" aria-hidden="true" tabindex="-1"></a>        prob_prim <span class="op">=</span> (prob_sem[:,<span class="va">None</span>,:] <span class="op">*</span> prob_syn[<span class="va">None</span>,:,:]).<span class="bu">sum</span>(<span class="dv">2</span>)</span>
<span id="cb22-50"><a href="#cb22-50" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb22-51"><a href="#cb22-51" aria-hidden="true" tabindex="-1"></a>        null_sem_to_nonnull_syn <span class="op">=</span> torch.zeros([</span>
<span id="cb22-52"><a href="#cb22-52" aria-hidden="true" tabindex="-1"></a>            <span class="dv">1</span>,</span>
<span id="cb22-53"><a href="#cb22-53" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.model_parameters.n_primitive_syntactic_types <span class="op">+</span> <span class="dv">1</span>,</span>
<span id="cb22-54"><a href="#cb22-54" aria-hidden="true" tabindex="-1"></a>        ])</span>
<span id="cb22-55"><a href="#cb22-55" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb22-56"><a href="#cb22-56" aria-hidden="true" tabindex="-1"></a>        null_sem_to_nonnull_syn[<span class="dv">0</span>,<span class="dv">0</span>] <span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb22-57"><a href="#cb22-57" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb22-58"><a href="#cb22-58" aria-hidden="true" tabindex="-1"></a>        nonnull_sem_to_null_syn <span class="op">=</span> torch.sigmoid(</span>
<span id="cb22-59"><a href="#cb22-59" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.nonnull_sem_to_null_syn_aux</span>
<span id="cb22-60"><a href="#cb22-60" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb22-61"><a href="#cb22-61" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb22-62"><a href="#cb22-62" aria-hidden="true" tabindex="-1"></a>        <span class="co"># the 0th primitive type is the null primitive type and null </span></span>
<span id="cb22-63"><a href="#cb22-63" aria-hidden="true" tabindex="-1"></a>        <span class="co"># primitive types should only map onto each other, we do this</span></span>
<span id="cb22-64"><a href="#cb22-64" aria-hidden="true" tabindex="-1"></a>        <span class="co"># by multiplying by a special mask</span></span>
<span id="cb22-65"><a href="#cb22-65" aria-hidden="true" tabindex="-1"></a>        prob <span class="op">=</span> torch.cat([</span>
<span id="cb22-66"><a href="#cb22-66" aria-hidden="true" tabindex="-1"></a>            nonnull_sem_to_null_syn[:,<span class="va">None</span>],</span>
<span id="cb22-67"><a href="#cb22-67" aria-hidden="true" tabindex="-1"></a>            prob_prim</span>
<span id="cb22-68"><a href="#cb22-68" aria-hidden="true" tabindex="-1"></a>        ], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb22-69"><a href="#cb22-69" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb22-70"><a href="#cb22-70" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.cat([null_sem_to_nonnull_syn, prob], axis<span class="op">=</span><span class="dv">0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="evaluating-the-models" class="level2">
<h2 class="anchored" data-anchor-id="evaluating-the-models">Evaluating the models</h2>
<p>To evaluate our models, we will use the <a href="http://megaattitude.io/projects/mega-orientation/">MegaOrientation dataset</a> <span class="citation" data-cites="moon_source_2020">(<a href="#ref-moon_source_2020" role="doc-biblioref">Moon and White 2020</a>)</span>.</p>
<div class="cell" data-tags="[]">
<details>
<summary>Download the MegaOrientation data</summary>
<div class="sourceCode cell-code" id="cb23" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>wget http:<span class="op">//</span>megaattitude.io<span class="op">/</span>projects<span class="op">/</span>mega<span class="op">-</span>orientation<span class="op">/</span>mega<span class="op">-</span>orientation<span class="op">-</span>v1<span class="fl">.1</span>.<span class="bu">zip</span> <span class="op">-</span>P data<span class="op">/</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>unzip data<span class="op">/</span>mega<span class="op">-</span>orientation<span class="op">-</span>v1<span class="fl">.1</span>.<span class="bu">zip</span> <span class="op">-</span>d data<span class="op">/</span></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>data_dir <span class="op">=</span> <span class="st">"./data/mega-orientation-v1.1/"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>This dataset aims to capture aspects of the temporal interpretation of sentences containing non-finite complement clauses. Specifically, it focuses on the <em>temporal orientation</em> of the event or state expressed by the matrix predicate relative to the event or state expressed by a predicate in a clause embedded by it. <span id="exm-regret"></span> <span id="exm-want"></span> For instance, in (10), we interpret the regretting to hold after the leaving, while in (11), we interpret the wanting to hold before the leaving.</p>
<ol start="10" class="example" type="1">
<li>Jo regretted leaving.</li>
<li>Jo wanted to leave.</li>
</ol>
<p>One common diagnostic for this orientation involves manipulation of temporal adverbs. <span id="exm-regret-good"></span> <span id="exm-regret-bad"></span> For instance, (12) is good, while (13) is weird.</p>
<ol start="12" class="example" type="1">
<li>Jo will regret leaving yesterday.</li>
<li>Jo regretted leaving tomorrow.</li>
</ol>
<p><span id="exm-want-bad"></span> <span id="exm-want-good"></span> Conversely, (14) is weird, while (15) is not.</p>
<ol start="14" class="example" type="1">
<li>Jo will want to leave yesterday.</li>
<li>Jo wanted to leave tomorrow.</li>
</ol>
<p>Building on MegaAcceptability, MegaOrientation captures these sorts of judgments.</p>
<div class="cell" data-tags="[]" data-execution_count="37">
<div class="sourceCode cell-code" id="cb24" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>data_orientation <span class="op">=</span> load_data(os.path.join(data_dir, <span class="st">"mega-orientation-v1.1.tsv"</span>))</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>data_orientation[[<span class="st">"participant"</span>, <span class="st">"verb"</span>, <span class="st">"frame"</span>, <span class="st">"orientation"</span>, <span class="st">"sentence"</span>, <span class="st">"response"</span>]].head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre data-code-line-numbers=""><code>The full dataset has 44160 datapoints.
Removing 0 responses from nonnative speakers.
Removing 0 NA responses.</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="37">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">participant</th>
<th data-quarto-table-cell-role="th">verb</th>
<th data-quarto-table-cell-role="th">frame</th>
<th data-quarto-table-cell-role="th">orientation</th>
<th data-quarto-table-cell-role="th">sentence</th>
<th data-quarto-table-cell-role="th">response</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>718</td>
<td>spook</td>
<td>NP was _ed to VP[+eventive]</td>
<td>future</td>
<td>Someone was spooked to do something in the fut...</td>
<td>4</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>718</td>
<td>envy</td>
<td>NP was _ed to VP[-eventive]</td>
<td>future</td>
<td>Someone was envied to have something in the fu...</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>718</td>
<td>confirm</td>
<td>NP _ed VPing</td>
<td>past</td>
<td>Someone will confirm doing something in the past.</td>
<td>2</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>718</td>
<td>remind</td>
<td>NP was _ed to VP[-eventive]</td>
<td>future</td>
<td>Someone was reminded to have something in the ...</td>
<td>3</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>718</td>
<td>instigate</td>
<td>NP _ed VPing</td>
<td>future</td>
<td>Someone instigated doing something in the future.</td>
<td>2</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>This dataset is useful for our purposes because it captures a phenomenon that, as noted in <span class="citation" data-cites="lohninger_typology_2020">Lohninger and Wurmbrand (<a href="#ref-lohninger_typology_2020" role="doc-biblioref">to appear</a>)</span>, is thought to be associated with clause size: the “smaller” a clause is, the more dependent its temporal interpretation is on the temporal interpretation of the matrix clause. So insofar as a model that incorporates an ordering on semantic and syntactic types is a good model, we should expect it to predict these judgments just as well or better than a model that does not assume the ordering.</p>
<p>To implement this evaluation, we will use the <span class="math inline">\(\boldsymbol\Lambda\)</span> and <span class="math inline">\(\boldsymbol\Pi\)</span> matrices we learn as a source of predictors in a mixed effects ordered logistic regression.</p>
</section>
<section id="summing-up" class="level2">
<h2 class="anchored" data-anchor-id="summing-up">Summing up</h2>
<p>We started with a relatively straightforward variant of matrix factorization as our model for inducing selection and augmented that out to a model that recognizes structured semantic and syntactic types. In the next section, we’ll fit these models and probe the representations they learn.</p>



</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" role="list">
<div id="ref-cristofaro_subordination_2005" class="csl-entry" role="listitem">
Cristofaro, Sonia, and Sonia Cristofaro. 2005. <em>Subordination</em>. Oxford <span>Studies</span> in <span>Typology</span> and <span>Linguistic</span> <span>Theory</span>. Oxford, New York: Oxford University Press.
</div>
<div id="ref-dixon_basic_2009" class="csl-entry" role="listitem">
Dixon, R. M. W. 2009. <em>Basic <span>Linguistic</span> <span>Theory</span> <span>Volume</span> 2: <span>Grammatical</span> <span>Topics</span></em>. Oxford, New York: Oxford University Press.
</div>
<div id="ref-givon_binding_1980" class="csl-entry" role="listitem">
Givón, T. 1980. <span>“The <span>Binding</span> <span>Hierarchy</span> and the <span>Typology</span> of <span>Complements</span>:”</span> <em>Studies in Language</em> 4 (3): 333–77. <a href="https://doi.org/10.1075/sl.4.3.03giv">https://doi.org/10.1075/sl.4.3.03giv</a>.
</div>
<div id="ref-grimshaw_complement_1979" class="csl-entry" role="listitem">
Grimshaw, Jane. 1979. <span>“Complement Selection and the Lexicon.”</span> <em>Linguistic Inquiry</em> 10 (2): 279–326.
</div>
<div id="ref-lohninger_typology_2020" class="csl-entry" role="listitem">
Lohninger, Magdalena, and Susanne Wurmbrand. to appear. <span>“Typology of Complement Clauses.”</span> Edited by Anton Benz, Werner Frey, Manfred Krifka, Thomas McFadden, and Marzena Żygis. <em>Handbook of Clausal Embedding</em>, to appear, 1–53.
</div>
<div id="ref-miettinen_recent_2020" class="csl-entry" role="listitem">
Miettinen, Pauli, and Stefan Neumann. 2020. <span>“Recent Developments in Boolean Matrix Factorization.”</span> <a href="https://arxiv.org/abs/2012.03127">https://arxiv.org/abs/2012.03127</a>.
</div>
<div id="ref-montague_proper_1973" class="csl-entry" role="listitem">
Montague, Richard. 1973. <span>“The Proper Treatment of Quantification in Ordinary <span>English</span>.”</span> In <em>Approaches to <span>Natural</span> <span>Language</span></em>, 221–42. Springer.
</div>
<div id="ref-moon_source_2020" class="csl-entry" role="listitem">
Moon, Ellise, and Aaron Steven White. 2020. <span>“The Source of Nonfinite Temporal Interpretation.”</span> In <em>Proceedings of the 50th <span>Annual</span> <span>Meeting</span> of the <span>North</span> <span>East</span> <span>Linguistic</span> <span>Society</span></em>, edited by Mariam Asatryan, Yixiao Song, and Ayana Whitmal, 3:11–24. Amherst, MA: GLSA Publications.
</div>
<div id="ref-noonan_complementation_2007" class="csl-entry" role="listitem">
Noonan, Michael. 2007. <span>“Complementation.”</span> In <em>Language Typology and Syntactic Description: <span>Volume</span> 2, <span>Complex</span> Constructions</em>, edited by Timothy Shopen, 2nd ed., 52–150. Cambridge: Cambridge University Press.
</div>
<div id="ref-paatero_positive_1994" class="csl-entry" role="listitem">
Paatero, Pentti, and Unto Tapper. 1994. <span>“Positive Matrix Factorization: <span>A</span> Non-Negative Factor Model with Optimal Utilization of Error Estimates of Data Values.”</span> <em>Environmetrics</em> 5 (2): 111–26. <a href="https://doi.org/10.1002/env.3170050203">https://doi.org/10.1002/env.3170050203</a>.
</div>
<div id="ref-pearson_lines_1901" class="csl-entry" role="listitem">
Pearson, Karl. 1901. <span>“On Lines and Planes of Closest Fit to Systems of Points in Space.”</span> <em>The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science</em> 2 (11): 559–72. <a href="https://doi.org/10.1080/14786440109462720">https://doi.org/10.1080/14786440109462720</a>.
</div>
<div id="ref-pesetsky_zero_1991" class="csl-entry" role="listitem">
Pesetsky, David. 1991. <span>“Zero Syntax: Vol. 2: <span>Infinitives</span>.”</span>
</div>
<div id="ref-ramchand_deriving_2014" class="csl-entry" role="listitem">
Ramchand, Gillian, and Peter Svenonius. 2014. <span>“Deriving the Functional Hierarchy.”</span> <em>Language Sciences</em>, New <span>Directions</span> in <span>Universal</span> <span>Grammar</span>, 46 (November): 152–74. <a href="https://doi.org/10.1016/j.langsci.2014.06.013">https://doi.org/10.1016/j.langsci.2014.06.013</a>.
</div>
<div id="ref-steedman_combinatory_2011" class="csl-entry" role="listitem">
Steedman, Mark, and Jason Baldridge. 2011. <span>“Combinatory <span>Categorial</span> <span>Grammar</span>.”</span> In <em>Non-<span>Transformational</span> <span>Syntax</span></em>, 181–224. John Wiley &amp; Sons, Ltd. <a href="https://doi.org/10.1002/9781444395037.ch5">https://doi.org/10.1002/9781444395037.ch5</a>.
</div>
<div id="ref-white_computational_2016" class="csl-entry" role="listitem">
White, Aaron Steven, and Kyle Rawlins. 2016. <span>“A Computational Model of <span>S</span>-Selection.”</span> Edited by Mary Moroney, Carol-Rose Little, Jacob Collard, and Dan Burgdorf. <em>Semantics and Linguistic Theory</em> 26 (October): 641–63. <a href="https://doi.org/10.3765/salt.v26i0.3819">https://doi.org/10.3765/salt.v26i0.3819</a>.
</div>
<div id="ref-white_frequency_2020" class="csl-entry" role="listitem">
———. 2020. <span>“Frequency, Acceptability, and Selection: <span>A</span> Case Study of Clause-Embedding.”</span> <em>Glossa: A Journal of General Linguistics</em> 5 (1): 105. <a href="https://doi.org/10.5334/gjgl.1001">https://doi.org/10.5334/gjgl.1001</a>.
</div>
<div id="ref-wurmbrand_implicational_2023" class="csl-entry" role="listitem">
Wurmbrand, Susanne, and Magdalena Lohninger. 2023. <span>“An Implicational Universal in Complementation–Theogrohretical Insights and Empirical Progress.”</span> In <em>Propositional <span>Arguments</span> in <span>Cross</span>-<span>Linguistic</span> <span>Research</span>: <span>Theoretical</span> and <span>Empirical</span> <span>Issues</span></em>, edited by Hartmann, Jutta M. and Wöllstein, Angelika, 84:183–231. Studien Zur Deutschen <span>Sprache</span>. Tübingen: Gunter Narr Verlag.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>In fact, not all predicates found in their sentences are necessarily verbs. Some–e.g.&nbsp;<em>annoy</em>–are likely to be (deverbal) adjectives in some frames. We’ll continue to just refer to these predicates as verbs.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>In fact, when <span class="math inline">\(\mathbf{U}\)</span> and <span class="math inline">\(\mathbf{V}\)</span> are boolean matrices and we do this swap, the problem is often referred to as boolean matrix factorization <span class="citation" data-cites="miettinen_recent_2020">(see <a href="#ref-miettinen_recent_2020" role="doc-biblioref">Miettinen and Neumann 2020</a> and references therein)</span>.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>We could alternatively learn a positive scaling term <span class="math inline">\(\beta\)</span> for <span class="math inline">\(\alpha_{vf}\)</span> that would expand it to be on <span class="math inline">\([0, \beta]\)</span>, but then we introduce an additional parameter that we need to worry about futzing with.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>STAN does use <a href="https://mc-stan.org/docs/reference-manual/stochastic-gradient-ascent.html">stochastic gradient ascent</a> in its implementation of automatic differentiation <a href="https://en.wikipedia.org/wiki/Variational_Bayesian_methods">variational inference</a> (ADVI). But since I want to demonstrate MAP estimation and how to implement it in the popular <code>torch</code> framework here, I’m not going to use STAN’s implementation of variational inference.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>There are other ways to set things up in <code>torch</code>, but this general approach is relatively common.<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://giscus.app/client.js" data-repo="aaronstevenwhite/representation-learning-course" data-repo-id="R_kgDOJsrvfQ" data-category="General" data-category-id="DIC_kwDOJsrvfc4CXIDs" data-mapping="title" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="top" data-theme="light" data-lang="en" crossorigin="anonymous" async="">
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../selection/a-brief-primer-on-gradient-based-optimization.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">A brief primer on gradient-based optimization</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../selection/model-fitting-and-comparison.html" class="pagination-link">
        <span class="nav-page-text">Model fitting and comparison</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



<script src="../site_libs/quarto-contrib/line-highlight-1.0.0/line-highlight.js" defer="true"></script>
</body></html>