@booksection{chomsky_current_1964,
  title={Current issues in linguistic theory},
  author={Chomsky, Noam},
  journal={The Structure of Language},
  pages={50--118},
  year={1964},
  editor={J. Fodor and J. Katz},
  publisher={Prentice Hall},
  address={New York}
}

@book{chomsky_aspects_1965,
    address = {Cambridge, MA},
    title = {Aspects of the {Theory} of {Syntax}},
    isbn = {0-262-53007-4},
    publisher = {MIT Press},
    author = {Chomsky, Noam},
    year = {1965}
}

@book{chomsky_barriers_1986,
  title={Barriers},
  author={Chomsky, Noam},
  year={1986},
  publisher={MIT Press},
  address={Cambridge, MA}
}

@book{schütze_gramaticality_2016,
    author = {Schütze, Carson T.},
    title = {The empirical base of linguistics},
    year = {2016},
    series = {Classics in Linguistics},
    number = {2},
    address = {Berlin},
    publisher = {Language Science Press},
    doi = {10.17169/langsci.b89.100},
    doi = {10.17169/langsci.b89.101}
}

@book{davis_semantics_2004,
    author = {Davis, Steven and Gillon, Brendan S},
    address = {New York},
    booktitle = {Semantics: A Reader},
    keywords = {Language arts ; Linguistics ; Philosophy of language ; Pragmatics ; Semantics ; Semantics (Philosophy)},
    language = {eng},
    isbn = {9780195136975},
    publisher = {Oxford University Press},
    title = {Semantics: A Reader},
    year = {2004},
}

@article{higginbotham_semantics_1985,
	title = {On {Semantics}},
	volume = {16},
	number = {4},
	urldate = {2020-11-18},
	journal = {Linguistic Inquiry},
	author = {Higginbotham, James},
	year = {1985},
	pages = {547--593},
}

@article{berwick_poverty_2011,
	title = {Poverty of the {Stimulus} {Revisited}},
	volume = {35},
	doi = {10.1111/j.1551-6709.2011.01189.x},
	abstract = {A central goal of modern generative grammar has been to discover invariant properties of human languages that reflect “the innate schematism of mind that is applied to the data of experience” and that “might reasonably be attributed to the organism itself as its contribution to the task of the acquisition of knowledge” (Chomsky, 1971). Candidates for such invariances include the structure dependence of grammatical rules, and in particular, certain constraints on question formation. Various “poverty of stimulus” (POS) arguments suggest that these invariances reflect an innate human endowment, as opposed to common experience: Such experience warrants selection of the grammars acquired only if humans assume, a priori, that selectable grammars respect substantive constraints. Recently, several researchers have tried to rebut these POS arguments. In response, we illustrate why POS arguments remain an important source of support for appeal to a priori structure-dependent constraints on the grammars that humans naturally acquire.},
	language = {en},
	number = {7},
	journal = {Cognitive Science},
	author = {Berwick, Robert C. and Pietroski, Paul and Yankama, Beracah and Chomsky, Noam},
	year = {2011},
	pages = {1207--1242},
}

@phdthesis{ross_constraints_1967,
  title={Constraints on variables in syntax},
  author={Ross, John Robert},
  year={1967},
  school={Massachusetts Institute of Technology},
}

@incollection{white_lexically_2019,
	title = {Lexically triggered veridicality inferences},
	volume = {22},
	url = {https://doi.org/10.1075/hop.22.lex4},
	booktitle = {Handbook of {Pragmatics}},
	publisher = {John Benjamins Publishing Company},
	author = {White, Aaron Steven},
	year = {2019},
	pages = {115--148}
}

@inbook{sprouse_island_2021, 
  place={Cambridge}, 
  series={Cambridge Handbooks in Language and Linguistics}, 
  title={Island Effects}, 
  DOI={10.1017/9781108569620.010}, 
  booktitle={The Cambridge Handbook of Experimental Syntax}, 
  publisher={Cambridge University Press}, 
  author={Sprouse, Jon and Villata, Sandra}, 
  editor={Goodall, Grant}, 
  year={2021}, 
  pages={227–257}, 
  collection={Cambridge Handbooks in Language and Linguistics}
}

@inbook{sprouse_acceptability_2018,
  url = {https://doi.org/10.1515/9781501506925-199},
  title = {Acceptability judgments and grammaticality, prospects and challenges},
  booktitle = {Syntactic Structures after 60 Years},
  booktitle = {The Impact of the Chomskyan Revolution in Linguistics},
  author = {Jon Sprouse},
  editor = {Norbert Hornstein and Howard Lasnik and Pritty Patel-Grosz and Charles Yang},
  publisher = {De Gruyter Mouton},
  address = {Berlin, Boston},
  pages = {195--224},
  doi = {doi:10.1515/9781501506925-199},
  isbn = {9781501506925},
  year = {2018},
  lastchecked = {2023-05-06}
}

@article{sprouse_experimental_2016,
  title={Experimental syntax and the variation of island effects in English and Italian},
  author={Sprouse, Jon and Caponigro, Ivano and Greco, Ciro and Cecchetto, Carlo},
  journal={Natural Language \& Linguistic Theory},
  volume={34},
  pages={307--344},
  year={2016},
  publisher={Springer},
  doi = {10.1007/s11049-015-9286-8},
}

@book{gelman_bayesian_2013,
  title={Bayesian Data Analysis},
  author={Gelman, Andrew and Carlin, John B. and Stern, Hal S. and Dunson, David B and Vehtari, Aki and Rubin, Donald B.},
  year={2013},
  publisher={CRC Press},
  address={New York}
}


@article{gelman_understanding_2014,
  title = {Understanding predictive information criteria for {Bayesian} models},
  volume = {24},
  issn = {1573-1375},
  url = {https://doi.org/10.1007/s11222-013-9416-2},
  doi = {10.1007/s11222-013-9416-2},
  abstract = {We review the Akaike, deviance, and Watanabe-Akaike information criteria from a Bayesian perspective, where the goal is to estimate expected out-of-sample-prediction error using a bias-corrected adjustment of within-sample error. We focus on the choices involved in setting up these measures, and we compare them in three simple examples, one theoretical and two applied. The contribution of this paper is to put all these information criteria into a Bayesian predictive context and to better understand, through small examples, how these methods can apply in practice.},
  language = {en},
  number = {6},
  urldate = {2023-06-19},
  journal = {Statistics and Computing},
  author = {Gelman, Andrew and Hwang, Jessica and Vehtari, Aki},
  month = nov,
  year = {2014},
  keywords = {AIC, Bayes, Cross-validation, DIC, Prediction, WAIC},
  pages = {997--1016},
}


@article{vehtari_practical_2017,
  title = {Practical {Bayesian} model evaluation using leave-one-out cross-validation and {WAIC}},
  volume = {27},
  issn = {1573-1375},
  url = {https://doi.org/10.1007/s11222-016-9696-4},
  doi = {10.1007/s11222-016-9696-4},
  abstract = {Leave-one-out cross-validation (LOO) and the widely applicable information criterion (WAIC) are methods for estimating pointwise out-of-sample prediction accuracy from a fitted Bayesian model using the log-likelihood evaluated at the posterior simulations of the parameter values. LOO and WAIC have various advantages over simpler estimates of predictive error such as AIC and DIC but are less used in practice because they involve additional computational steps. Here we lay out fast and stable computations for LOO and WAIC that can be performed using existing simulation draws. We introduce an efficient computation of LOO using Pareto-smoothed importance sampling (PSIS), a new procedure for regularizing importance weights. Although WAIC is asymptotically equal to LOO, we demonstrate that PSIS-LOO is more robust in the finite case with weak priors or influential observations. As a byproduct of our calculations, we also obtain approximate standard errors for estimated predictive errors and for comparison of predictive errors between two models. We implement the computations in an R package called loo and demonstrate using models fit with the Bayesian inference package Stan.},
  language = {en},
  number = {5},
  urldate = {2023-06-19},
  journal = {Statistics and Computing},
  author = {Vehtari, Aki and Gelman, Andrew and Gabry, Jonah},
  month = sep,
  year = {2017},
  keywords = {Bayesian computation, K-fold cross-validation, Leave-one-out cross-validation (LOO), Pareto smoothed importance sampling (PSIS), Stan, Widely applicable information criterion (WAIC)},
  pages = {1413--1432},
  file = {Submitted Version:/Users/awhite48/Zotero/storage/9VAU4A6W/Vehtari et al. - 2017 - Practical Bayesian model evaluation using leave-on.pdf:application/pdf},
}


@article{watanabe_asymptotic_2010,
  author = {Watanabe, Sumio},
  title = {Asymptotic Equivalence of Bayes Cross Validation and Widely Applicable Information Criterion in Singular Learning Theory},
  year = {2010},
  issue_date = {3/1/2010},
  volume = {11},
  issn = {1532-4435},
  abstract = {In regular statistical models, the leave-one-out cross-validation is asymptotically equivalent to the Akaike information criterion. However, since many learning machines are singular statistical models, the asymptotic behavior of the cross-validation remains unknown. In previous studies, we established the singular learning theory and proposed a widely applicable information criterion, the expectation value of which is asymptotically equal to the average Bayes generalization loss. In the present paper, we theoretically compare the Bayes cross-validation loss and the widely applicable information criterion and prove two theorems. First, the Bayes cross-validation loss is asymptotically equivalent to the widely applicable information criterion as a random variable. Therefore, model selection and hyperparameter optimization using these two values are asymptotically equivalent. Second, the sum of the Bayes generalization error and the Bayes cross-validation error is asymptotically equal to 2λ/n, where λ is the real log canonical threshold and n is the number of training samples. Therefore the relation between the cross-validation error and the generalization error is determined by the algebraic geometrical structure of a learning machine. We also clarify that the deviance information criteria are different from the Bayes cross-validation and the widely applicable information criterion.},
  journal = {Journal of Machine Learning Research},
  month = {dec},
  pages = {3571–3594},
  numpages = {24}
}

@article{degen_factive_2022,
  title={Are there factive predicates? An empirical investigation},
  author={Degen, Judith and Tonhauser, Judith},
  journal={Language},
  volume={98},
  number={3},
  pages={552--591},
  year={2022},
  publisher={Linguistic Society of America},
  doi = {10.1353/lan.0.0271}
}

@article{degen_prior_2021,
  author = {Degen, Judith and Tonhauser, Judith},
  title = "{Prior Beliefs Modulate Projection}",
  journal = {Open Mind},
  volume = {5},
  pages = {59-70},
  year = {2021},
  month = {09},
  abstract = "{Beliefs about the world affect language processing and interpretation in several empirical domains. In two experiments, we tested whether subjective prior beliefs about the probability of utterance content modulate projection, that is, listeners’ inferences about speaker commitment to that content. We find that prior beliefs predict projection at both the group and the participant level: the higher the prior belief in a content, the more speakers are taken to be committed to it. This result motivates the integration of formal analyses of projection with cognitive theories of language understanding.}",
  issn = {2470-2986},
  doi = {10.1162/opmi_a_00042},
}

@article{lohninger_typology_2020,
  title={Typology of complement clauses},
  author={Lohninger, Magdalena and Wurmbrand, Susanne},
  editor = {Anton Benz and Werner Frey and Manfred Krifka and Thomas McFadden and Marzena Żygis},
  journal={Handbook of Clausal Embedding},
  pages={1--53},
  year={to appear},
  address = {Oxford},
  publisher={Oxford University Press},
}

@article{white_computational_2016,
	title = {A computational model of {S}-selection},
	volume = {26},
	issn = {2163-5951},
	doi = {10.3765/salt.v26i0.3819},
	abstract = {We develop a probabilistic model of S(emantic)-selection that encodes both the notion of systematic mappings from semantic type signature to syntactic distribution—i.e., projection rules—and the notion of selectional noise—e.g., C(ategory)-selection, L(exical)-selection, and/or other independent syntactic processes. We train this model on data from a large-scale judgment study assessing the acceptability of 1,000 English clause-taking verbs in 50 distinct syntactic frames, finding that this model infers coherent semantic type signatures. We focus in on type signatures relevant to interrogative and declarative selection, arguing that our results suggest a principled split between cognitive verbs, which select distinct proposition and question types, and communicative verbs, which select a single hybrid type.},
	language = {en},
	journal = {Semantics and Linguistic Theory},
	author = {White, Aaron Steven and Rawlins, Kyle},
	editor = {{Mary Moroney} and {Carol-Rose Little} and {Jacob Collard} and {Dan Burgdorf}},
	month = oct,
	year = {2016},
	pages = {641--663},
}

@article{white_frequency_2020,
	title = {Frequency, acceptability, and selection: {A} case study of clause-embedding},
	volume = {5},
	issn = {2397-1835},
	shorttitle = {Frequency, acceptability, and selection},
	url = {http://www.glossa-journal.org//article/10.5334/gjgl.1001/},
	doi = {10.5334/gjgl.1001},
	language = {en},
	number = {1},
	urldate = {2020-11-04},
	journal = {Glossa: a journal of general linguistics},
	author = {White, Aaron Steven and Rawlins, Kyle},
	month = nov,
	year = {2020},
	pages = {105},
}

@article{reisinger_semantic_2015,
    title = "Semantic Proto-Roles",
    author = "Reisinger, Dee Ann  and
      Rudinger, Rachel  and
      Ferraro, Francis  and
      Harman, Craig  and
      Rawlins, Kyle  and
      Van Durme, Benjamin",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "3",
    year = "2015",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    doi = "10.1162/tacl_a_00152",
    pages = "475--488",
    abstract = "We present the first large-scale, corpus based verification of Dowty{'}s seminal theory of proto-roles. Our results demonstrate both the need for and the feasibility of a property-based annotation scheme of semantic relationships, as opposed to the currently dominant notion of categorical roles.",
}

@article{pearson_lines_1901,
  author = {Pearson, Karl},
  title = {On lines and planes of closest fit to systems of points in space},
  journal = {The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science},
  volume = {2},
  number = {11},
  pages = {559-572},
  year  = {1901},
  publisher = {Taylor & Francis},
  doi = {10.1080/14786440109462720},
}

@article{paatero_positive_1994,
  title = {Positive matrix factorization: {A} non-negative factor model with optimal utilization of error estimates of data values},
  volume = {5},
  issn = {1099-095X},
  shorttitle = {Positive matrix factorization},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/env.3170050203},
  doi = {10.1002/env.3170050203},
  abstract = {A new variant ‘PMF’ of factor analysis is described. It is assumed that X is a matrix of observed data and σ is the known matrix of standard deviations of elements of X. Both X and σ are of dimensions n × m. The method solves the bilinear matrix problem X = GF + E where G is the unknown left hand factor matrix (scores) of dimensions n × p, F is the unknown right hand factor matrix (loadings) of dimensions p × m, and E is the matrix of residuals. The problem is solved in the weighted least squares sense: G and F are determined so that the Frobenius norm of E divided (element-by-element) by σ is minimized. Furthermore, the solution is constrained so that all the elements of G and F are required to be non-negative. It is shown that the solutions by PMF are usually different from any solutions produced by the customary factor analysis (FA, i.e. principal component analysis (PCA) followed by rotations). Usually PMF produces a better fit to the data than FA. Also, the result of PF is guaranteed to be non-negative, while the result of FA often cannot be rotated so that all negative entries would be eliminated. Different possible application areas of the new method are briefly discussed. In environmental data, the error estimates of data can be widely varying and non-negativity is often an essential feature of the underlying models. Thus it is concluded that PMF is better suited than FA or PCA in many environmental applications. Examples of successful applications of PMF are shown in companion papers.},
  language = {en},
  number = {2},
  urldate = {2023-05-22},
  journal = {Environmetrics},
  author = {Paatero, Pentti and Tapper, Unto},
  year = {1994},
  keywords = {Alternating regression, Error estimates, Factor analysis, Principal component analysis, Repetitive measurements, Scaling, Weighted least squares},
  pages = {111--126},
}


@article{pavlick_symbols_2023,
  title = {Symbols and grounding in large language models},
  volume = {381},
  url = {https://royalsocietypublishing.org/doi/10.1098/rsta.2022.0041},
  doi = {10.1098/rsta.2022.0041},
  number = {2251},
  urldate = {2023-06-08},
  journal = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
  author = {Pavlick, Ellie},
  month = jun,
  year = {2023},
}

@incollection{baroni_proper_2022,
  title = {On the {Proper} {Role} of {Linguistically} {Oriented} {Deep} {Net} {Analysis} in {Linguistic} {Theorising}},
  isbn = {978-1-00-320538-8},
  abstract = {A lively research field has recently emerged that uses experimental methods to probe the linguistic behaviour of modern deep networks. While work in this tradition often reports intriguing results about the grammatical skills of deep nets, it is not clear what their implications for linguistic theorising should be. As a consequence, linguistically oriented deep net analysis has had very little impact on linguistics at large. In this chapter, I suggest that deep networks should be treated as theories making explicit predictions about the acceptability of linguistic utterances. I argue that if we overcome some obstacles standing in the way of seriously pursuing this idea, we will gain a powerful new theoretical tool, complementary to mainstream algebraic approaches.},
  booktitle = {Algebraic {Structures} in {Natural} {Language}},
  publisher = {CRC Press},
  author = {Baroni, Marco},
  year = {2022},
}

@article{peters_generative_1973,
  title = {On the generative power of transformational grammars},
  volume = {6},
  issn = {0020-0255},
  url = {https://www.sciencedirect.com/science/article/pii/0020025573900273},
  doi = {10.1016/0020-0255(73)90027-3},
  abstract = {Mathematical modeling of phrase structure grammars has yielded many results of benefit to linguists in their investigation of these grammars, such as Chomsky's characterization in terms of self-embedding of those context-free languages which are not regular. The recent shift of focus in linguistic theory to transformational grammars has not been accompanied by a similar application of mathematical techniques to transformations. Our present purpose is to foster such studies by providing general definitions which model grammatical transformations as mappings on trees (equivalently, labeled bracketings) and investigating questions of current linguistic interest, such as the recursiveness of languages generated by transformational grammars. The first result of our research is that, despite the linguistically motivated, complex restrictions placed on transformational grammars, every recursively enumerable set of strings is a transformational language (Theorem 5.1). We demonstrate that this power of transformational grammars to generate non-recursive languages results from their ability to cycle their rules, applying transformations an unbounded number of times (Corollary 6.6). Analysis of decision procedures for grammars with bounded cycling reveals a connection between the amount of cycling permitted by a grammar and the complexity of the recursive set it generates; if cycling is bounded by any elementary recursive function (primitive recursive function, function in ∄n for n {\textgreater} 3), then the language generated has characteristic function in the same class (Corollary 6.7). One application of these results provides empirical support for the notion that natural languages are recursively, in fact elementarily, decidable. Our results also isolate one feature which must be further restricted in a linguistically motivated way if transformational theory is to achieve its goal of delimiting precisely the natural languages.},
  language = {en},
  urldate = {2023-06-08},
  journal = {Information Sciences},
  author = {Peters, P. Stanley and Ritchie, R. W.},
  month = jan,
  year = {1973},
  pages = {49--83},
}

@incollection{chomsky_conditions_1973,
  address = {New York},
  title = {Conditions on transformations},
  booktitle = {A {Festschrift} for {Morris} {Halle}},
  publisher = {Holt, Rinehart, \& Winston},
  author = {Chomsky, Noam},
  editor = {{S. Anderson} and {P. Kiparsky}},
  year = {1973},
  pages = {232--286},
}

@techreport{joshi_convergence_1990,
  title = {The {Convergence} of {Mildly} {Context}-{Sensitive} {Grammar} {Formalisms}},
  url = {https://repository.upenn.edu/cis_reports/539},
  number={MS-CIS-90-01},
  author = {Joshi, Aravind and Shanker, Vijay K. and Weir, David},
  institution={Department of Computer and Information Science, University of Pennsylvania},
  address={Philadelphia},
  month = jan,
  year = {1990},
}


@book{levin_argument_2005,
  address = {Cambridge},
  title = {Argument {Realization}},
  isbn = {0-521-66376-8},
  publisher = {Cambridge University Press},
  author = {Levin, Beth and Rappaport Hovav, Malka},
  year = {2005},
}

@article{dowty_thematic_1991,
  title = {Thematic proto-roles and argument selection},
  volume = {67},
  doi = {10.2307/415037},
  number = {3},
  journal = {Language},
  author = {Dowty, David},
  year = {1991},
  pages = {547--619},
}

@inproceedings{white_universal_2020,
    title = "The Universal Decompositional Semantics Dataset and Decomp Toolkit",
    author = "White, Aaron Steven  and
      Stengel-Eskin, Elias  and
      Vashishtha, Siddharth  and
      Govindarajan, Venkata Subrahmanyan  and
      Reisinger, Dee Ann  and
      Vieira, Tim  and
      Sakaguchi, Keisuke  and
      Zhang, Sheng  and
      Ferraro, Francis  and
      Rudinger, Rachel  and
      Rawlins, Kyle  and
      Van Durme, Benjamin",
    booktitle = "Proceedings of the Twelfth Language Resources and Evaluation Conference",
    month = may,
    year = "2020",
    address = "Marseille, France",
    publisher = "European Language Resources Association",
    url = "https://aclanthology.org/2020.lrec-1.699",
    pages = "5698--5707",
    abstract = "We present the Universal Decompositional Semantics (UDS) dataset (v1.0), which is bundled with the Decomp toolkit (v0.1). UDS1.0 unifies five high-quality, decompositional semantics-aligned annotation sets within a single semantic graph specification{---}with graph structures defined by the predicative patterns produced by the PredPatt tool and real-valued node and edge attributes constructed using sophisticated normalization procedures. The Decomp toolkit provides a suite of Python 3 tools for querying UDS graphs using SPARQL. Both UDS1.0 and Decomp0.1 are publicly available at http://decomp.io.",
    language = "English",
    ISBN = "979-10-95546-34-4",
}

@article{gantt_decomposing_2022,
  title = {Decomposing and {Recomposing} {Event} {Structure}},
  volume = {10},
  issn = {2307-387X},
  doi = {10.1162/tacl_a_00445},
  abstract = {We present an event structure classification empirically derived from inferential properties annotated on sentence- and document-level Universal Decompositional Semantics (UDS) graphs. We induce this classification jointly with semantic role, entity, and event-event relation classifications using a document-level generative model structured by these graphs. To support this induction, we augment existing annotations found in the UDS1.0 dataset, which covers the entirety of the English Web Treebank, with an array of inferential properties capturing fine-grained aspects of the temporal and aspectual structure of events. The resulting dataset (available at decomp.io) is the largest annotation of event structure and (partial) event coreference to date.},
  urldate = {2022-01-30},
  journal = {Transactions of the Association for Computational Linguistics},
  author = {Gantt, William and Glass, Lelia and White, Aaron Steven},
  month = jan,
  year = {2022},
  pages = {17--34},
}


@article{kane_intensional_2022,
  title = {Intensional {Gaps}: {Relating} veridicality, factivity, doxasticity, bouleticity, and neg-raising},
  volume = {31},
  copyright = {Copyright (c) 2022 Benjamin Kane, Will Gantt, Aaron Steven White},
  issn = {2163-5951},
  shorttitle = {Intensional {Gaps}},
  url = {https://journals.linguisticsociety.org/proceedings/index.php/SALT/article/view/31.029},
  doi = {10.3765/salt.v31i0.5137},
  abstract = {We investigate which patterns of lexically triggered doxastic, bouletic, neg(ation)-raising, and veridicality inferences are (un)attested across clause-embedding verbs in English. To carry out this investigation, we use a multiview mixed effects mixture model to discover the inference patterns captured in three lexicon-scale inference judgment datasets: two existing datasets, MegaVeridicality and MegaNegRaising, which capture veridicality and neg-raising inferences across a wide swath of the English clause-embedding lexicon, and a new dataset, MegaIntensionality, which similarly captures doxastic and bouletic inferences. We focus in particular on inference patterns that are correlated with morphosyntactic distribution, as determined by how well those patterns predict the acceptability judgments in the MegaAcceptability dataset. We find that there are 15 such patterns attested. Similarities among these patterns suggest the possibility of underlying lexical semantic components that give rise to them. We use principal component analysis to discover these components and suggest generalizations that can be derived from them.},
  language = {en},
  urldate = {2022-01-13},
  journal = {Semantics and Linguistic Theory},
  author = {Kane, Benjamin and Gantt, Will and White, Aaron Steven},
  month = jan,
  year = {2022},
  note = {Number: 0},
  pages = {570--605},
  file = {Full Text PDF:/Users/awhite48/Zotero/storage/LV5JYAGT/Kane et al. - 2022 - Intensional Gaps Relating veridicality, factivity.pdf:application/pdf},
}

@inproceedings{stabler_derivational_1997,
  address = {Berlin, Heidelberg},
  series = {Lecture {Notes} in {Computer} {Science}},
  title = {Derivational minimalism},
  isbn = {978-3-540-69631-5},
  doi = {10.1007/BFb0052152},
  abstract = {A basic idea of the transformational tradition is that constituents move. More recently, there has been a trend towards the view that all features are lexical features. And in recent “minimalist” grammars, structure building operations are assumed to be feature driven. A simple grammar formalism with these properties is presented here and briefly explored. Grammars in this formalism can define languages that are not in the “mildly context sensitive” class defined by Vijay-Shanker and Weir (1994).},
  language = {en},
  booktitle = {Logical {Aspects} of {Computational} {Linguistics}},
  publisher = {Springer},
  author = {Stabler, Edward},
  editor = {Retoré, Christian},
  year = {1997},
  keywords = {Linguistic Inquiry, Maximal Projection, Noun Phrase, Phonetic Feature, Syntactic Feature},
  pages = {68--95},
}

@book{steedman_surface_1996,
  title={Surface Structure and Interpretation},
  author={Steedman, Mark},
  year={1996},
  publisher={MIT Press},
  address={Cambridge, MA}
}

@article{church_poisson_1995, 
  title={Poisson mixtures}, 
  volume={1}, 
  DOI={10.1017/S1351324900000139}, 
  number={2}, 
  journal={Natural Language Engineering}, 
  publisher={Cambridge University Press}, 
  author={Church, Kenneth W. and Gale, William A.}, 
  year={1995}, 
  pages={163–190}
}

@article{stevens_psychophysical_1957,
  title = {On the psychophysical law},
  volume = {64},
  issn = {1939-1471},
  doi = {10.1037/h0046162},
  abstract = {The general psychophysical law is that equal stimulus ratios produce equal subjective ratios. A first-order approximation is a power function whose exponent varies from 0.3 (loudness) to 2.0 (visual flash rate). This holds for Class I (prothetic) or quantitative continua, distinguishable by 4 criteria: "the j.n.d. increases in subjective size as psychological magnitude increases, category rating-scales are concave downwards when plotted against psychological magnitude, comparative judgments exhibit a time-order error… , and equisection experiments exhibit hystersis" (a lagging behind of apparent sense differences). Class II (metathetic) or qualitative continua are lacking in these 4 criteria. Psychological scales based on direct ratio methods are better than Fechnerian methods, e.g., method of paired comparisons. 75 references. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  journal = {Psychological Review},
  author = {Stevens, S. S.},
  year = {1957},
  note = {Place: US
Publisher: American Psychological Association},
  keywords = {Judgment, Laws, Psychophysics, Rating Scales},
  pages = {153--181},
  file = {Snapshot:/Users/awhite48/Zotero/storage/UQLQHM3I/1958-04769-001.html:text/html},
}


@phdthesis{sprouse_program_2007,
  title = {A {Program} for {Experimental} {Syntax}},
  school = {University of Maryland},
  author = {Sprouse, Jon},
  year = {2007},
}

@article{sprouse_validation_2011,
  title = {A validation of {Amazon} {Mechanical} {Turk} for the collection of acceptability judgments in linguistic theory},
  volume = {43},
  journal = {Behavorial Research},
  author = {Sprouse, Jon},
  year = {2011},
  pages = {155--167},
}

@article{sprouse_assessing_2012,
  title = {Assessing the reliability of textbook data in syntax: {Adger}'s {Core} {Syntax}},
  volume = {48},
  number = {03},
  journal = {Journal of Linguistics},
  author = {Sprouse, Jon and Almeida, Diogo},
  year = {2012},
  pages = {609--652},
}


@inproceedings{hale_probabilistic_2001,
  address = {Stroudsburg, PA, USA},
  series = {{NAACL} '01},
  title = {A {Probabilistic} {Earley} {Parser} {As} a {Psycholinguistic} {Model}},
  booktitle = {Proceedings of the {Second} {Meeting} of the {North} {American} {Chapter} of the {Association} for {Computational} {Linguistics} on {Language} {Technologies}},
  publisher = {Association for Computational Linguistics},
  author = {Hale, John},
  year = {2001}
}

@article{levy_expectation-based_2008,
  title = {Expectation-based syntactic comprehension},
  volume = {106},
  number = {3},
  journal = {Cognition},
  author = {Levy, Roger},
  year = {2008},
  pages = {1126--1177},
}

@article{lewis_activation-based_2005,
  title = {An {Activation}-{Based} {Model} of {Sentence} {Processing} as {Skilled} {Memory} {Retrieval}},
  volume = {29},
  copyright = {© 2005 Cognitive Science Society, Inc.},
  issn = {1551-6709},
  doi = {10.1207/s15516709cog0000_25},
  abstract = {We present a detailed process theory of the moment-by-moment working-memory retrievals and associated control structure that subserve sentence comprehension. The theory is derived from the application of independently motivated principles of memory and cognitive skill to the specialized task of sentence parsing. The resulting theory construes sentence processing as a series of skilled associative memory retrievals modulated by similarity-based interference and fluctuating activation. The cognitive principles are formalized in computational form in the Adaptive Control of Thought–Rational (ACT–R) architecture, and our process model is realized in ACT–R. We present the results of 6 sets of simulations: 5 simulation sets provide quantitative accounts of the effects of length and structural interference on both unambiguous and garden-path structures. A final simulation set provides a graded taxonomy of double center embeddings ranging from relatively easy to extremely difficult. The explanation of center-embedding difficulty is a novel one that derives from the model' complete reliance on discriminating retrieval cues in the absence of an explicit representation of serial order information. All fits were obtained with only 1 free scaling parameter fixed across the simulations; all other parameters were ACT–R defaults. The modeling results support the hypothesis that fluctuating activation and similarity-based interference are the key factors shaping working memory in sentence processing. We contrast the theory and empirical predictions with several related accounts of sentence-processing complexity.},
  language = {en},
  number = {3},
  urldate = {2023-06-15},
  journal = {Cognitive Science},
  author = {Lewis, Richard L. and Vasishth, Shravan},
  year = {2005},
  keywords = {ACT-R, Activation, Cognitive architectures, Cognitive modeling, Decay, Interference, Parsing, Sentence processing, Syntax, Working memory},
  pages = {375--419},
}

@article{mcelree_memory_2003,
  title = {Memory structures that subserve sentence comprehension},
  volume = {48},
  issn = {0749-596X},
  url = {https://www.sciencedirect.com/science/article/pii/S0749596X02005156},
  doi = {10.1016/S0749-596X(02)00515-6},
  abstract = {Measures of the speed and accuracy of processing sentences with nonadjacent dependencies derived from the response-signal speed-accuracy tradeoff procedure were used to examine the nature of the memory system that underlies sentence comprehension. Three experiments with different sentence structures demonstrated that the accuracy of processing a dependency decreased as more material was interpolated between nonadjacent constituents. However, processing speed was unaffected by the amount of interpolated material, indicating that memory representations for previously processed constituents can be accessed directly. These results suggest that a content-addressable memory system mediates sentence comprehension, in which syntactic and semantic information provide direct access to memory representations without the need to search through extraneous representations. Notably, content-addressability appears to underlie the interpretation of sentence structures that also require the recovery of order information, a type of operation that has been shown to necessitate a slow search process in list-learning experiments (McElree, 2001; McElree \& Dosher, 1993).},
  language = {en},
  number = {1},
  urldate = {2023-06-15},
  journal = {Journal of Memory and Language},
  author = {McElree, Brian and Foraker, Stephani and Dyer, Lisbeth},
  month = jan,
  year = {2003},
  keywords = {Memory retrieval, Sentence comprehension, Speed-accuracy tradeoff, Unbounded dependencies, Working memory},
  pages = {67--91},
}

@article{gibson_linguistic_1998,
  title = {Linguistic complexity: locality of syntactic dependencies},
  volume = {68},
  issn = {0010-0277},
  shorttitle = {Linguistic complexity},
  url = {https://www.sciencedirect.com/science/article/pii/S0010027798000341},
  doi = {10.1016/S0010-0277(98)00034-1},
  abstract = {This paper proposes a new theory of the relationship between the sentence processing mechanism and the available computational resources. This theory – the Syntactic Prediction Locality Theory (SPLT) – has two components: an integration cost component and a component for the memory cost associated with keeping track of obligatory syntactic requirements. Memory cost is hypothesized to be quantified in terms of the number of syntactic categories that are necessary to complete the current input string as a grammatical sentence. Furthermore, in accordance with results from the working memory literature both memory cost and integration cost are hypothesized to be heavily influenced by locality (1) the longer a predicted category must be kept in memory before the prediction is satisfied, the greater is the cost for maintaining that prediction; and (2) the greater the distance between an incoming word and the most local head or dependent to which it attaches, the greater the integration cost. The SPLT is shown to explain a wide range of processing complexity phenomena not previously accounted for under a single theory, including (1) the lower complexity of subject-extracted relative clauses compared to object-extracted relative clauses, (2) numerous processing overload effects across languages, including the unacceptability of multiply center-embedded structures, (3) the lower complexity of cross-serial dependencies relative to center-embedded dependencies, (4) heaviness effects, such that sentences are easier to understand when larger phrases are placed later and (5) numerous ambiguity effects, such as those which have been argued to be evidence for the Active Filler Hypothesis.},
  language = {en},
  number = {1},
  urldate = {2023-06-15},
  journal = {Cognition},
  author = {Gibson, Edward},
  month = aug,
  year = {1998},
  keywords = {Computational resources, Linguistic complexity, Sentence processing, Syntactic dependency},
  pages = {1--76},
}
