{
 "cells": [
  {
   "cell_type": "raw",
   "id": "b904bc5b-bc33-42a2-a9cf-749dc311a542",
   "metadata": {},
   "source": [
    "---\n",
    "title: Adding structured representations\n",
    "bibliography: references.bib\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5e4dcaa9-e0b9-452f-bbac-016e20fa9e46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: Load MegaAttitude data\n",
    "\n",
    "import os\n",
    "from pandas import DataFrame, read_csv\n",
    "\n",
    "def load_data(fname: str, verbose: bool = True) -> DataFrame:\n",
    "    # read the raw data skipping comment rows at the beginning\n",
    "    data = read_csv(fname, sep=\"\\t\")\n",
    "    \n",
    "    if verbose:\n",
    "        n_datapoints = data.shape[0]\n",
    "        print(f\"The full dataset has {n_datapoints} datapoints.\")\n",
    "    \n",
    "    # remove non-native speakers\n",
    "    data = data.query(\"nativeenglish\")\n",
    "    \n",
    "    if verbose:\n",
    "        n_datapoints_native = data.shape[0]\n",
    "        print(f\"Removing {n_datapoints - n_datapoints_native} \"\n",
    "              \"responses from nonnative speakers.\")\n",
    "    \n",
    "    # remove NaN judgments\n",
    "    data = data.query(\"~response.isnull()\")\n",
    "    \n",
    "    if verbose:\n",
    "        n_datapoints_nonnull = data.shape[0]\n",
    "        print(f\"Removing {n_datapoints_native - n_datapoints_nonnull} NA responses.\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "data = load_data(\"data/mega-acceptability-v1/mega-acceptability-v1.tsv\", verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "55373a23-3872-4249-a6e9-12f61eaac8ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: Frame-to-constitutent mapping\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "frame_to_constituents = OrderedDict({\n",
    "    'NP was Ved whichNP to VP': {\n",
    "        (\"NP_subj\", \"NP_obj\", \"whichNP to VP\"),\n",
    "        (\"NP_obj\", \"whichNP to VP\")\n",
    "    }, \n",
    "    'NP Ved for NP to VP': {\n",
    "        (\"NP_subj\", \"for NP to VP\"), \n",
    "        (\"NP_subj\", \"PP_for\", \"to VP\")\n",
    "    },\n",
    "    'NP Ved NP to VP[+eventive]': {\n",
    "        (\"NP_subj\", \"NP to VP[+eventive]\"), \n",
    "        (\"NP_subj\", \"NP_obj\", \"to VP[+eventive]\")\n",
    "    }, \n",
    "    'NP was Ved whether to VP': {\n",
    "        (\"NP_subj\", \"NP_obj\", \"whether to VP\"),\n",
    "        (\"NP_obj\", \"whether to VP\")\n",
    "    },\n",
    "    'NP Ved to VP[+eventive]': {\n",
    "        (\"NP_subj\", \"to VP[+eventive]\")\n",
    "    }, \n",
    "    'NP Ved NP to NP': {\n",
    "        (\"NP_subj\", \"NP_obj\", \"NP_iobj\") \n",
    "    }, \n",
    "    'NP Ved NP that S': {\n",
    "        (\"NP_subj\", \"NP_obj\", \"that S\") \n",
    "    },\n",
    "    'NP was Ved about NP': {\n",
    "        (\"NP_subj\", \"NP_obj\", \"about NP\") ,\n",
    "        (\"NP_obj\", \"about NP\") \n",
    "    }, \n",
    "    'NP was Ved that S[-tense]': {\n",
    "        (\"NP_subj\", \"NP_obj\", \"S[-tense]\") ,\n",
    "        (\"NP_obj\", \"S[-tense]\") \n",
    "    },\n",
    "    'NP Ved to NP that S[+future]': {\n",
    "        (\"NP_subj\", \"NP_iobj\", \"that S[+future]\") \n",
    "    }, \n",
    "    'NP Ved whether to VP': {\n",
    "        (\"NP_subj\", \"whether to VP\")\n",
    "    },\n",
    "    'NP Ved whichNP to VP': {\n",
    "        (\"NP_subj\", \"whichNP to VP\")\n",
    "    }, \n",
    "    'NP Ved about whether S': {\n",
    "        (\"NP_subj\", \"about whether S\") \n",
    "    },\n",
    "    'NP Ved whichNP S': {\n",
    "        (\"NP_subj\", \"whichNP S\")\n",
    "    }, \n",
    "    'NP Ved that S[-tense]': {\n",
    "        (\"NP_subj\", \"that S[-tense]\") \n",
    "    },\n",
    "    'NP Ved whether S[+future]': {\n",
    "        (\"NP_subj\", \"whether S[+future]\") \n",
    "    }, \n",
    "    'NP was Ved that S[+future]': {\n",
    "        (\"NP_subj\", \"NP_obj\", \"that S[+future]\") ,\n",
    "        (\"NP_obj\", \"that S[+future]\") \n",
    "    },\n",
    "    'NP Ved to NP whether S': {\n",
    "        (\"NP_subj\", \"NP_iobj\", \"whether S\") \n",
    "    }, \n",
    "    'NP Ved': {\n",
    "        (\"NP_subj\",)\n",
    "    }, \n",
    "    'NP Ved NP to VP[-eventive]': {\n",
    "        (\"NP_subj\", \"NP to VP[-eventive]\"), \n",
    "        (\"NP_subj\", \"NP_obj\", \"to VP[-eventive]\"),\n",
    "        (\"NP_subj\", \"NP to VP[-eventive]\")\n",
    "    },\n",
    "    'NP was Ved so': {\n",
    "        (\"NP_obj\", \"so\"), \n",
    "        (\"NP_subj\", \"NP_obj\", \"so\")\n",
    "    }, \n",
    "    'NP Ved so': {\n",
    "        (\"NP_subj\", \"so\")\n",
    "    }, \n",
    "    'NP Ved NP that S[+future]': {\n",
    "        (\"NP_subj\", \"NP_obj\", \"that S[+future]\")\n",
    "    },\n",
    "    'NP Ved NP whether S[+future]': {\n",
    "        (\"NP_subj\", \"NP_obj\", \"whether S[+future]\")\n",
    "    }, \n",
    "    'NP Ved to NP whether S[+future]': {\n",
    "        (\"NP_subj\", \"NP_iobj\", \"whether S[+future]\")\n",
    "    },\n",
    "    'NP was Ved that S': {\n",
    "        (\"NP_obj\", \"that S\"), \n",
    "        (\"NP_subj\", \"NP_obj\", \"that S\")\n",
    "    }, \n",
    "    'NP Ved NP whether S': {\n",
    "        (\"NP_subj\", \"NP_obj\", \"whether S\")\n",
    "    }, \n",
    "    'NP was Ved whether S': {\n",
    "        (\"NP_obj\", \"whether S\"), \n",
    "        (\"NP_subj\", \"NP_obj\", \"whether S\")\n",
    "    },\n",
    "    'NP was Ved to VP[-eventive]': {\n",
    "        (\"NP_obj\", \"to VP[-eventive]\"), \n",
    "        (\"NP_subj\", \"NP_obj\", \"to VP[-eventive]\"),\n",
    "        (\"NP_subj\", \"NP to VP[-eventive]\")\n",
    "    }, \n",
    "    'NP Ved NP VP': {\n",
    "        (\"NP_subj\", \"NP_obj\", \"VP\"),\n",
    "        (\"NP_subj\", \"NP VP\")\n",
    "    }, \n",
    "    'NP Ved VPing': {\n",
    "        (\"NP_subj\", \"VPing\")\n",
    "    },\n",
    "    'NP was Ved to VP[+eventive]': {\n",
    "        (\"NP_obj\", \"to VP[+eventive]\"), \n",
    "        (\"NP_subj\", \"NP_obj\", \"to VP[+eventive]\"),\n",
    "        (\"NP_subj\", \"NP to VP[+eventive]\")\n",
    "    }, \n",
    "    'NP Ved NP that S[-tense]': {\n",
    "        (\"NP_subj\", \"NP_obj\", \"that S[-tense]\")\n",
    "    },\n",
    "    'NP Ved that S': {\n",
    "        (\"NP_subj\", \"that S\")\n",
    "    }, \n",
    "    'NP was Ved': {\n",
    "        (\"NP_obj\",), \n",
    "        (\"NP_subj\", \"NP_obj\")\n",
    "    }, \n",
    "    'NP Ved S': {\n",
    "        (\"NP_subj\", \"S\")\n",
    "    },\n",
    "    'NP Ved that S[+future]': {\n",
    "        (\"NP_subj\", \"that S[+future]\")\n",
    "    }, \n",
    "    'NP was Ved about whether S': {\n",
    "        (\"NP_subj\", \"NP_obj\", \"about whether S\") ,\n",
    "        (\"NP_obj\", \"about whether S\") \n",
    "    },\n",
    "    'NP Ved NP': {\n",
    "        (\"NP_subj\", \"NP_obj\") \n",
    "    }, \n",
    "    'NP Ved NP VPing': {\n",
    "        (\"NP_subj\", \"NP_obj\", \"VPing\"),\n",
    "        (\"NP_subj\", \"NP VPing\")\n",
    "    }, \n",
    "    'NP Ved NP whichNP S': {\n",
    "        (\"NP_subj\", \"NP_obj\", \"whichNP S\")\n",
    "    },\n",
    "    'NP Ved about NP': {\n",
    "        (\"NP_subj\", \"about NP\") \n",
    "    }, \n",
    "    'NP was Ved S': {\n",
    "        (\"NP_subj\", \"NP_obj\", \"S\") ,\n",
    "        (\"NP_obj\", \"S\") \n",
    "    }, \n",
    "    'NP Ved to NP that S': {\n",
    "        (\"NP_subj\", \"NP_iobj\", \"that S\"),\n",
    "    },\n",
    "    'NP was Ved whether S[+future]': {\n",
    "        (\"NP_subj\", \"NP_obj\", \"whether S[+future]\") ,\n",
    "        (\"NP_obj\", \"whether S[+future]\") \n",
    "    }, \n",
    "    'NP Ved whether S': {\n",
    "        (\"NP_subj\", \"whether S\") \n",
    "    },\n",
    "    'NP was Ved whichNP S': {\n",
    "        (\"NP_subj\", \"NP_obj\", \"whichNP S\") ,\n",
    "        (\"NP_obj\", \"whichNP S\") \n",
    "    }, \n",
    "    'NP Ved to NP that S[-tense]': {\n",
    "        (\"NP_subj\", \"NP_iobj\", \"that S[-tense]\")\n",
    "    },\n",
    "    'NP Ved to VP[-eventive]': {\n",
    "        (\"NP_subj\", \"to VP[-eventive]\")\n",
    "    }\n",
    "})\n",
    "\n",
    "data = data[data.frame.isin(frame_to_constituents)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bd317a06-6f5c-46e9-b2cb-488d7fd8d419",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "body[data-theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-index-preview {\n",
       "  grid-column: 2 / 5;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data,\n",
       ".xr-index-data-in:checked ~ .xr-index-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-index-name div,\n",
       ".xr-index-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2,\n",
       ".xr-no-icon {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.DataArray (frame: 49, parse: 3, constituent: 27)&gt;\n",
       "array([[[0., 0., 0., ..., 0., 0., 1.],\n",
       "        [0., 0., 0., ..., 0., 0., 1.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 1., 0.],\n",
       "        [0., 0., 0., ..., 0., 1., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]])\n",
       "Coordinates:\n",
       "  * frame        (frame) &lt;U31 &#x27;NP was Ved whichNP to VP&#x27; ... &#x27;NP Ved to VP[-e...\n",
       "  * parse        (parse) int64 0 1 2\n",
       "  * constituent  (constituent) &lt;U19 &#x27;NP VP&#x27; &#x27;NP VPing&#x27; ... &#x27;whichNP to VP&#x27;</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.DataArray</div><div class='xr-array-name'></div><ul class='xr-dim-list'><li><span class='xr-has-index'>frame</span>: 49</li><li><span class='xr-has-index'>parse</span>: 3</li><li><span class='xr-has-index'>constituent</span>: 27</li></ul></div><ul class='xr-sections'><li class='xr-section-item'><div class='xr-array-wrap'><input id='section-b0864171-f216-4eed-b9d2-767b5ac5406d' class='xr-array-in' type='checkbox' checked><label for='section-b0864171-f216-4eed-b9d2-767b5ac5406d' title='Show/hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-array-preview xr-preview'><span>0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0</span></div><div class='xr-array-data'><pre>array([[[0., 0., 0., ..., 0., 0., 1.],\n",
       "        [0., 0., 0., ..., 0., 0., 1.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 1., 0.],\n",
       "        [0., 0., 0., ..., 0., 1., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]])</pre></div></div></li><li class='xr-section-item'><input id='section-55bb3f9b-66fa-4ae9-88cf-9732d3d086d2' class='xr-section-summary-in' type='checkbox'  checked><label for='section-55bb3f9b-66fa-4ae9-88cf-9732d3d086d2' class='xr-section-summary' >Coordinates: <span>(3)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>frame</span></div><div class='xr-var-dims'>(frame)</div><div class='xr-var-dtype'>&lt;U31</div><div class='xr-var-preview xr-preview'>&#x27;NP was Ved whichNP to VP&#x27; ... &#x27;...</div><input id='attrs-26c4eb41-c282-4a83-a541-1520f953c68d' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-26c4eb41-c282-4a83-a541-1520f953c68d' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-6599a382-7ab7-4ae7-90ce-8ab1fd79a2be' class='xr-var-data-in' type='checkbox'><label for='data-6599a382-7ab7-4ae7-90ce-8ab1fd79a2be' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([&#x27;NP was Ved whichNP to VP&#x27;, &#x27;NP Ved for NP to VP&#x27;,\n",
       "       &#x27;NP Ved NP to VP[+eventive]&#x27;, &#x27;NP was Ved whether to VP&#x27;,\n",
       "       &#x27;NP Ved to VP[+eventive]&#x27;, &#x27;NP Ved NP to NP&#x27;, &#x27;NP Ved NP that S&#x27;,\n",
       "       &#x27;NP was Ved about NP&#x27;, &#x27;NP was Ved that S[-tense]&#x27;,\n",
       "       &#x27;NP Ved to NP that S[+future]&#x27;, &#x27;NP Ved whether to VP&#x27;,\n",
       "       &#x27;NP Ved whichNP to VP&#x27;, &#x27;NP Ved about whether S&#x27;, &#x27;NP Ved whichNP S&#x27;,\n",
       "       &#x27;NP Ved that S[-tense]&#x27;, &#x27;NP Ved whether S[+future]&#x27;,\n",
       "       &#x27;NP was Ved that S[+future]&#x27;, &#x27;NP Ved to NP whether S&#x27;, &#x27;NP Ved&#x27;,\n",
       "       &#x27;NP Ved NP to VP[-eventive]&#x27;, &#x27;NP was Ved so&#x27;, &#x27;NP Ved so&#x27;,\n",
       "       &#x27;NP Ved NP that S[+future]&#x27;, &#x27;NP Ved NP whether S[+future]&#x27;,\n",
       "       &#x27;NP Ved to NP whether S[+future]&#x27;, &#x27;NP was Ved that S&#x27;,\n",
       "       &#x27;NP Ved NP whether S&#x27;, &#x27;NP was Ved whether S&#x27;,\n",
       "       &#x27;NP was Ved to VP[-eventive]&#x27;, &#x27;NP Ved NP VP&#x27;, &#x27;NP Ved VPing&#x27;,\n",
       "       &#x27;NP was Ved to VP[+eventive]&#x27;, &#x27;NP Ved NP that S[-tense]&#x27;,\n",
       "       &#x27;NP Ved that S&#x27;, &#x27;NP was Ved&#x27;, &#x27;NP Ved S&#x27;, &#x27;NP Ved that S[+future]&#x27;,\n",
       "       &#x27;NP was Ved about whether S&#x27;, &#x27;NP Ved NP&#x27;, &#x27;NP Ved NP VPing&#x27;,\n",
       "       &#x27;NP Ved NP whichNP S&#x27;, &#x27;NP Ved about NP&#x27;, &#x27;NP was Ved S&#x27;,\n",
       "       &#x27;NP Ved to NP that S&#x27;, &#x27;NP was Ved whether S[+future]&#x27;,\n",
       "       &#x27;NP Ved whether S&#x27;, &#x27;NP was Ved whichNP S&#x27;,\n",
       "       &#x27;NP Ved to NP that S[-tense]&#x27;, &#x27;NP Ved to VP[-eventive]&#x27;], dtype=&#x27;&lt;U31&#x27;)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>parse</span></div><div class='xr-var-dims'>(parse)</div><div class='xr-var-dtype'>int64</div><div class='xr-var-preview xr-preview'>0 1 2</div><input id='attrs-a13d0f5c-144f-4e6e-bfa2-0d61a61b3cd1' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-a13d0f5c-144f-4e6e-bfa2-0d61a61b3cd1' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-24fa42e3-ca30-4576-b794-057741c6f42e' class='xr-var-data-in' type='checkbox'><label for='data-24fa42e3-ca30-4576-b794-057741c6f42e' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([0, 1, 2])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>constituent</span></div><div class='xr-var-dims'>(constituent)</div><div class='xr-var-dtype'>&lt;U19</div><div class='xr-var-preview xr-preview'>&#x27;NP VP&#x27; ... &#x27;whichNP to VP&#x27;</div><input id='attrs-f6f2b5cd-5df8-4c62-b40e-3e454379862c' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-f6f2b5cd-5df8-4c62-b40e-3e454379862c' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-327235bf-53d1-4d96-959c-17e33a5c92f0' class='xr-var-data-in' type='checkbox'><label for='data-327235bf-53d1-4d96-959c-17e33a5c92f0' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([&#x27;NP VP&#x27;, &#x27;NP VPing&#x27;, &#x27;NP to VP[+eventive]&#x27;, &#x27;NP to VP[-eventive]&#x27;,\n",
       "       &#x27;NP_iobj&#x27;, &#x27;NP_obj&#x27;, &#x27;NP_subj&#x27;, &#x27;PP_for&#x27;, &#x27;S&#x27;, &#x27;S[-tense]&#x27;, &#x27;VP&#x27;,\n",
       "       &#x27;VPing&#x27;, &#x27;about NP&#x27;, &#x27;about whether S&#x27;, &#x27;for NP to VP&#x27;, &#x27;so&#x27;, &#x27;that S&#x27;,\n",
       "       &#x27;that S[+future]&#x27;, &#x27;that S[-tense]&#x27;, &#x27;to VP&#x27;, &#x27;to VP[+eventive]&#x27;,\n",
       "       &#x27;to VP[-eventive]&#x27;, &#x27;whether S&#x27;, &#x27;whether S[+future]&#x27;, &#x27;whether to VP&#x27;,\n",
       "       &#x27;whichNP S&#x27;, &#x27;whichNP to VP&#x27;], dtype=&#x27;&lt;U19&#x27;)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-8b7912b1-7b03-4948-b844-2e7b067476b8' class='xr-section-summary-in' type='checkbox'  ><label for='section-8b7912b1-7b03-4948-b844-2e7b067476b8' class='xr-section-summary' >Indexes: <span>(3)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-index-name'><div>frame</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-f1fce610-d4b2-4c9f-bf49-6fcc48cb2e99' class='xr-index-data-in' type='checkbox'/><label for='index-f1fce610-d4b2-4c9f-bf49-6fcc48cb2e99' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([&#x27;NP was Ved whichNP to VP&#x27;, &#x27;NP Ved for NP to VP&#x27;,\n",
       "       &#x27;NP Ved NP to VP[+eventive]&#x27;, &#x27;NP was Ved whether to VP&#x27;,\n",
       "       &#x27;NP Ved to VP[+eventive]&#x27;, &#x27;NP Ved NP to NP&#x27;, &#x27;NP Ved NP that S&#x27;,\n",
       "       &#x27;NP was Ved about NP&#x27;, &#x27;NP was Ved that S[-tense]&#x27;,\n",
       "       &#x27;NP Ved to NP that S[+future]&#x27;, &#x27;NP Ved whether to VP&#x27;,\n",
       "       &#x27;NP Ved whichNP to VP&#x27;, &#x27;NP Ved about whether S&#x27;, &#x27;NP Ved whichNP S&#x27;,\n",
       "       &#x27;NP Ved that S[-tense]&#x27;, &#x27;NP Ved whether S[+future]&#x27;,\n",
       "       &#x27;NP was Ved that S[+future]&#x27;, &#x27;NP Ved to NP whether S&#x27;, &#x27;NP Ved&#x27;,\n",
       "       &#x27;NP Ved NP to VP[-eventive]&#x27;, &#x27;NP was Ved so&#x27;, &#x27;NP Ved so&#x27;,\n",
       "       &#x27;NP Ved NP that S[+future]&#x27;, &#x27;NP Ved NP whether S[+future]&#x27;,\n",
       "       &#x27;NP Ved to NP whether S[+future]&#x27;, &#x27;NP was Ved that S&#x27;,\n",
       "       &#x27;NP Ved NP whether S&#x27;, &#x27;NP was Ved whether S&#x27;,\n",
       "       &#x27;NP was Ved to VP[-eventive]&#x27;, &#x27;NP Ved NP VP&#x27;, &#x27;NP Ved VPing&#x27;,\n",
       "       &#x27;NP was Ved to VP[+eventive]&#x27;, &#x27;NP Ved NP that S[-tense]&#x27;,\n",
       "       &#x27;NP Ved that S&#x27;, &#x27;NP was Ved&#x27;, &#x27;NP Ved S&#x27;, &#x27;NP Ved that S[+future]&#x27;,\n",
       "       &#x27;NP was Ved about whether S&#x27;, &#x27;NP Ved NP&#x27;, &#x27;NP Ved NP VPing&#x27;,\n",
       "       &#x27;NP Ved NP whichNP S&#x27;, &#x27;NP Ved about NP&#x27;, &#x27;NP was Ved S&#x27;,\n",
       "       &#x27;NP Ved to NP that S&#x27;, &#x27;NP was Ved whether S[+future]&#x27;,\n",
       "       &#x27;NP Ved whether S&#x27;, &#x27;NP was Ved whichNP S&#x27;,\n",
       "       &#x27;NP Ved to NP that S[-tense]&#x27;, &#x27;NP Ved to VP[-eventive]&#x27;],\n",
       "      dtype=&#x27;object&#x27;, name=&#x27;frame&#x27;))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>parse</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-aff5585a-4718-4a19-87d5-d11d38800d2b' class='xr-index-data-in' type='checkbox'/><label for='index-aff5585a-4718-4a19-87d5-d11d38800d2b' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([0, 1, 2], dtype=&#x27;int64&#x27;, name=&#x27;parse&#x27;))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>constituent</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-ed85068f-5510-4357-b3e0-26e2d3160485' class='xr-index-data-in' type='checkbox'/><label for='index-ed85068f-5510-4357-b3e0-26e2d3160485' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([&#x27;NP VP&#x27;, &#x27;NP VPing&#x27;, &#x27;NP to VP[+eventive]&#x27;, &#x27;NP to VP[-eventive]&#x27;,\n",
       "       &#x27;NP_iobj&#x27;, &#x27;NP_obj&#x27;, &#x27;NP_subj&#x27;, &#x27;PP_for&#x27;, &#x27;S&#x27;, &#x27;S[-tense]&#x27;, &#x27;VP&#x27;,\n",
       "       &#x27;VPing&#x27;, &#x27;about NP&#x27;, &#x27;about whether S&#x27;, &#x27;for NP to VP&#x27;, &#x27;so&#x27;, &#x27;that S&#x27;,\n",
       "       &#x27;that S[+future]&#x27;, &#x27;that S[-tense]&#x27;, &#x27;to VP&#x27;, &#x27;to VP[+eventive]&#x27;,\n",
       "       &#x27;to VP[-eventive]&#x27;, &#x27;whether S&#x27;, &#x27;whether S[+future]&#x27;, &#x27;whether to VP&#x27;,\n",
       "       &#x27;whichNP S&#x27;, &#x27;whichNP to VP&#x27;],\n",
       "      dtype=&#x27;object&#x27;, name=&#x27;constituent&#x27;))</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-c4a4fb04-bad9-47e8-b27b-80c9f22e8ee5' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-c4a4fb04-bad9-47e8-b27b-80c9f22e8ee5' class='xr-section-summary'  title='Expand/collapse section'>Attributes: <span>(0)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.DataArray (frame: 49, parse: 3, constituent: 27)>\n",
       "array([[[0., 0., 0., ..., 0., 0., 1.],\n",
       "        [0., 0., 0., ..., 0., 0., 1.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 1., 0.],\n",
       "        [0., 0., 0., ..., 0., 1., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]])\n",
       "Coordinates:\n",
       "  * frame        (frame) <U31 'NP was Ved whichNP to VP' ... 'NP Ved to VP[-e...\n",
       "  * parse        (parse) int64 0 1 2\n",
       "  * constituent  (constituent) <U19 'NP VP' 'NP VPing' ... 'whichNP to VP'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: Constituent-to-feature vector mapping\n",
    "\n",
    "from numpy import array, zeros, where, isin\n",
    "from xarray import DataArray\n",
    "\n",
    "constituents = array(sorted({\n",
    "    c \n",
    "    for tups in frame_to_constituents.values() \n",
    "    for t in tups \n",
    "    for c in t\n",
    "}))\n",
    "\n",
    "max_parses = max(\n",
    "    len(t) \n",
    "    for tups in frame_to_constituents.values() \n",
    "    for t in tups \n",
    ")\n",
    "    \n",
    "constituents_to_feature = zeros([\n",
    "    len(frame_to_constituents), max_parses, len(constituents)\n",
    "])\n",
    "    \n",
    "for i, (f, parses) in enumerate(frame_to_constituents.items()):\n",
    "    for j, parse in enumerate(parses):\n",
    "        for k, const in enumerate(parse):\n",
    "            const_idx = where(constituents == const)[0][0]\n",
    "            constituents_to_feature[i,j,const_idx] = 1.\n",
    "            \n",
    "constituents_to_feature = DataArray(\n",
    "    constituents_to_feature, \n",
    "    dims=[\"frame\", \"parse\", \"constituent\"],\n",
    "    coords={\n",
    "        \"frame\": list(frame_to_constituents),\n",
    "        \"parse\": list(range(max_parses)),\n",
    "        \"constituent\": constituents,\n",
    "    }\n",
    ")\n",
    "\n",
    "constituents_to_feature.loc[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1f2b1089-ec6a-4f62-a515-e59d90fc84e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from numpy import ndarray\n",
    "\n",
    "@dataclass\n",
    "class BaseSelectionModelParameters:\n",
    "    n_verb: int\n",
    "    n_frame: int\n",
    "    n_subj: int\n",
    "    n_resp_levels: int\n",
    "    \n",
    "@dataclass\n",
    "class StructuredSelectionModelParameters(BaseSelectionModelParameters):\n",
    "    constituents_to_feature: DataArray\n",
    "    n_constituent_types: int\n",
    "    n_primitive_semantic_types: int\n",
    "    n_primitive_syntactic_types: int\n",
    "    max_complex_type_size: int\n",
    "\n",
    "@dataclass\n",
    "class SelectionData:\n",
    "    verb: ndarray\n",
    "    frame: ndarray\n",
    "    subj: ndarray\n",
    "    resp: ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5b65516e-bcac-40f5-8139-7e3bf0ed5c92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Optional\n",
    "from numpy import prod\n",
    "from torch import Tensor, zeros, zeros_like, ones_like\n",
    "\n",
    "ZERO = 1e-3\n",
    "ONE = 1. - ZERO\n",
    "\n",
    "class StructuredSelectionModel(torch.nn.Module):\n",
    "    parameter_class = StructuredSelectionModelParameters\n",
    "    data_class = SelectionData\n",
    "    \n",
    "    def __init__(self, parameters: StructuredSelectionModelParameters):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model_parameters = parameters\n",
    "        \n",
    "        verb_shape = (parameters.n_verb,) + self.complex_semantic_type_shape\n",
    "        self.verb_complex_semantic_type_aux = torch.nn.Parameter(\n",
    "            torch.randn(verb_shape), \n",
    "            requires_grad=True\n",
    "        )\n",
    "        \n",
    "        frame_shape = (parameters.n_frame,) + self.complex_syntactic_type_shape\n",
    "        self.frame_complex_syntactic_type_aux = torch.nn.Parameter(\n",
    "            torch.randn(frame_shape), \n",
    "            requires_grad=True\n",
    "        )\n",
    "        \n",
    "        primitive_type_map_aux = zeros([\n",
    "            parameters.n_primitive_semantic_types + 1, \n",
    "            parameters.n_primitive_syntactic_types + 1\n",
    "        ])\n",
    "\n",
    "        self.primitive_type_map_aux = torch.nn.Parameter(\n",
    "            primitive_type_map_aux, \n",
    "            requires_grad=True\n",
    "        )\n",
    "        \n",
    "        syntactic_primitive_type_constituent_map_aux = zeros([\n",
    "             parameters.n_primitive_syntactic_types + 1,\n",
    "             parameters.n_constituent_types\n",
    "        ])\n",
    "        \n",
    "        self.syntactic_primitive_type_constituent_map_aux = torch.nn.Parameter(\n",
    "            syntactic_primitive_type_constituent_map_aux, \n",
    "            requires_grad=True\n",
    "        )\n",
    "        \n",
    "        self.log_jumps = torch.nn.Parameter(\n",
    "            torch.ones([\n",
    "                parameters.n_subj, parameters.n_resp_levels-1\n",
    "            ]), \n",
    "            requires_grad=True\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def complex_semantic_type_shape(self):\n",
    "        return (self.model_parameters.n_primitive_semantic_types+1,) *\\\n",
    "               self.model_parameters.max_complex_type_size\n",
    "    \n",
    "    @property\n",
    "    def complex_syntactic_type_shape(self):\n",
    "        return (self.model_parameters.n_primitive_syntactic_types+1,)*\\\n",
    "               self.model_parameters.max_complex_type_size\n",
    "        \n",
    "    def forward(self, data: SelectionData):\n",
    "        verb_frame_prob = self.verb_frame_prob(data.verb, data.frame)\n",
    "        verb_frame_logodds = torch.log(verb_frame_prob) - torch.log(1. - verb_frame_prob)\n",
    "        \n",
    "        jumps = self.jumps[data.subj]\n",
    "        \n",
    "        return ordered_logistic_likelihood(\n",
    "            verb_frame_logodds, jumps\n",
    "        )\n",
    "    \n",
    "    def verb_frame_prob(\n",
    "        self, \n",
    "        verb_idx: Optional[ndarray] = None, \n",
    "        frame_idx: Optional[ndarray] = None,\n",
    "        #feature: ndarray\n",
    "    ) -> Tensor:\n",
    "        n_verb = self.model_parameters.n_verb\n",
    "        n_frame = self.model_parameters.n_frame\n",
    "        \n",
    "        verb_shape = self.complex_semantic_type_shape +\\\n",
    "                     (1,) * len(self.complex_syntactic_type_shape)\n",
    "        frame_shape = (1,) * len(self.complex_semantic_type_shape) +\\\n",
    "                      self.complex_syntactic_type_shape\n",
    "        \n",
    "        if verb_idx is not None or frame_idx is not None:\n",
    "            if verb_idx.shape != frame_idx.shape:\n",
    "                raise ValueError\n",
    "            else:\n",
    "                resp_shape = verb_idx.shape[0]\n",
    "            \n",
    "            # shape for verbs and frames to complex type signatures\n",
    "            verb_shape = (resp_shape,) + verb_shape\n",
    "            frame_shape = (resp_shape,) + frame_shape\n",
    "            \n",
    "            # shape with response dimension inserted into map\n",
    "            map_shape = (1,) + self.complex_type_map.shape\n",
    "            \n",
    "            # shape for computing prod on all but the reponse dimension\n",
    "            flat_shape = (resp_shape, prod(map_shape))\n",
    "            \n",
    "            p = self.verb_complex_semantic_type[verb_idx].view(verb_shape) *\\\n",
    "                self.frame_complex_syntactic_type[frame_idx].view(frame_shape) *\\\n",
    "                self.complex_type_map.view(map_shape)\n",
    "            \n",
    "            print(p.shape)\n",
    "            \n",
    "            acc = 1. - (1. - p.view(flat_shape)).prod(axis=1)\n",
    "            acc = acc.clamp(min=ZERO, max=ONE)\n",
    "            \n",
    "            return acc\n",
    "        \n",
    "        elif verb_idx is None and frame_idx is not None:\n",
    "            raise NotImplementedError\n",
    "        elif verb_idx is not None and frame_idx is None:\n",
    "            raise NotImplementedError\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "#             verb_shape = (n_verb, 1) + verb_shape\n",
    "#             frame_shape = (1, n_frame) + frame_shape\n",
    "#             map_shape = (1, 1) + self.complex_type_map.shape\n",
    "            \n",
    "#             # shape for computing prod on all but the verb and frame dimensions\n",
    "#             flat_shape = (n_verb, n_frame, prod(map_shape))\n",
    "            \n",
    "#             p = self.verb_complex_semantic_type.view(verb_shape) *\\\n",
    "#                 self.frame_complex_syntactic_type.view(frame_shape) *\\\n",
    "#                 self.complex_type_map.view(map_shape)\n",
    "            \n",
    "#             return 1. - (1. - p.view(flat_shape)).prod(axis=2)   \n",
    "    \n",
    "    @property\n",
    "    def verb_complex_semantic_type(self) -> Tensor:\n",
    "        return torch.sigmoid(self.verb_complex_semantic_type_aux)\n",
    "    \n",
    "    @property\n",
    "    def frame_complex_syntactic_type(self) -> Tensor:\n",
    "        return torch.sigmoid(self.frame_complex_syntactic_type_aux)\n",
    "    \n",
    "    @property\n",
    "    def primitive_type_map(self) -> Tensor:\n",
    "        prob = torch.sigmoid(self.primitive_type_map_aux)\n",
    "        \n",
    "        # the 0th primitive type is the null primitive type and null \n",
    "        # primitive types should only map onto each other, we do this\n",
    "        # by multiplying by a special mask\n",
    "        mask = ones_like(prob)\n",
    "        mask[0,0] = 1/prob[0,0]\n",
    "        mask[0,1:] = 0.0\n",
    "        mask[1:,0] = 0.0\n",
    "        \n",
    "        return mask * prob\n",
    "    \n",
    "    @property\n",
    "    def complex_type_map(self):\n",
    "        final_shape = self.primitive_type_map.shape *\\\n",
    "                      self.model_parameters.max_complex_type_size\n",
    "        \n",
    "        shape = (self.primitive_type_map.shape[0],) +\\\n",
    "                (1,) * (self.model_parameters.max_complex_type_size - 1) +\\\n",
    "                (self.primitive_type_map.shape[1],) +\\\n",
    "                (1,) * (self.model_parameters.max_complex_type_size - 1)\n",
    "        m = self.primitive_type_map.view(shape)\n",
    "        \n",
    "        for i in range(1, self.model_parameters.max_complex_type_size):\n",
    "            shape = (1,) * i +\\\n",
    "                    (self.primitive_type_map.shape[0],) +\\\n",
    "                    (1,) * (self.model_parameters.max_complex_type_size - (i + 1)) +\\\n",
    "                    (1,) * i +\\\n",
    "                    (self.primitive_type_map.shape[1],) +\\\n",
    "                    (1,) * (self.model_parameters.max_complex_type_size - (i + 1))\n",
    "            m = m * self.primitive_type_map.view(shape)\n",
    "            \n",
    "        return m\n",
    "    \n",
    "    @property\n",
    "    def syntactic_primitive_type_constituent_map(self):\n",
    "        prob = torch.sigmoid(\n",
    "            self.syntactic_primitive_type_constituent_map_aux\n",
    "        )\n",
    "\n",
    "        # the 0th primitive type is the null primitive type and null \n",
    "        # primitive types should not map onto any constitutent, we do \n",
    "        # this by multiplying by a special mask\n",
    "        mask = ones_like(prob)\n",
    "        mask[0,:] = 0.0\n",
    "        \n",
    "        return mask * prob\n",
    "    \n",
    "    @property\n",
    "    def jumps(self):\n",
    "        return torch.exp(self.log_jumps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "85994f66-6fee-45a2-877e-ac514dc8dcb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "def ordered_logistic_likelihood(value: Tensor, jumps: Tensor, center: bool = True) -> Tensor:\n",
    "    \"\"\"Compute the ordered logistic likelihood given a value\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    value\n",
    "        The value to compute the likelihood for \n",
    "        (shape: batch_size)\n",
    "    jumps\n",
    "        The distance between cutpoints \n",
    "        (shape: batch_size x number of response levels - 1)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    log_likelihood\n",
    "        the ordered logistic log-likelihood\n",
    "    \"\"\"\n",
    "    cutpoints = torch.cumsum(jumps, axis=1) \n",
    "    \n",
    "    if center:\n",
    "        cutpoints = cutpoints - cutpoints.mean(1)[:,None]\n",
    "    \n",
    "    cdfs = torch.sigmoid(cutpoints - value[:,None])\n",
    "\n",
    "    low_prob = torch.cat(\n",
    "        [torch.zeros([cdfs.shape[0], 1]), cdfs],\n",
    "        axis=1\n",
    "    )\n",
    "    high_prob = torch.cat(\n",
    "        [cdfs, torch.ones([cdfs.shape[0], 1])],\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    return high_prob - low_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8d0f9d64-d3b4-4e0e-839f-8dba807b5211",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from numpy import ndarray\n",
    "from pandas import CategoricalDtype, Series\n",
    "\n",
    "def hash_series(series: Series, categories: Optional[list[str]] = None, indexation: int=1) -> tuple[ndarray, ndarray]:\n",
    "    \"\"\"Hash a series to numeric codes\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    column\n",
    "        The series to hash\n",
    "    index\n",
    "        The starting index (defaults to 1)\n",
    "    \"\"\"\n",
    "    # enforce 0- or 1-indexation\n",
    "    if indexation not in [0, 1]:\n",
    "        raise ValueError(\"Must choose either 0- or 1-indexation.\")\n",
    "    \n",
    "    # convert the series to a category\n",
    "    if categories is None:\n",
    "        category_series = series.astype(\"category\")\n",
    "    else:\n",
    "        cat_type = CategoricalDtype(categories=categories)\n",
    "        category_series = series.astype(cat_type)\n",
    "    \n",
    "    # get the hash\n",
    "    hash_map = category_series.cat.categories.values\n",
    "    \n",
    "    # map to one-indexed codes\n",
    "    hashed_series = (category_series.cat.codes + indexation).values\n",
    "    \n",
    "    return hash_map, hashed_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6b868c5a-c61e-450c-b3a2-a59a1225b78b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from numpy import round, mean, inf\n",
    "from numpy import random\n",
    "from numpy.random import choice\n",
    "from torch import manual_seed\n",
    "\n",
    "class StructuredSelectionModelTrainerABC(ABC):\n",
    "    data_class = SelectionData\n",
    "    \n",
    "    @abstractmethod\n",
    "    def construct_model_parameters(self, data: DataFrame) -> BaseSelectionModelParameters:\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def construct_model_data(self, data: DataFrame) -> SelectionData:            \n",
    "        frame_hashed, verb_hashed, subj_hashed = self._construct_hashes(data)\n",
    "        \n",
    "        model_data = {\n",
    "            \"verb\": verb_hashed,\n",
    "            \"frame\": frame_hashed,\n",
    "            \"subj\": subj_hashed,\n",
    "            \"resp\": data.response.astype(int).values - 1\n",
    "        }\n",
    "        \n",
    "        return self.data_class(**model_data)\n",
    "    \n",
    "    def _construct_hashes(self, data: DataFrame, ):\n",
    "        if hasattr(self, \"frame_hash_map\"):\n",
    "            _, frame_hashed = hash_series(data.frame, self.frame_hash_map, indexation=0)\n",
    "        else:\n",
    "            self.frame_hash_map, frame_hashed = hash_series(data.frame, indexation=0)\n",
    "            \n",
    "        if hasattr(self, \"verb_hash_map\"):\n",
    "            _, verb_hashed = hash_series(data.verb, self.verb_hash_map, indexation=0)\n",
    "        else:\n",
    "            self.verb_hash_map, verb_hashed = hash_series(data.verb, indexation=0)\n",
    "\n",
    "        if hasattr(self, \"subj_hash_map\"):\n",
    "            _, subj_hashed = hash_series(data.participant, self.subj_hash_map, indexation=0)\n",
    "        else:\n",
    "            self.subj_hash_map, subj_hashed = hash_series(data.participant, indexation=0)\n",
    "            \n",
    "        return frame_hashed, verb_hashed, subj_hashed\n",
    "    \n",
    "    def _initialize_model(self, data: DataFrame):\n",
    "        model_parameters = self.construct_model_parameters(data)\n",
    "        \n",
    "        return self.model_class(model_parameters)\n",
    "    \n",
    "    def _construct_splits(self, data: DataFrame) -> tuple[SelectionData]:\n",
    "        verbs = data.verb.unique()\n",
    "        frames = data.frame.unique()\n",
    "        \n",
    "        verb_frame_pairs = [v + \"_\" + f for v in verbs for f in frames]\n",
    "        \n",
    "        n_dev = int(len(verb_frame_pairs) / 10)\n",
    "        \n",
    "        verb_frame_pairs_dev = choice(verb_frame_pairs, n_dev, replace=False)\n",
    "        \n",
    "        dev_indicator = (data.verb + \"_\" + data.frame).isin(verb_frame_pairs_dev)\n",
    "        \n",
    "        data_train = data[~dev_indicator]\n",
    "        data_dev = data[dev_indicator]\n",
    "        \n",
    "        return data_train, data_dev\n",
    "    \n",
    "    def fit(\n",
    "        self, data: DataFrame, batch_size=1000, max_epochs:int=10_000, \n",
    "        lr: float = 1e-5, patience: int = 0, tolerance: float = 0.05, \n",
    "        window_size: int = 100, verbosity: int=100, seed: int = 403928\n",
    "    ) -> StructuredSelectionModel:\n",
    "        manual_seed(seed)\n",
    "        random.seed(seed)\n",
    "        \n",
    "        # necessary for initializing hashes\n",
    "        self._construct_hashes(data)\n",
    "        data_train, data_dev = self._construct_splits(data)\n",
    "        self.model = self._initialize_model(data_train)\n",
    "        \n",
    "        # wrap the dev split responses in a tensor\n",
    "        # this tensor will be used to compute the correlation between\n",
    "        # the models expected value for a response and the actual\n",
    "        # response\n",
    "        target_dev = torch.tensor(data_dev.response.values)\n",
    "        \n",
    "        # initialize the optimizer\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)\n",
    "        \n",
    "        # initialize the dev-train correlation differences\n",
    "        self.corr_diffs = []\n",
    "        \n",
    "        for e in range(max_epochs):\n",
    "            # shuffle the training data\n",
    "            data_shuffled = data_train.sample(frac=1.)\n",
    "            data_shuffled = data_shuffled.reset_index(drop=True)\n",
    "            \n",
    "            # compute the number of batches based on the batch size\n",
    "            n_batches = int(data_shuffled.shape[0]/batch_size)\n",
    "        \n",
    "            # zero the total loss for the epoch\n",
    "            epoch_total_loss = 0.\n",
    "        \n",
    "            # initialize the list of correlations\n",
    "            correlations_train = []\n",
    "            \n",
    "            for i in range(n_batches):\n",
    "                # construct the minibatch\n",
    "                lower_bound = i*batch_size\n",
    "                \n",
    "                if i == (n_batches - 1):\n",
    "                    upper_bound = data_shuffled.shape[0]\n",
    "                else:\n",
    "                    upper_bound = (i+1)*batch_size\n",
    "\n",
    "                data_sub = self.construct_model_data(\n",
    "                    data_shuffled.iloc[lower_bound:upper_bound]\n",
    "                )\n",
    "                \n",
    "                # wrap the responses in a tensor\n",
    "                target = torch.tensor(data_sub.resp)\n",
    "\n",
    "                # zero out the gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # compute the (log-)probabilities for the minibatch\n",
    "                probs = self.model(data_sub)\n",
    "                logprobs = torch.log(probs)\n",
    "\n",
    "                # compute the loss\n",
    "                loss = self.loss_function(logprobs, target)\n",
    "                loss += self._prior_loss()\n",
    "\n",
    "                # compute correlation between expected value and target\n",
    "                expected_value_train = torch.sum(\n",
    "                    torch.arange(1, probs.shape[1]+1)[None,:] * probs, \n",
    "                    axis=1\n",
    "                )\n",
    "                corr_train = torch.corrcoef(\n",
    "                    torch.cat([\n",
    "                        expected_value_train[None,:], \n",
    "                        target[None,:]\n",
    "                    ], axis=0)\n",
    "                )\n",
    "                correlations_train.append(corr_train[0,1].item())\n",
    "                \n",
    "                loss.backward()\n",
    "\n",
    "                optimizer.step()\n",
    "                \n",
    "                epoch_total_loss += loss.item()\n",
    "            \n",
    "            expected_value_dev = self.expected_value(data_dev)\n",
    "            corr_dev = torch.corrcoef(\n",
    "                torch.cat([\n",
    "                    expected_value_dev[None,:], \n",
    "                    target_dev[None,:]\n",
    "                ], axis=0)\n",
    "            )[0,1]\n",
    "            \n",
    "            correlations_train_mean = mean(correlations_train)\n",
    "            \n",
    "            self.corr_diffs.append(\n",
    "                correlations_train_mean - corr_dev\n",
    "            )\n",
    "            \n",
    "            if verbosity and not e % verbosity:\n",
    "                print(f\"Epoch:             {e}\")\n",
    "                print(f\"Mean loss:         {round(epoch_total_loss / n_batches, 2)}\")\n",
    "                print(f\"Mean train corr.:  {round(correlations_train_mean, 2)}\")\n",
    "                print(f\"Dev corr.:         {round(corr_dev.data.numpy(), 2)}\")\n",
    "                print()\n",
    "          \n",
    "            max_window_size = min(len(self.corr_diffs), window_size)\n",
    "            mean_diff = torch.mean(torch.tensor(self.corr_diffs[-max_window_size:]))\n",
    "            \n",
    "            if e > patience and mean_diff > tolerance:\n",
    "                \n",
    "                if verbosity:\n",
    "                    print(f\"Epoch:             {e}\")\n",
    "                    print(f\"Mean loss:         {round(epoch_total_loss / n_batches, 2)}\")\n",
    "                    print(f\"Mean train corr.:  {round(correlations_train_mean, 2)}\")\n",
    "                    print(f\"Dev corr.:         {round(corr_dev.data.numpy(), 2)}\")\n",
    "                    print()\n",
    "                \n",
    "                break\n",
    "            else:\n",
    "                prev_corr_dev = corr_dev\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    @abstractmethod\n",
    "    def _prior_loss(self):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def expected_value(self, data: DataFrame):\n",
    "        model_data = self.construct_model_data(data)\n",
    "        probs = self.model(model_data)\n",
    "        \n",
    "        expected_value = torch.sum(\n",
    "            torch.arange(1, 8)[None,:] * probs, \n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        return expected_value\n",
    "    \n",
    "    def likelihood(self, data: DataFrame):\n",
    "        model_data = self.construct_model_data(data)\n",
    "        probs = self.model(model_data)\n",
    "        \n",
    "        return probs[model_data.resp]\n",
    "    \n",
    "    def predict(self, data: DataFrame):\n",
    "        model_data = self.construct_model_data(data)\n",
    "        probs = self.model(model_data)\n",
    "        \n",
    "        return probs[model_data.resp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "63ba0452-b2d0-46f6-81f2-a87475e0babe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class StructuredSelectionModelTrainer(StructuredSelectionModelTrainerABC):\n",
    "    parameter_class = StructuredSelectionModelParameters\n",
    "    model_class = StructuredSelectionModel\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        constituents_to_feature: DataArray,\n",
    "        n_primitive_semantic_types: int, \n",
    "        n_primitive_syntactic_types: int, \n",
    "        max_complex_type_size: int\n",
    "    ):\n",
    "        self.constituents_to_feature = constituents_to_feature\n",
    "        self.n_primitive_semantic_types = n_primitive_semantic_types\n",
    "        self.n_primitive_syntactic_types = n_primitive_syntactic_types\n",
    "        self.max_complex_type_size = max_complex_type_size\n",
    "        \n",
    "        self.loss_function = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    def construct_model_parameters(self, data: DataFrame) -> StructuredSelectionModelParameters:\n",
    "        \n",
    "        \n",
    "        model_parameters = {\n",
    "            \"n_verb\": self.verb_hash_map.shape[0],\n",
    "            \"n_frame\": self.frame_hash_map.shape[0],\n",
    "            \"n_subj\": self.subj_hash_map.shape[0],\n",
    "            \"n_resp_levels\": 7,\n",
    "            \"constituents_to_feature\": self.constituents_to_feature,\n",
    "            \"n_constituent_types\": self.constituents_to_feature.shape[2],\n",
    "            \"n_primitive_semantic_types\": self.n_primitive_semantic_types,\n",
    "            \"n_primitive_syntactic_types\": self.n_primitive_syntactic_types,\n",
    "            \"max_complex_type_size\": self.max_complex_type_size\n",
    "        }\n",
    "        \n",
    "        return self.parameter_class(**model_parameters)\n",
    "    \n",
    "    def _prior_loss(self):\n",
    "        jumps = self.model.jumps\n",
    "        loss = (jumps / jumps.mean(0)[None,:]).mean()\n",
    "        \n",
    "#         verb_component_prior_mean = torch.cumprod(\n",
    "#             verb_component_prior_mean_aux,\n",
    "#             axis=0\n",
    "#         )\n",
    "#         frame_component_prior_mean = torch.cumprod(\n",
    "#             frame_component_prior_mean_aux,\n",
    "#             axis=0\n",
    "#         )\n",
    "        \n",
    "#         if self.nonparametric:\n",
    "#             hyperprior = Beta(self.alpha, 1.)\n",
    "            \n",
    "#             verb_component_prior_mean_aux = self.model.verb_component_prior_mean\n",
    "#             frame_component_prior_mean_aux = self.model.frame_component_prior_mean\n",
    "            \n",
    "#             loss -= hyperprior.log_prob(verb_component_prior_mean_aux).mean()\n",
    "#             loss -= hyperprior.log_prob(frame_component_prior_mean_aux).mean()\n",
    "            \n",
    "#             verb_prior = Beta(\n",
    "#                 verb_component_prior_mean*self.model.verb_component_prior_precision,\n",
    "#                 (1.-verb_component_prior_mean)*self.model.verb_component_prior_precision,\n",
    "#             )\n",
    "#             frame_prior = Beta(\n",
    "#                 frame_component_prior_mean*self.model.frame_component_prior_precision,\n",
    "#                 (1.-frame_component_prior_mean)*self.model.frame_component_prior_precision,\n",
    "#             )\n",
    "            \n",
    "#         if self.alpha != 1. or self.beta != 1.:\n",
    "#             verb_prior = Beta(self.alpha, self.beta)\n",
    "#             frame_prior = Beta(self.alpha, self.beta)\n",
    "            \n",
    "#         loss -= verb_prior.log_prob(self.model.verb_component_prob).mean()\n",
    "#         loss -= frame_prior.log_prob(self.model.frame_component_prob).mean()\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "243273dd-c68c-46c5-9656-5d3f493b6a83",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting model with 1 primitive semantic types and 1 primitive syntactic types...\n",
      "\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1448, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([24942, 2, 2, 2, 2, 2, 2])\n",
      "Epoch:             0\n",
      "Mean loss:         5.82\n",
      "Mean train corr.:  0.01\n",
      "Dev corr.:         0.02\n",
      "\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1448, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([24942, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n",
      "torch.Size([1000, 2, 2, 2, 2, 2, 2])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[82], line 10\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFitting model with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_sem\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m primitive semantic types and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_syn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m primitive syntactic types...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m      9\u001b[0m unconstrained_models[n_sem, n_syn] \u001b[38;5;241m=\u001b[39m StructuredSelectionModelTrainer(constituents_to_feature, n_sem, n_syn, \u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m \u001b[43munconstrained_models\u001b[49m\u001b[43m[\u001b[49m\u001b[43mn_sem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_syn\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[79], line 125\u001b[0m, in \u001b[0;36mStructuredSelectionModelTrainerABC.fit\u001b[0;34m(self, data, batch_size, max_epochs, lr, patience, tolerance, window_size, verbosity, seed)\u001b[0m\n\u001b[1;32m    122\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# compute the (log-)probabilities for the minibatch\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_sub\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m logprobs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlog(probs)\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m# compute the loss\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[75], line 68\u001b[0m, in \u001b[0;36mStructuredSelectionModel.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: SelectionData):\n\u001b[0;32m---> 68\u001b[0m     verb_frame_prob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverb_frame_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m     verb_frame_logodds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlog(verb_frame_prob) \u001b[38;5;241m-\u001b[39m torch\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m1.\u001b[39m \u001b[38;5;241m-\u001b[39m verb_frame_prob)\n\u001b[1;32m     71\u001b[0m     jumps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjumps[data\u001b[38;5;241m.\u001b[39msubj]\n",
      "Cell \u001b[0;32mIn[75], line 107\u001b[0m, in \u001b[0;36mStructuredSelectionModel.verb_frame_prob\u001b[0;34m(self, verb_idx, frame_idx)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;66;03m# shape for computing prod on all but the reponse dimension\u001b[39;00m\n\u001b[1;32m    105\u001b[0m flat_shape \u001b[38;5;241m=\u001b[39m (resp_shape, prod(map_shape))\n\u001b[0;32m--> 107\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverb_complex_semantic_type\u001b[49m\u001b[43m[\u001b[49m\u001b[43mverb_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mverb_shape\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m\\\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframe_complex_syntactic_type[frame_idx]\u001b[38;5;241m.\u001b[39mview(frame_shape) \u001b[38;5;241m*\u001b[39m\\\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomplex_type_map\u001b[38;5;241m.\u001b[39mview(map_shape)\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28mprint\u001b[39m(p\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    113\u001b[0m acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.\u001b[39m \u001b[38;5;241m-\u001b[39m (\u001b[38;5;241m1.\u001b[39m \u001b[38;5;241m-\u001b[39m p\u001b[38;5;241m.\u001b[39mview(flat_shape))\u001b[38;5;241m.\u001b[39mprod(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "unconstrained_models = {}\n",
    "\n",
    "for n_sem in range(1, 5):\n",
    "    for n_syn in range(1, 5):\n",
    "        print(\n",
    "            f\"\\nFitting model with {n_sem} primitive semantic types and \"\n",
    "            f\"{n_syn} primitive syntactic types...\\n\"\n",
    "        )\n",
    "        unconstrained_models[n_sem, n_syn] = StructuredSelectionModelTrainer(constituents_to_feature, n_sem, n_syn, 3)\n",
    "        unconstrained_models[n_sem, n_syn].fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "d166aa18-1a96-4622-beec-5df0930e958d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SignificanceResult(statistic=nan, pvalue=nan)"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "from seaborn import boxplot\n",
    "\n",
    "data[\"expected_value\"] = unconstrained_selection_model.expected_value(data).data\n",
    "\n",
    "_ = boxplot(data, x=\"response\", y=\"expected_value\")\n",
    "\n",
    "spearmanr(data[[\"response\", \"expected_value\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "116c6d04-dcf3-49d6-9333-82130be2d275",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.4941, 0.4941],\n",
       "        [0.0000, 0.4941, 0.4941]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.model.primitive_type_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef54dfb-e151-4c07-b487-3761fd467866",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#sns.clustermap(DataFrame(m.model.frame_component_prob.data, index=m.frame_hash_map), cmap=\"vlag\", yticklabels=True)\n",
    "sns.clustermap(DataFrame(m.model.verb_component_prob.data, index=m.verb_hash_map), cmap=\"vlag\", yticklabels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f37180-a45c-4903-9c53-73d64c9336f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ConstrainedSelectionModelParameters(SelectionModelParameters):\n",
    "    n_clause_component: int\n",
    "    n_nonclause_component: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a614a4-95d3-4d46-a651-44e3feb41505",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "class ConstrainedSelectionModel(torch.nn.Module):\n",
    "    parameter_class = ConstrainedSelectionModelParameters\n",
    "    \n",
    "    def __init__(self, parameters: ConstrainedSelectionModelParameters):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model_parameters = parameters\n",
    "        \n",
    "        self.verb_clause_aux = torch.nn.Parameter(\n",
    "            torch.randn([parameters.n_verb]), \n",
    "            requires_grad=True\n",
    "        )\n",
    "        self.verb_nonclause_aux = torch.nn.Parameter(\n",
    "            torch.randn([\n",
    "                parameters.n_verb, parameters.n_nonclause_component\n",
    "            ]), \n",
    "            requires_grad=True\n",
    "        )\n",
    "        \n",
    "        self.frame_clause_aux = torch.nn.Parameter(\n",
    "            torch.randn([parameters.n_frame]), \n",
    "            requires_grad=True\n",
    "        )\n",
    "        self.frame_nonclause_aux = torch.nn.Parameter(\n",
    "            torch.randn([\n",
    "                parameters.n_frame, parameters.n_nonclause_component\n",
    "            ]), \n",
    "            requires_grad=True\n",
    "        )\n",
    "        \n",
    "        self.log_clause_jumps = torch.nn.Parameter(\n",
    "            torch.ones(parameters.n_clause_component-1), \n",
    "            requires_grad=True\n",
    "        )\n",
    "        \n",
    "        self.log_jumps = torch.nn.Parameter(\n",
    "            torch.ones([\n",
    "                parameters.n_subj, parameters.n_resp_levels-1\n",
    "            ]), \n",
    "            requires_grad=True\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, data: SelectionData):\n",
    "        verb_frame_prob = self.verb_frame_prob(data.verb, data.frame)\n",
    "        verb_frame_logodds = torch.log(verb_frame_prob) - torch.log(1. - verb_frame_prob)\n",
    "        \n",
    "        jumps = self.jumps[data.subj]\n",
    "        \n",
    "        return ordered_logistic_likelihood(\n",
    "            verb_frame_logodds, jumps\n",
    "        )\n",
    "   \n",
    "    def verb_frame_prob(\n",
    "        self, \n",
    "        verb_idx: Optional[ndarray] = None, \n",
    "        frame_idx: Optional[ndarray] = None\n",
    "    ) -> Tensor:\n",
    "        return self.verb_frame_clause_prob(verb_idx, frame_idx) *\\\n",
    "               self.verb_frame_nonclause_prob(verb_idx, frame_idx)\n",
    "\n",
    "    def verb_frame_clause_prob(\n",
    "        self, \n",
    "        verb_idx: Optional[ndarray] = None, \n",
    "        frame_idx: Optional[ndarray] = None\n",
    "    ) -> Tensor:\n",
    "        if verb_idx is not None or frame_idx is not None:\n",
    "            return 1. - torch.prod(\n",
    "                1. - self.verb_clause_component_prob[verb_idx,:] * \n",
    "                     self.frame_clause_component_prob[frame_idx,:],\n",
    "                axis=1\n",
    "            )\n",
    "        elif verb_idx is None and frame_idx is not None:\n",
    "            return 1. - torch.prod(\n",
    "                1. - self.verb_clause_component_prob[:,None,:] * \n",
    "                     self.frame_clause_component_prob[:,frame_idx,:],\n",
    "                axis=2\n",
    "            )\n",
    "        elif verb_idx is not None and frame_idx is None:\n",
    "            return 1. - torch.prod(\n",
    "                1. - self.verb_clause_component_prob[verb_idx,None,:] * \n",
    "                     self.frame_clause_component_prob[None,:,:],\n",
    "                axis=2\n",
    "            )\n",
    "        else:\n",
    "            return 1. - torch.prod(\n",
    "                1. - self.verb_clause_component_prob[:,None,:] * \n",
    "                     self.frame_clause_component_prob[None,:,:],\n",
    "                axis=2\n",
    "            ) \n",
    "\n",
    "    def verb_frame_nonclause_prob(\n",
    "        self, \n",
    "        verb_idx: Optional[ndarray] = None, \n",
    "        frame_idx: Optional[ndarray] = None\n",
    "    ) -> Tensor:\n",
    "        if verb_idx is not None or frame_idx is not None:\n",
    "            return 1. - torch.prod(\n",
    "                1. - self.verb_nonclause_component_prob[verb_idx,:] * \n",
    "                     self.frame_nonclause_component_prob[frame_idx,:],\n",
    "                axis=1\n",
    "            )\n",
    "        elif verb_idx is None and frame_idx is not None:\n",
    "            return 1. - torch.prod(\n",
    "                1. - self.verb_nonclause_component_prob[:,None,:] * \n",
    "                     self.frame_nonclause_component_prob[:,frame_idx,:],\n",
    "                axis=2\n",
    "            )\n",
    "        elif verb_idx is not None and frame_idx is None:\n",
    "            return 1. - torch.prod(\n",
    "                1. - self.verb_nonclause_component_prob[verb_idx,None,:] * \n",
    "                     self.frame_nonclause_component_prob[None,:,:],\n",
    "                axis=2\n",
    "            )\n",
    "        else:\n",
    "            return 1. - torch.prod(\n",
    "                1. - self.verb_nonclause_component_prob[:,None,:] * \n",
    "                     self.frame_nonclause_component_prob[None,:,:],\n",
    "                axis=2\n",
    "            )       \n",
    "    \n",
    "    @property\n",
    "    def verb_clause_component_prob(self) -> Tensor:\n",
    "        return ordered_logistic_likelihood(\n",
    "            self.verb_clause_aux, self.clause_jumps[None,:]\n",
    "        )\n",
    "    \n",
    "    @property\n",
    "    def frame_clause_component_prob(self) -> Tensor:\n",
    "        return ordered_logistic_likelihood(\n",
    "            self.frame_clause_aux, self.clause_jumps[None,:]\n",
    "        )\n",
    "    \n",
    "    @property\n",
    "    def verb_nonclause_component_prob(self) -> Tensor:\n",
    "        return torch.sigmoid(self.verb_nonclause_aux)\n",
    "    \n",
    "    @property\n",
    "    def frame_nonclause_component_prob(self) -> Tensor:\n",
    "        return torch.sigmoid(self.frame_nonclause_aux)\n",
    "\n",
    "    @property\n",
    "    def clause_jumps(self):\n",
    "        return torch.exp(self.log_clause_jumps)\n",
    "    \n",
    "    @property\n",
    "    def jumps(self):\n",
    "        return torch.exp(self.log_jumps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bc056a-08bb-44a4-9558-f7f36797882d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ConstrainedSelectionModelTrainer(SelectionModelTrainer):\n",
    "    parameter_class = ConstrainedSelectionModelParameters\n",
    "    model_class = ConstrainedSelectionModel\n",
    "    \n",
    "    def __init__(self, n_clause_component: int, n_nonclause_component: int):\n",
    "        self.n_clause_component = n_clause_component\n",
    "        self.n_nonclause_component = n_nonclause_component\n",
    "        \n",
    "        self.loss_function = torch.nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "    \n",
    "    def construct_model_parameters(self, data: DataFrame) -> UnconstrainedSelectionModelParameters:\n",
    "        model_parameters = {\n",
    "            \"n_verb\": self.verb_hash_map.shape[0],\n",
    "            \"n_frame\": self.frame_hash_map.shape[0],\n",
    "            \"n_subj\": self.subj_hash_map.shape[0],\n",
    "            \"n_resp_levels\": 7,\n",
    "            \"n_clause_component\": self.n_clause_component,\n",
    "            \"n_nonclause_component\": self.n_nonclause_component\n",
    "        }\n",
    "        \n",
    "        return self.parameter_class(**model_parameters)\n",
    "    \n",
    "m = ConstrainedSelectionModelTrainer(3, 2)\n",
    "m.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2ac14f-f517-405b-948b-311322460781",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.clustermap(DataFrame(m.model.frame_clause_component_prob.data, index=m.frame_hash_map), yticklabels=True)\n",
    "#sns.clustermap(DataFrame(m.model.verb_component_prob.data, index=m.verb_hash_map), cmap=\"vlag\", yticklabels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb36d97-c0d5-478c-99a6-d69efbec1943",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ordered_logistic_likelihood??"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
